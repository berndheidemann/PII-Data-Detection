{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["from transformers import AutoTokenizer, TrainingArguments, Trainer, AutoModelForTokenClassification\n","from pathlib import Path\n","import numpy as np\n","import torch\n","from tokenizers import AddedToken\n","from tqdm.notebook import tqdm\n","from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n","import pandas as pd\n","from seqeval.metrics import recall_score, precision_score, f1_score, accuracy_score\n","from datasets import Dataset\n","\n","kaggle=False\n","\n","path=\"/kaggle/input/pii-detection-removal-from-educational-data\" if kaggle else \"data\"\n","train_path = path + \"/train.json\"\n","test_path = path + \"/test.json\"\n","\n","model_path = \"/kaggle/input/huggingfacedebertav3variants/deberta-v3-base\" if kaggle else \"microsoft/deberta-v3-base\"\n","\n","if not kaggle: import neptune"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-01-25T21:37:35.578114Z","iopub.status.busy":"2024-01-25T21:37:35.577723Z","iopub.status.idle":"2024-01-25T21:37:35.587366Z","shell.execute_reply":"2024-01-25T21:37:35.5858Z","shell.execute_reply.started":"2024-01-25T21:37:35.578083Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["{'model': 'microsoft/deberta-v3-base', 'max_length': 1024, 'inference_max_length': 2000, 'batch_size': 4, 'inference_batch_size': 1, 'lr': 5e-05, 'lr_scale_unfreeze': 0.1, 'filter_no_pii_percent_allow': 0.2, 'notebook': '20_deberta base_1024len.ipynb', 'CROSS_ENTROPY_WEIGHT_MULTI': 400, 'epochs_before_unfreeze': 1, 'epochs_after_unfreeze': 6, 'repeat_unfreeze_train_n_times': 2, 'validate_every_n_epochs': 2, 'train_test_split': 0.2, 'num_proc': 16, 'freeze_embeddings': False, 'freeze_layers': 6}\n"]}],"source":["cross_entropy_weight_multi = 400\n","\n","CROSS_ENTROPY_WEIGHTS = [cross_entropy_weight_multi]*12\n","CROSS_ENTROPY_WEIGHTS.append(1)\n","\n","parameter= {\n","    \"model\": model_path,\n","    \"max_length\": 1024,\n","    \"inference_max_length\": 2000,\n","    \"batch_size\": 4,\n","    \"inference_batch_size\": 1,\n","    \"lr\": 5e-05,\n","    \"lr_scale_unfreeze\": 0.1,\n","    \"filter_no_pii_percent_allow\": 0.2,\n","    \"notebook\": \"20_deberta base_1024len.ipynb\",\n","    \"CROSS_ENTROPY_WEIGHT_MULTI\": cross_entropy_weight_multi,\n","    \"epochs_before_unfreeze\": 1,\n","    \"epochs_after_unfreeze\": 6,\n","    \"repeat_unfreeze_train_n_times\": 2,\n","    \"validate_every_n_epochs\": 2,\n","    \"train_test_split\": 0.2,\n","    \"num_proc\": 16, \n","    \"freeze_embeddings\": False,\n","    \"freeze_layers\": 6\n","}\n","\n","print(parameter)"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["target = [\n","    'B-EMAIL', 'B-ID_NUM', 'B-NAME_STUDENT', 'B-PHONE_NUM', \n","    'B-STREET_ADDRESS', 'B-URL_PERSONAL', 'B-USERNAME', 'I-ID_NUM', \n","    'I-NAME_STUDENT', 'I-PHONE_NUM', 'I-STREET_ADDRESS', 'I-URL_PERSONAL'\n","]"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-01-25T21:37:35.606208Z","iopub.status.busy":"2024-01-25T21:37:35.605889Z","iopub.status.idle":"2024-01-25T21:37:35.62164Z","shell.execute_reply":"2024-01-25T21:37:35.620746Z","shell.execute_reply.started":"2024-01-25T21:37:35.606175Z"},"trusted":true},"outputs":[],"source":["from itertools import chain\n","import json\n","\n","data = json.load(open(train_path))\n","all_labels = sorted(list(set(chain(*[x[\"labels\"] for x in data]))))\n","label2id = {l: i for i,l in enumerate(all_labels)}\n","id2label = {v:k for k,v in label2id.items()}"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["import random\n","\n","def tokenize(example, tokenizer, label2id, max_length, all_labels_list):\n","    text = []\n","    import numpy as np\n","\n","    # these are at the character level\n","    labels = []\n","    targets = []\n","\n","    for t, l, ws in zip(example[\"tokens\"], example[\"labels\"], example[\"trailing_whitespace\"]):\n","\n","        text.append(t)\n","        labels.extend([l]*len(t))\n","        \n","        if l in all_labels_list:\n","            targets.append(1)\n","        else:\n","            targets.append(0)\n","        # if there is trailing whitespace\n","        if ws:\n","            text.append(\" \")\n","            labels.append(\"O\")\n","\n","    tokenized = tokenizer(\"\".join(text), return_offsets_mapping=True, truncation=True, max_length=max_length, padding=\"max_length\")\n","    \n","    target_num = sum(targets)\n","    labels = np.array(labels)\n","\n","    text = \"\".join(text)\n","    token_labels = []\n","\n","    for start_idx, end_idx in tokenized.offset_mapping:\n","\n","        # CLS token\n","        if start_idx == 0 and end_idx == 0: \n","            token_labels.append(label2id[\"O\"])\n","            continue\n","\n","        # case when token starts with whitespace\n","        if text[start_idx].isspace():\n","            start_idx += 1\n","\n","        try:\n","            token_labels.append(label2id[labels[start_idx]])\n","        except:\n","            token_labels.append(label2id[\"O\"])\n","\n","    length = len(tokenized.input_ids)\n","\n","    return {\n","        **tokenized,\n","        \"labels\": token_labels,\n","        \"length\": length,\n","        \"target_num\": target_num,\n","        \"group\": 1 if target_num>0 else 0\n","    }\n","\n","# https://www.kaggle.com/competitions/pii-detection-removal-from-educational-data/discussion/468844\n","def filter_no_pii(example, percent_allow=parameter[\"filter_no_pii_percent_allow\"]):\n","    # Return True if there is PII\n","    # Or 20% of the time if there isn't\n","    has_pii = set(\"O\") != set(example[\"labels\"])\n","    return has_pii or (random.random() < percent_allow)"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","c:\\Users\\Bernd\\anaconda3\\envs\\mytorch\\lib\\site-packages\\transformers\\convert_slow_tokenizer.py:470: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n","  warnings.warn(\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1c6b0dd8c46142a28e0ed2437bf49ddf","version_major":2,"version_minor":0},"text/plain":["Map (num_proc=16):   0%|          | 0/6807 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"221618cae5ec4a25aa87917a4a051ede","version_major":2,"version_minor":0},"text/plain":["Filter (num_proc=16):   0%|          | 0/6807 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["train_len 5445\n","valid_len 1362\n"]}],"source":["data = json.load(open(train_path))\n","ds = Dataset.from_dict({\n","    \"full_text\": [x[\"full_text\"] for x in data],\n","    \"document\": [str(x[\"document\"]) for x in data],\n","    \"tokens\": [x[\"tokens\"] for x in data],\n","    \"trailing_whitespace\": [x[\"trailing_whitespace\"] for x in data],\n","    \"labels\": [x[\"labels\"] for x in data],\n","})\n","    \n","tokenizer = AutoTokenizer.from_pretrained(parameter[\"model\"])\n","ds = ds.map(tokenize, fn_kwargs={\"tokenizer\": tokenizer, \"label2id\": label2id, \"max_length\": parameter[\"max_length\"], \"all_labels_list\": target}, num_proc=parameter[\"num_proc\"])\n","ds=ds.filter(filter_no_pii, num_proc=parameter[\"num_proc\"])\n","\n","\n","data_len=len(ds)\n","train_len=int(len(ds)*(1-parameter[\"train_test_split\"]))\n","valid_len=len(ds)-train_len\n","train_data_idx=np.random.choice(data_len, train_len, replace=False)\n","valid_data_idx=np.array(list(set(range(data_len))-set(train_data_idx)))\n","print(\"train_len\", train_len)\n","print(\"valid_len\", valid_len)\n","\n","# split ds in train and valid\n","train_ds=ds.select(train_data_idx)\n","valid_ds=ds.select(valid_data_idx)"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"data":{"text/plain":["[1,\n"," 6348,\n"," 6190,\n"," 377,\n"," 2169,\n"," 1291,\n"," 270,\n"," 3513,\n"," 45730,\n"," 377,\n"," 53779,\n"," 1637,\n"," 6738,\n"," 429,\n"," 14700,\n"," 4305,\n"," 277,\n"," 312,\n"," 517,\n"," 261,\n"," 53779,\n"," 303,\n"," 1666,\n"," 351,\n"," 553,\n"," 262,\n"," 11412,\n"," 866,\n"," 265,\n"," 266,\n"," 483,\n"," 264,\n"," 355,\n"," 2282,\n"," 277,\n"," 262,\n"," 23114,\n"," 465,\n"," 265,\n"," 308,\n"," 374,\n"," 260,\n"," 463,\n"," 465,\n"," 265,\n"," 312,\n"," 5311,\n"," 261,\n"," 273,\n"," 3232,\n"," 275,\n"," 266,\n"," 509,\n"," 265,\n"," 467,\n"," 6998,\n"," 264,\n"," 10151,\n"," 262,\n"," 568,\n"," 272,\n"," 413,\n"," 465,\n"," 265,\n"," 260,\n"," 589,\n"," 386,\n"," 5658,\n"," 261,\n"," 273,\n"," 286,\n"," 757,\n"," 1568,\n"," 3498,\n"," 264,\n"," 398,\n"," 262,\n"," 610,\n"," 1355,\n"," 265,\n"," 262,\n"," 374,\n"," 306,\n"," 333,\n"," 267,\n"," 266,\n"," 406,\n"," 264,\n"," 406,\n"," 1599,\n"," 260,\n"," 329,\n"," 3498,\n"," 303,\n"," 1379,\n"," 264,\n"," 8509,\n"," 292,\n"," 347,\n"," 1568,\n"," 1712,\n"," 262,\n"," 713,\n"," 272,\n"," 308,\n"," 1016,\n"," 702,\n"," 276,\n"," 297,\n"," 1329,\n"," 264,\n"," 286,\n"," 1239,\n"," 277,\n"," 262,\n"," 568,\n"," 306,\n"," 374,\n"," 277,\n"," 260,\n"," 463,\n"," 2996,\n"," 293,\n"," 6601,\n"," 77962,\n"," 53144,\n"," 261,\n"," 3234,\n"," 4735,\n"," 1872,\n"," 288,\n"," 7583,\n"," 261,\n"," 277,\n"," 262,\n"," 567,\n"," 542,\n"," 265,\n"," 262,\n"," 586,\n"," 261,\n"," 53779,\n"," 335,\n"," 619,\n"," 4337,\n"," 1530,\n"," 264,\n"," 676,\n"," 1138,\n"," 292,\n"," 339,\n"," 284,\n"," 4114,\n"," 266,\n"," 735,\n"," 260,\n"," 3089,\n"," 261,\n"," 273,\n"," 276,\n"," 415,\n"," 2915,\n"," 291,\n"," 1637,\n"," 264,\n"," 676,\n"," 266,\n"," 1138,\n"," 292,\n"," 262,\n"," 1719,\n"," 272,\n"," 276,\n"," 268,\n"," 1992,\n"," 264,\n"," 351,\n"," 260,\n"," 5736,\n"," 502,\n"," 282,\n"," 1514,\n"," 264,\n"," 380,\n"," 53779,\n"," 264,\n"," 262,\n"," 1719,\n"," 273,\n"," 284,\n"," 1992,\n"," 261,\n"," 273,\n"," 330,\n"," 264,\n"," 796,\n"," 262,\n"," 1602,\n"," 319,\n"," 5066,\n"," 262,\n"," 6998,\n"," 260,\n"," 643,\n"," 1605,\n"," 275,\n"," 349,\n"," 261,\n"," 273,\n"," 670,\n"," 264,\n"," 2544,\n"," 272,\n"," 306,\n"," 849,\n"," 264,\n"," 551,\n"," 272,\n"," 308,\n"," 374,\n"," 284,\n"," 5222,\n"," 263,\n"," 330,\n"," 1239,\n"," 277,\n"," 262,\n"," 483,\n"," 260,\n"," 4087,\n"," 291,\n"," 2302,\n"," 261,\n"," 273,\n"," 330,\n"," 266,\n"," 397,\n"," 6960,\n"," 277,\n"," 339,\n"," 262,\n"," 665,\n"," 265,\n"," 262,\n"," 697,\n"," 403,\n"," 282,\n"," 260,\n"," 573,\n"," 1238,\n"," 284,\n"," 394,\n"," 264,\n"," 553,\n"," 361,\n"," 308,\n"," 374,\n"," 4940,\n"," 264,\n"," 262,\n"," 1228,\n"," 265,\n"," 262,\n"," 483,\n"," 260,\n"," 273,\n"," 2528,\n"," 262,\n"," 53779,\n"," 1637,\n"," 275,\n"," 262,\n"," 51146,\n"," 1637,\n"," 293,\n"," 1512,\n"," 266,\n"," 697,\n"," 10630,\n"," 399,\n"," 448,\n"," 24329,\n"," 284,\n"," 262,\n"," 2041,\n"," 265,\n"," 266,\n"," 553,\n"," 292,\n"," 319,\n"," 262,\n"," 1099,\n"," 284,\n"," 262,\n"," 1976,\n"," 1034,\n"," 260,\n"," 2891,\n"," 266,\n"," 1671,\n"," 2155,\n"," 4047,\n"," 261,\n"," 273,\n"," 284,\n"," 526,\n"," 264,\n"," 3656,\n"," 361,\n"," 262,\n"," 467,\n"," 568,\n"," 267,\n"," 262,\n"," 483,\n"," 284,\n"," 379,\n"," 1058,\n"," 264,\n"," 266,\n"," 553,\n"," 399,\n"," 262,\n"," 1238,\n"," 284,\n"," 264,\n"," 6887,\n"," 262,\n"," 1099,\n"," 389,\n"," 263,\n"," 361,\n"," 262,\n"," 876,\n"," 265,\n"," 469,\n"," 4435,\n"," 377,\n"," 6998,\n"," 377,\n"," 330,\n"," 299,\n"," 1239,\n"," 277,\n"," 278,\n"," 260,\n"," 805,\n"," 291,\n"," 15563,\n"," 520,\n"," 286,\n"," 757,\n"," 14772,\n"," 261,\n"," 278,\n"," 464,\n"," 861,\n"," 347,\n"," 3292,\n"," 263,\n"," 11808,\n"," 6443,\n"," 292,\n"," 1568,\n"," 272,\n"," 332,\n"," 8578,\n"," 347,\n"," 260,\n"," 22459,\n"," 429,\n"," 17798,\n"," 927,\n"," 8406,\n"," 1113,\n"," 264,\n"," 380,\n"," 20582,\n"," 1870,\n"," 334,\n"," 262,\n"," 53779,\n"," 1637,\n"," 4796,\n"," 262,\n"," 2956,\n"," 7464,\n"," 10994,\n"," 1459,\n"," 261,\n"," 273,\n"," 284,\n"," 526,\n"," 264,\n"," 398,\n"," 361,\n"," 310,\n"," 1287,\n"," 278,\n"," 284,\n"," 264,\n"," 3634,\n"," 262,\n"," 735,\n"," 319,\n"," 281,\n"," 327,\n"," 310,\n"," 20582,\n"," 263,\n"," 286,\n"," 625,\n"," 4871,\n"," 1527,\n"," 321,\n"," 343,\n"," 260,\n"," 463,\n"," 1897,\n"," 267,\n"," 291,\n"," 586,\n"," 261,\n"," 4871,\n"," 1870,\n"," 295,\n"," 282,\n"," 379,\n"," 1287,\n"," 264,\n"," 3634,\n"," 947,\n"," 399,\n"," 262,\n"," 808,\n"," 281,\n"," 913,\n"," 263,\n"," 301,\n"," 286,\n"," 514,\n"," 264,\n"," 2760,\n"," 278,\n"," 261,\n"," 304,\n"," 335,\n"," 301,\n"," 281,\n"," 4131,\n"," 275,\n"," 2070,\n"," 4086,\n"," 386,\n"," 20331,\n"," 261,\n"," 587,\n"," 1291,\n"," 269,\n"," 310,\n"," 2567,\n"," 260,\n"," 329,\n"," 9102,\n"," 265,\n"," 587,\n"," 1291,\n"," 303,\n"," 1614,\n"," 264,\n"," 8078,\n"," 493,\n"," 267,\n"," 262,\n"," 812,\n"," 265,\n"," 467,\n"," 2070,\n"," 786,\n"," 306,\n"," 295,\n"," 282,\n"," 8712,\n"," 293,\n"," 7464,\n"," 10994,\n"," 1459,\n"," 377,\n"," 319,\n"," 273,\n"," 330,\n"," 262,\n"," 517,\n"," 264,\n"," 333,\n"," 377,\n"," 289,\n"," 293,\n"," 291,\n"," 353,\n"," 1459,\n"," 265,\n"," 587,\n"," 1291,\n"," 319,\n"," 1614,\n"," 351,\n"," 264,\n"," 286,\n"," 266,\n"," 310,\n"," 615,\n"," 791,\n"," 264,\n"," 2760,\n"," 1179,\n"," 263,\n"," 1739,\n"," 947,\n"," 260,\n"," 4305,\n"," 277,\n"," 291,\n"," 1031,\n"," 517,\n"," 261,\n"," 262,\n"," 498,\n"," 326,\n"," 273,\n"," 296,\n"," 282,\n"," 526,\n"," 264,\n"," 380,\n"," 587,\n"," 1291,\n"," 261,\n"," 273,\n"," 296,\n"," 365,\n"," 521,\n"," 273,\n"," 295,\n"," 427,\n"," 264,\n"," 540,\n"," 3572,\n"," 265,\n"," 540,\n"," 32941,\n"," 1569,\n"," 267,\n"," 291,\n"," 586,\n"," 260,\n"," 927,\n"," 478,\n"," 364,\n"," 53779,\n"," 263,\n"," 51146,\n"," 1637,\n"," 261,\n"," 273,\n"," 284,\n"," 526,\n"," 264,\n"," 398,\n"," 637,\n"," 262,\n"," 610,\n"," 1239,\n"," 378,\n"," 1415,\n"," 295,\n"," 286,\n"," 264,\n"," 2760,\n"," 947,\n"," 260,\n"," 7986,\n"," 292,\n"," 12629,\n"," 28771,\n"," 482,\n"," 262,\n"," 317,\n"," 3125,\n"," 269,\n"," 302,\n"," 318,\n"," 3138,\n"," 264,\n"," 262,\n"," 1422,\n"," 271,\n"," 74289,\n"," 267,\n"," 262,\n"," 317,\n"," 3125,\n"," 337,\n"," 302,\n"," 318,\n"," 3138,\n"," 263,\n"," 5078,\n"," 275,\n"," 1538,\n"," 263,\n"," 2315,\n"," 6492,\n"," 482,\n"," 262,\n"," 498,\n"," 392,\n"," 10664,\n"," 260,\n"," 2,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," ...]"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["train_ds[0][\"input_ids\"]"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["def tokenize_inference(example, tokenizer, max_length):\n","        text = []\n","        for t,  ws in zip(example[\"tokens\"], example[\"trailing_whitespace\"]):\n","            text.append(t)\n","            if ws:\n","                text.append(\" \")\n","        tokenized = tokenizer(\"\".join(text), return_offsets_mapping=True, truncation=True, max_length=max_length, padding=\"max_length\")\n","        text = \"\".join(text)\n","        length = len(tokenized.input_ids)\n","        return {\n","            **tokenized,\n","            \"length\": length,\n","        }\n","        \n","class TestTokenizer():\n","    def __init__(self, tokenizer):\n","        self.tokenizer = tokenizer\n","    \n","    def preprocess(self, example):\n","        # Preprocess the tokens and labels by adding trailing whitespace and labels\n","        tokens = []\n","        tokens_without_ws = []\n","        token_map = [] # Use the index as labels\n","        index = 0\n","        for token, t_ws in zip(example[\"tokens\"], example[\"trailing_whitespace\"]):\n","            tokens_without_ws.append(token)\n","            tokens.append(token)\n","            token_map.extend([index] * len(token))\n","            # Added trailing whitespace and label if true and \n","            if t_ws:\n","                tokens.append(\" \")\n","                token_map.append(-1)\n","            index += 1\n","        return tokens, token_map, tokens_without_ws\n","    \n","    def tokenize(self, example):\n","        tokens, token_map, tokens_without_ws = self.preprocess(example)\n","        text = \"\".join(tokens)\n","        tokenized = self.tokenizer(text, return_offsets_mapping=True, padding=\"max_length\",\n","                                   truncation=True, max_length=parameter[\"inference_max_length\"])\n","        return {**tokenized, \"token_map\": token_map, \"tokens\": tokens, \"tokens_without_ws\": tokens_without_ws} \n","\n","class PiiDatasetInference(torch.utils.data.Dataset):\n","        def __init__(self, dataset, tokenizer):\n","            self.dataset = dataset\n","            self.tokenizer=TestTokenizer(tokenizer)\n","            \n","        def __getitem__(self, idx):\n","            vals=self.tokenizer.tokenize(self.dataset[idx])\n","            input_ids = torch.tensor(vals[\"input_ids\"])\n","            attention_mask = torch.tensor(vals[\"attention_mask\"])\n","            document_id = self.dataset[idx][\"document\"]\n","            return input_ids, attention_mask, document_id, vals\n","        \n","        def __len__(self):\n","            return len(self.dataset)\n","\n","# Convert preds to a list of dictionaries\n","def to_test_submission(preds=None, dataset=None, document_ids=None, id2label=None):\n","    triplets = []\n","    row_id = 0\n","    results = []\n","    \n","    for i in range(len(preds)):\n","        input_ids, attention_mask, document_id, vals = dataset[i]\n","        token_map=vals[\"token_map\"]\n","        offsets=vals[\"offset_mapping\"]\n","        tokens=vals[\"tokens_without_ws\"]\n","        #print(\"tokens\", tokens)\n","        pred=preds[i]\n","        original_text = tokenizer.decode(input_ids)[6:] # skip CLS token\n","        #print(\"original_text\", original_text)\n","        #print(\"token_map\", token_map)\n","        #print(\"offsets\", offsets)   \n","        #print(\"pred\", pred)\n","\n","        for token_pred, input_id, (start_idx, end_idx) in zip(pred, input_ids, offsets):\n","            #print(\"\\nnow doing \", start_idx,  end_idx, token_pred)\n","            if start_idx == 0 and end_idx == 0: # Skip 0 offset\n","                continue\n","            # Skip spaces \n","            while start_idx < len(token_map):\n","                #print(\"loop, start_idx now\", start_idx) \n","                #print(\" tokens[token_map[start_idx]]: \", tokens[token_map[start_idx]] if not tokens[token_map[start_idx]].isspace() else \"WHITESPACE\")          \n","                if token_map[start_idx] == -1: # Skip unknown tokens               \n","                    start_idx += 1\n","                elif tokens[token_map[start_idx]].isspace(): # Skip white space\n","                    start_idx += 1\n","                else:\n","                    break\n","            # Ensure start index < length\n","            if start_idx < len(token_map):\n","                token_id = token_map[start_idx]\n","                #print(\"token_id\", token_id)\n","                #token_id= input_id.item()\n","                label_pred = id2label[token_pred.item()]\n","                #print(\"label_pred\", label_pred)\n","                # ignore \"O\" and whitespace preds\n","                if label_pred != \"O\" and token_id != -1:\n","                    #print(\"is PII\", token_id, label_pred)\n","                    token_str = tokens[token_id]\n","                    triplet = (label_pred, token_id, token_str)\n","                    if triplet not in triplets:\n","                        results.append({\n","                            \"row_id\": row_id, \n","                            \"document\": document_id,\n","                            \"token\": token_id, \n","                            \"label\": label_pred,\n","                            \"token_str\": token_str\n","                        })\n","                        triplets.append(triplet)\n","                        row_id += 1\n","\n","    # Create a dataframe \n","    return results\n","\n","def create_submission(model, filename=\"submission.csv\"):\n","    data = json.load(open(train_path))\n","    from itertools import chain\n","    all_labels = sorted(list(set(chain(*[x[\"labels\"] for x in data]))))\n","    label2id = {l: i for i,l in enumerate(all_labels)}\n","    id2label = {v:k for k,v in label2id.items()}\n","\n","    data=json.load(open(test_path))\n","    tokenizer = AutoTokenizer.from_pretrained(parameter[\"model\"])\n","    my_dataset=PiiDatasetInference(data, tokenizer)\n","    loader=torch.utils.data.DataLoader(my_dataset, batch_size=1, shuffle=False)\n","\n","    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    model.eval()\n","    \n","    # stack all predictions into tensor\n","    all_preds = []\n","\n","    for id, attention_mask, document_ids, vals in loader:\n","        id=id.to(device)\n","        attention_mask=attention_mask.to(device)\n","        preds=model(id, attention_mask).get('logits').argmax(dim=2)\n","        all_preds.append(preds)\n","        #for pred, id in zip(preds.flatten(), id.flatten()):\n","        #    if pred != 12:\n","                #print(f\"Document: {document_id.item()} TOKEN:{tokenizer.decode(id)}  --- pred:{id2label[pred.item()]}\")\n","        #        output[row_id]={\"document\":document_id.item(), \"token\":id.item(), \"label\":id2label[pred.item()]}\n","        #        row_id+=1\n","        #for pred, id in zip(preds.flatten(), id.flatten()):\n","        #    if pred != 12:\n","        #        print(f\"TOKEN:{tokenizer.decode(id)}  --- pred:{id2label[pred.item()]}\")\n","    \n","   \n","    all_preds = torch.cat(all_preds, dim=0)\n","    \n","    results = to_test_submission(preds=all_preds, dataset=my_dataset, document_ids=document_ids, id2label=id2label)\n","    if len(results) == 0:\n","        print(\"Error in create_submission(): No predictions made, probably because the model is not learning. Check the model and the data.\")\n","        return\n","    df = pd.DataFrame(results)\n","    df=df[[\"row_id\", \"document\", \"token\", \"label\"]]\n","    print(df)\n","    df.to_csv(filename, index=False)\n","\n","#create_submission(MyModel(parameter['model'], len(label2id)).to(device), \"submission_just_dumb.csv\")\n","# create_submission(model, \"submission.csv\")\n"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["from transformers import DataCollatorForTokenClassification\n","\n","collator = DataCollatorForTokenClassification(tokenizer, pad_to_multiple_of=16)"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\Bernd\\anaconda3\\envs\\mytorch\\lib\\site-packages\\neptune\\common\\warnings.py:71: NeptuneWarning: The following monitoring options are disabled by default in interactive sessions: 'capture_stdout', 'capture_stderr', 'capture_traceback', and 'capture_hardware_metrics'. To enable them, set each parameter to 'True' when initializing the run. The monitoring will continue until you call run.stop() or the kernel stops. Also note: Your source files can only be tracked if you pass the path(s) to the 'source_code' argument. For help, see the Neptune docs: https://docs.neptune.ai/logging/source_code/\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["https://app.neptune.ai/bernd.heidemann/PII/e/PII-216\n"]}],"source":["# using Trainer and TrainingArguments from transformers\n","\n","\n","def compute_metrics(p, all_labels):\n","    predictions, labels = p\n","    predictions = np.argmax(predictions, axis=2)\n","\n","    # Remove ignored index (special tokens)\n","    true_predictions = [\n","        [all_labels[p] for (p, l) in zip(prediction, label) if l != -100]\n","        for prediction, label in zip(predictions, labels)\n","    ]\n","    true_labels = [\n","        [all_labels[l] for (p, l) in zip(prediction, label) if l != -100]\n","        for prediction, label in zip(predictions, labels)\n","    ]\n","    \n","    recall = recall_score(true_labels, true_predictions)\n","    precision = precision_score(true_labels, true_predictions)\n","    f1_score = (1 + 5*5) * recall * precision / (5*5*precision + recall)\n","    \n","    results = {\n","        'recall': recall,\n","        'precision': precision,\n","        'f1': f1_score\n","    }\n","    return results\n","\n","if not kaggle:\n","    from transformers.integrations import NeptuneCallback\n","\n","    run = neptune.init_run(\n","        project=\"bernd.heidemann/PII\",\n","        api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiIzNjBlYzVkNi0zZTUwLTQ1ODYtODhlNC02NDUxNDg0MDdjNzUifQ==\",\n","    )  # your credentials\n","    run[\"parameters\"] = {\n","    **parameter\n","    }\n","\n","    neptune_callback = NeptuneCallback(run=run, log_model_weights=False, log_parameters=False)\n","\n","from functools import partial\n","\n","def get_trainer(model, train_dataloader, valid_dataloader):\n","    training_args = TrainingArguments(\n","        output_dir='./results',          # output directory\n","        num_train_epochs=parameter[\"epochs_before_unfreeze\"],              # total number of training epochs\n","        per_device_train_batch_size=parameter[\"batch_size\"],  # batch size per device during training\n","        per_device_eval_batch_size=parameter[\"inference_batch_size\"],   # batch size for evaluation\n","        warmup_steps=500,                # number of warmup steps for learning rate scheduler\n","        weight_decay=0.01,               # strength of weight decay\n","        logging_dir='./logs',            # directory for storing logs\n","        logging_steps=10,\n","        evaluation_strategy=\"steps\",\n","        eval_steps=400,\n","        save_steps=400,\n","        save_total_limit=3,\n","        load_best_model_at_end=True,\n","        metric_for_best_model=\"f1\" if not kaggle else \"eval_loss\",\n","        greater_is_better=True,\n","        overwrite_output_dir=True,\n","        report_to=\"none\",\n","        learning_rate=parameter[\"lr\"],\n","\n","        #callback for neptune\n","    )\n","\n","    class MyTrainer(Trainer):\n","        def __init__(self, model=None, args=None, train_dataset=None, eval_dataset=None, compute_metrics=None, callbacks=None):\n","            super().__init__(model=model, args=args, train_dataset=train_dataset, eval_dataset=eval_dataset, compute_metrics=compute_metrics, callbacks=callbacks)\n","            # Definieren Sie hier Ihre Gewichte fÃ¼r die Klassen, z.B. torch.tensor([1.0, 2.0, 0.5])\n","            self.weight = torch.tensor(CROSS_ENTROPY_WEIGHTS).to(device)\n","            self.loss_func=torch.nn.CrossEntropyLoss(ignore_index=-100, weight=torch.tensor(CROSS_ENTROPY_WEIGHTS, dtype=torch.float32).to(device))\n","\n","        def compute_loss(self, model, inputs, return_outputs=False):\n","            labels = inputs.get(\"labels\")\n","            outputs = model(**inputs)\n","            logits = outputs.get('logits')\n","            loss = self.loss_func(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n","            return (loss, outputs) if return_outputs else loss\n","\n","    trainer = MyTrainer(\n","        model=model,                         # the instantiated ðŸ¤— Transformers model to be trained\n","        args=training_args,                  # training arguments, defined above\n","        train_dataset=train_dataloader,         # training dataset\n","        eval_dataset=valid_dataloader,             # evaluation dataset\n","        compute_metrics=partial(compute_metrics, all_labels=all_labels) if not kaggle else None,\n","        callbacks=[neptune_callback] if not kaggle else None\n","    )\n","    return trainer"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["def unfreeze(model):\n","    for param in model.base_model.parameters():\n","        param.requires_grad = True\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","Some weights of DebertaV2ForTokenClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"name":"stdout","output_type":"stream","text":["DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"B-EMAIL\",\n","    \"1\": \"B-ID_NUM\",\n","    \"2\": \"B-NAME_STUDENT\",\n","    \"3\": \"B-PHONE_NUM\",\n","    \"4\": \"B-STREET_ADDRESS\",\n","    \"5\": \"B-URL_PERSONAL\",\n","    \"6\": \"B-USERNAME\",\n","    \"7\": \"I-ID_NUM\",\n","    \"8\": \"I-NAME_STUDENT\",\n","    \"9\": \"I-PHONE_NUM\",\n","    \"10\": \"I-STREET_ADDRESS\",\n","    \"11\": \"I-URL_PERSONAL\",\n","    \"12\": \"O\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"B-EMAIL\": 0,\n","    \"B-ID_NUM\": 1,\n","    \"B-NAME_STUDENT\": 2,\n","    \"B-PHONE_NUM\": 3,\n","    \"B-STREET_ADDRESS\": 4,\n","    \"B-URL_PERSONAL\": 5,\n","    \"B-USERNAME\": 6,\n","    \"I-ID_NUM\": 7,\n","    \"I-NAME_STUDENT\": 8,\n","    \"I-PHONE_NUM\": 9,\n","    \"I-STREET_ADDRESS\": 10,\n","    \"I-URL_PERSONAL\": 11,\n","    \"O\": 12\n","  },\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.31.0\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\Bernd\\anaconda3\\envs\\mytorch\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"12d17ebdc0744bf1b82a12205c11eed2","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1362 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'loss': 2.9192, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.01}\n","{'loss': 2.7746, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.01}\n","{'loss': 2.5098, 'learning_rate': 3e-06, 'epoch': 0.02}\n","{'loss': 2.2666, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.03}\n","{'loss': 1.8006, 'learning_rate': 5e-06, 'epoch': 0.04}\n","{'loss': 1.6844, 'learning_rate': 6e-06, 'epoch': 0.04}\n","{'loss': 1.1798, 'learning_rate': 7.000000000000001e-06, 'epoch': 0.05}\n","{'loss': 0.8757, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.06}\n","{'loss': 0.499, 'learning_rate': 9e-06, 'epoch': 0.07}\n","{'loss': 1.0246, 'learning_rate': 1e-05, 'epoch': 0.07}\n","{'loss': 0.7192, 'learning_rate': 1.1000000000000001e-05, 'epoch': 0.08}\n","{'loss': 0.8068, 'learning_rate': 1.2e-05, 'epoch': 0.09}\n","{'loss': 1.1109, 'learning_rate': 1.3000000000000001e-05, 'epoch': 0.1}\n","{'loss': 0.4495, 'learning_rate': 1.4000000000000001e-05, 'epoch': 0.1}\n","{'loss': 0.306, 'learning_rate': 1.5e-05, 'epoch': 0.11}\n","{'loss': 0.3918, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.12}\n","{'loss': 0.5364, 'learning_rate': 1.7000000000000003e-05, 'epoch': 0.12}\n","{'loss': 0.4827, 'learning_rate': 1.8e-05, 'epoch': 0.13}\n","{'loss': 0.6875, 'learning_rate': 1.9e-05, 'epoch': 0.14}\n","{'loss': 0.0946, 'learning_rate': 2e-05, 'epoch': 0.15}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"796932c0410e4a038bf922b5698db5fe","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1362 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.09517715871334076, 'eval_recall': 0.19258202567760344, 'eval_precision': 0.09527170077628794, 'eval_f1': 0.18530250237567314, 'eval_runtime': 45.9915, 'eval_samples_per_second': 29.614, 'eval_steps_per_second': 29.614, 'epoch': 0.15}\n","{'loss': 0.0718, 'learning_rate': 2.1e-05, 'epoch': 0.15}\n","{'loss': 0.3089, 'learning_rate': 2.2000000000000003e-05, 'epoch': 0.16}\n","{'loss': 0.0741, 'learning_rate': 2.3000000000000003e-05, 'epoch': 0.17}\n","{'loss': 0.6722, 'learning_rate': 2.4e-05, 'epoch': 0.18}\n","{'loss': 0.2051, 'learning_rate': 2.5e-05, 'epoch': 0.18}\n","{'loss': 0.3092, 'learning_rate': 2.6000000000000002e-05, 'epoch': 0.19}\n","{'loss': 0.0083, 'learning_rate': 2.7000000000000002e-05, 'epoch': 0.2}\n","{'loss': 0.317, 'learning_rate': 2.8000000000000003e-05, 'epoch': 0.21}\n","{'loss': 0.0433, 'learning_rate': 2.9e-05, 'epoch': 0.21}\n","{'loss': 0.2264, 'learning_rate': 3e-05, 'epoch': 0.22}\n","{'loss': 0.0336, 'learning_rate': 3.1e-05, 'epoch': 0.23}\n","{'loss': 0.0495, 'learning_rate': 3.2000000000000005e-05, 'epoch': 0.23}\n","{'loss': 0.2514, 'learning_rate': 3.3e-05, 'epoch': 0.24}\n","{'loss': 0.0114, 'learning_rate': 3.4000000000000007e-05, 'epoch': 0.25}\n","{'loss': 0.2538, 'learning_rate': 3.5e-05, 'epoch': 0.26}\n","{'loss': 0.1825, 'learning_rate': 3.6e-05, 'epoch': 0.26}\n","{'loss': 0.0018, 'learning_rate': 3.7e-05, 'epoch': 0.27}\n","{'loss': 0.094, 'learning_rate': 3.8e-05, 'epoch': 0.28}\n","{'loss': 0.0073, 'learning_rate': 3.9000000000000006e-05, 'epoch': 0.29}\n","{'loss': 0.3952, 'learning_rate': 4e-05, 'epoch': 0.29}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"22320e2d4d004e27820b171c35eefec7","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1362 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.0422653965651989, 'eval_recall': 0.456490727532097, 'eval_precision': 0.4657933042212518, 'eval_f1': 0.4568416428728311, 'eval_runtime': 43.1015, 'eval_samples_per_second': 31.6, 'eval_steps_per_second': 31.6, 'epoch': 0.29}\n","{'loss': 0.1514, 'learning_rate': 4.1e-05, 'epoch': 0.3}\n","{'loss': 0.0053, 'learning_rate': 4.2e-05, 'epoch': 0.31}\n","{'loss': 0.1882, 'learning_rate': 4.3e-05, 'epoch': 0.32}\n","{'loss': 0.0016, 'learning_rate': 4.4000000000000006e-05, 'epoch': 0.32}\n","{'loss': 0.0993, 'learning_rate': 4.5e-05, 'epoch': 0.33}\n","{'loss': 0.0108, 'learning_rate': 4.600000000000001e-05, 'epoch': 0.34}\n","{'loss': 0.0802, 'learning_rate': 4.7e-05, 'epoch': 0.35}\n","{'loss': 0.0033, 'learning_rate': 4.8e-05, 'epoch': 0.35}\n","{'loss': 0.0003, 'learning_rate': 4.9e-05, 'epoch': 0.36}\n","{'loss': 0.11, 'learning_rate': 5e-05, 'epoch': 0.37}\n","{'loss': 0.0152, 'learning_rate': 4.9419953596287704e-05, 'epoch': 0.37}\n","{'loss': 0.0311, 'learning_rate': 4.8839907192575406e-05, 'epoch': 0.38}\n","{'loss': 0.0096, 'learning_rate': 4.825986078886311e-05, 'epoch': 0.39}\n","{'loss': 0.0026, 'learning_rate': 4.767981438515081e-05, 'epoch': 0.4}\n","{'loss': 0.0157, 'learning_rate': 4.709976798143852e-05, 'epoch': 0.4}\n","{'loss': 0.5396, 'learning_rate': 4.651972157772622e-05, 'epoch': 0.41}\n","{'loss': 0.0135, 'learning_rate': 4.593967517401392e-05, 'epoch': 0.42}\n","{'loss': 0.0014, 'learning_rate': 4.5359628770301624e-05, 'epoch': 0.43}\n","{'loss': 0.0457, 'learning_rate': 4.477958236658933e-05, 'epoch': 0.43}\n","{'loss': 0.2451, 'learning_rate': 4.4199535962877034e-05, 'epoch': 0.44}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"335aaeaceae749f3bba405b4591403ae","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1362 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.1080680564045906, 'eval_recall': 0.4108416547788873, 'eval_precision': 0.6220302375809935, 'eval_f1': 0.41627751834556376, 'eval_runtime': 43.2732, 'eval_samples_per_second': 31.474, 'eval_steps_per_second': 31.474, 'epoch': 0.44}\n","{'loss': 0.0005, 'learning_rate': 4.3619489559164736e-05, 'epoch': 0.45}\n","{'loss': 0.0031, 'learning_rate': 4.303944315545244e-05, 'epoch': 0.46}\n","{'loss': 0.9597, 'learning_rate': 4.2459396751740146e-05, 'epoch': 0.46}\n","{'loss': 0.0088, 'learning_rate': 4.187935034802785e-05, 'epoch': 0.47}\n","{'loss': 0.0895, 'learning_rate': 4.129930394431555e-05, 'epoch': 0.48}\n","{'loss': 0.0018, 'learning_rate': 4.071925754060325e-05, 'epoch': 0.48}\n","{'loss': 0.0055, 'learning_rate': 4.013921113689095e-05, 'epoch': 0.49}\n","{'loss': 0.1362, 'learning_rate': 3.9559164733178655e-05, 'epoch': 0.5}\n","{'loss': 0.1732, 'learning_rate': 3.897911832946636e-05, 'epoch': 0.51}\n","{'loss': 0.357, 'learning_rate': 3.839907192575406e-05, 'epoch': 0.51}\n","{'loss': 0.0279, 'learning_rate': 3.781902552204177e-05, 'epoch': 0.52}\n","{'loss': 0.0091, 'learning_rate': 3.723897911832947e-05, 'epoch': 0.53}\n","{'loss': 0.0008, 'learning_rate': 3.665893271461717e-05, 'epoch': 0.54}\n","{'loss': 0.0062, 'learning_rate': 3.607888631090487e-05, 'epoch': 0.54}\n","{'loss': 0.0094, 'learning_rate': 3.5498839907192574e-05, 'epoch': 0.55}\n"]}],"source":["# set environment variables: TOKENIZERS_PARALLELISM=false\n","import os\n","os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n","\n","tokenizer = AutoTokenizer.from_pretrained(parameter[\"model\"])\n","tokenizer.add_tokens(AddedToken(\"\\n\", normalized=False))\n","\n","model = AutoModelForTokenClassification.from_pretrained(\n","    parameter[\"model\"],\n","    num_labels=len(all_labels),\n","    id2label=id2label,\n","    label2id=label2id,\n","    ignore_mismatched_sizes=True\n",")\n","\n","if parameter['freeze_embeddings']:\n","    for param in model.deberta.embeddings.parameters():\n","        param.requires_grad = False\n","        \n","if parameter['freeze_layers'] > 0:\n","    for layer in model.deberta.encoder.layer[:parameter['freeze_layers']]:\n","        for param in layer.parameters():\n","            param.requires_grad = False\n","\n","print(model.config)\n","#my_model=MyModel(parameter['model'], len(label2id))\n","\n","trainer=get_trainer(model, train_ds, valid_ds)\n","trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\Bernd\\anaconda3\\envs\\mytorch\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"60a3800a569f4e51a61849c28005e470","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/5448 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'loss': 0.0006, 'learning_rate': 1.0000000000000001e-07, 'epoch': 0.01}\n","{'loss': 0.0121, 'learning_rate': 2.0000000000000002e-07, 'epoch': 0.01}\n","{'loss': 0.0008, 'learning_rate': 3.0000000000000004e-07, 'epoch': 0.02}\n","{'loss': 0.0006, 'learning_rate': 4.0000000000000003e-07, 'epoch': 0.03}\n","{'loss': 0.0334, 'learning_rate': 5.000000000000001e-07, 'epoch': 0.04}\n","{'loss': 0.1075, 'learning_rate': 6.000000000000001e-07, 'epoch': 0.04}\n","{'loss': 0.0009, 'learning_rate': 7.000000000000001e-07, 'epoch': 0.05}\n","{'loss': 0.0006, 'learning_rate': 8.000000000000001e-07, 'epoch': 0.06}\n","{'loss': 0.0008, 'learning_rate': 9.000000000000001e-07, 'epoch': 0.07}\n","{'loss': 0.0014, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.07}\n","{'loss': 0.0007, 'learning_rate': 1.1e-06, 'epoch': 0.08}\n","{'loss': 0.0025, 'learning_rate': 1.2000000000000002e-06, 'epoch': 0.09}\n","{'loss': 0.0017, 'learning_rate': 1.3e-06, 'epoch': 0.1}\n","{'loss': 0.0014, 'learning_rate': 1.4000000000000001e-06, 'epoch': 0.1}\n","{'loss': 0.0004, 'learning_rate': 1.5e-06, 'epoch': 0.11}\n","{'loss': 0.0009, 'learning_rate': 1.6000000000000001e-06, 'epoch': 0.12}\n","{'loss': 0.0048, 'learning_rate': 1.7000000000000002e-06, 'epoch': 0.12}\n","{'loss': 0.0015, 'learning_rate': 1.8000000000000001e-06, 'epoch': 0.13}\n","{'loss': 0.0005, 'learning_rate': 1.9000000000000002e-06, 'epoch': 0.14}\n","{'loss': 0.0014, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.15}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"028ebbf93db1497cb2aa43c19be56ed7","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1362 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.01020288746803999, 'eval_recall': 0.9641319942611191, 'eval_precision': 0.5808124459809854, 'eval_f1': 0.9402647723603486, 'eval_runtime': 44.5961, 'eval_samples_per_second': 30.541, 'eval_steps_per_second': 30.541, 'epoch': 0.15}\n","{'loss': 0.0038, 'learning_rate': 2.1000000000000002e-06, 'epoch': 0.15}\n","{'loss': 0.0007, 'learning_rate': 2.2e-06, 'epoch': 0.16}\n","{'loss': 0.0002, 'learning_rate': 2.3000000000000004e-06, 'epoch': 0.17}\n","{'loss': 0.0001, 'learning_rate': 2.4000000000000003e-06, 'epoch': 0.18}\n","{'loss': 0.0003, 'learning_rate': 2.5e-06, 'epoch': 0.18}\n","{'loss': 0.149, 'learning_rate': 2.6e-06, 'epoch': 0.19}\n","{'loss': 0.0003, 'learning_rate': 2.7000000000000004e-06, 'epoch': 0.2}\n","{'loss': 0.0023, 'learning_rate': 2.8000000000000003e-06, 'epoch': 0.21}\n","{'loss': 0.0001, 'learning_rate': 2.9e-06, 'epoch': 0.21}\n","{'loss': 0.1787, 'learning_rate': 3e-06, 'epoch': 0.22}\n","{'loss': 0.0001, 'learning_rate': 3.1000000000000004e-06, 'epoch': 0.23}\n","{'loss': 0.0032, 'learning_rate': 3.2000000000000003e-06, 'epoch': 0.23}\n","{'loss': 0.0029, 'learning_rate': 3.3000000000000006e-06, 'epoch': 0.24}\n","{'loss': 0.0007, 'learning_rate': 3.4000000000000005e-06, 'epoch': 0.25}\n","{'loss': 0.0022, 'learning_rate': 3.5e-06, 'epoch': 0.26}\n","{'loss': 0.1401, 'learning_rate': 3.6000000000000003e-06, 'epoch': 0.26}\n","{'loss': 0.0006, 'learning_rate': 3.7e-06, 'epoch': 0.27}\n","{'loss': 0.001, 'learning_rate': 3.8000000000000005e-06, 'epoch': 0.28}\n","{'loss': 0.0006, 'learning_rate': 3.900000000000001e-06, 'epoch': 0.29}\n","{'loss': 0.0004, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.29}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1c550aa4828e4ac8bb905e957ae236fe","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1362 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.008522579446434975, 'eval_recall': 0.9670014347202296, 'eval_precision': 0.5815358067299397, 'eval_f1': 0.9429616874730952, 'eval_runtime': 44.079, 'eval_samples_per_second': 30.899, 'eval_steps_per_second': 30.899, 'epoch': 0.29}\n","{'loss': 0.0034, 'learning_rate': 4.1e-06, 'epoch': 0.3}\n","{'loss': 0.0002, 'learning_rate': 4.2000000000000004e-06, 'epoch': 0.31}\n","{'loss': 0.0005, 'learning_rate': 4.3e-06, 'epoch': 0.32}\n","{'loss': 0.0021, 'learning_rate': 4.4e-06, 'epoch': 0.32}\n","{'loss': 0.0024, 'learning_rate': 4.5e-06, 'epoch': 0.33}\n","{'loss': 0.0003, 'learning_rate': 4.600000000000001e-06, 'epoch': 0.34}\n","{'loss': 0.005, 'learning_rate': 4.7e-06, 'epoch': 0.35}\n","{'loss': 0.0006, 'learning_rate': 4.800000000000001e-06, 'epoch': 0.35}\n","{'loss': 0.0001, 'learning_rate': 4.9000000000000005e-06, 'epoch': 0.36}\n","{'loss': 0.0084, 'learning_rate': 5e-06, 'epoch': 0.37}\n","{'loss': 0.0034, 'learning_rate': 4.989894907033146e-06, 'epoch': 0.37}\n","{'loss': 0.2412, 'learning_rate': 4.9797898140662895e-06, 'epoch': 0.38}\n","{'loss': 0.0007, 'learning_rate': 4.969684721099435e-06, 'epoch': 0.39}\n","{'loss': 0.0001, 'learning_rate': 4.959579628132579e-06, 'epoch': 0.4}\n","{'loss': 0.0474, 'learning_rate': 4.949474535165724e-06, 'epoch': 0.4}\n","{'loss': 0.0002, 'learning_rate': 4.9393694421988685e-06, 'epoch': 0.41}\n","{'loss': 0.0023, 'learning_rate': 4.929264349232014e-06, 'epoch': 0.42}\n","{'loss': 0.3664, 'learning_rate': 4.919159256265158e-06, 'epoch': 0.43}\n","{'loss': 0.0105, 'learning_rate': 4.909054163298303e-06, 'epoch': 0.43}\n","{'loss': 0.0023, 'learning_rate': 4.8989490703314475e-06, 'epoch': 0.44}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bdb4eac69c3f4af0bbd07ca8a3d771a8","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1362 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.007412514183670282, 'eval_recall': 0.9741750358680057, 'eval_precision': 0.5950920245398773, 'eval_f1': 0.9508779489389205, 'eval_runtime': 43.1139, 'eval_samples_per_second': 31.591, 'eval_steps_per_second': 31.591, 'epoch': 0.44}\n","{'loss': 0.0225, 'learning_rate': 4.888843977364592e-06, 'epoch': 0.45}\n","{'loss': 0.0007, 'learning_rate': 4.878738884397737e-06, 'epoch': 0.46}\n","{'loss': 0.0008, 'learning_rate': 4.868633791430882e-06, 'epoch': 0.46}\n","{'loss': 0.0004, 'learning_rate': 4.8585286984640265e-06, 'epoch': 0.47}\n","{'loss': 0.0006, 'learning_rate': 4.848423605497171e-06, 'epoch': 0.48}\n","{'loss': 0.0003, 'learning_rate': 4.838318512530316e-06, 'epoch': 0.48}\n","{'loss': 0.0016, 'learning_rate': 4.82821341956346e-06, 'epoch': 0.49}\n","{'loss': 0.0004, 'learning_rate': 4.818108326596605e-06, 'epoch': 0.5}\n","{'loss': 0.0101, 'learning_rate': 4.80800323362975e-06, 'epoch': 0.51}\n","{'loss': 0.0129, 'learning_rate': 4.797898140662895e-06, 'epoch': 0.51}\n","{'loss': 0.0011, 'learning_rate': 4.787793047696039e-06, 'epoch': 0.52}\n","{'loss': 0.0008, 'learning_rate': 4.777687954729184e-06, 'epoch': 0.53}\n","{'loss': 0.0006, 'learning_rate': 4.767582861762329e-06, 'epoch': 0.54}\n","{'loss': 0.001, 'learning_rate': 4.757477768795473e-06, 'epoch': 0.54}\n","{'loss': 0.0001, 'learning_rate': 4.747372675828618e-06, 'epoch': 0.55}\n","{'loss': 0.0003, 'learning_rate': 4.737267582861763e-06, 'epoch': 0.56}\n","{'loss': 0.0595, 'learning_rate': 4.727162489894907e-06, 'epoch': 0.57}\n","{'loss': 0.0003, 'learning_rate': 4.717057396928052e-06, 'epoch': 0.57}\n","{'loss': 0.0015, 'learning_rate': 4.706952303961197e-06, 'epoch': 0.58}\n","{'loss': 0.0011, 'learning_rate': 4.696847210994342e-06, 'epoch': 0.59}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"eff807a80bf44feaba1b37e7a901d56e","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1362 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.009337876923382282, 'eval_recall': 0.9483500717360115, 'eval_precision': 0.6241737488196412, 'eval_f1': 0.9297771045228307, 'eval_runtime': 44.0382, 'eval_samples_per_second': 30.928, 'eval_steps_per_second': 30.928, 'epoch': 0.59}\n","{'loss': 0.0023, 'learning_rate': 4.686742118027486e-06, 'epoch': 0.59}\n","{'loss': 0.0845, 'learning_rate': 4.676637025060631e-06, 'epoch': 0.6}\n","{'loss': 0.0009, 'learning_rate': 4.666531932093775e-06, 'epoch': 0.61}\n","{'loss': 0.0005, 'learning_rate': 4.65642683912692e-06, 'epoch': 0.62}\n","{'loss': 0.0002, 'learning_rate': 4.646321746160065e-06, 'epoch': 0.62}\n","{'loss': 0.0003, 'learning_rate': 4.63621665319321e-06, 'epoch': 0.63}\n","{'loss': 0.0001, 'learning_rate': 4.626111560226354e-06, 'epoch': 0.64}\n","{'loss': 0.0002, 'learning_rate': 4.616006467259499e-06, 'epoch': 0.65}\n","{'loss': 0.0026, 'learning_rate': 4.605901374292644e-06, 'epoch': 0.65}\n","{'loss': 0.0025, 'learning_rate': 4.595796281325788e-06, 'epoch': 0.66}\n","{'loss': 0.0002, 'learning_rate': 4.585691188358933e-06, 'epoch': 0.67}\n","{'loss': 0.0001, 'learning_rate': 4.575586095392078e-06, 'epoch': 0.68}\n","{'loss': 0.0002, 'learning_rate': 4.5654810024252225e-06, 'epoch': 0.68}\n","{'loss': 0.2664, 'learning_rate': 4.555375909458367e-06, 'epoch': 0.69}\n","{'loss': 0.0015, 'learning_rate': 4.545270816491512e-06, 'epoch': 0.7}\n","{'loss': 0.002, 'learning_rate': 4.535165723524657e-06, 'epoch': 0.7}\n","{'loss': 0.0001, 'learning_rate': 4.5250606305578015e-06, 'epoch': 0.71}\n","{'loss': 0.0027, 'learning_rate': 4.514955537590946e-06, 'epoch': 0.72}\n","{'loss': 0.0012, 'learning_rate': 4.5048504446240906e-06, 'epoch': 0.73}\n","{'loss': 0.1397, 'learning_rate': 4.494745351657235e-06, 'epoch': 0.73}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"aeaf98a3933d4663b782b60d612bb845","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1362 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.014843376353383064, 'eval_recall': 0.896700143472023, 'eval_precision': 0.686059275521405, 'eval_f1': 0.8862347294938918, 'eval_runtime': 43.8719, 'eval_samples_per_second': 31.045, 'eval_steps_per_second': 31.045, 'epoch': 0.73}\n","{'loss': 0.0012, 'learning_rate': 4.4846402586903805e-06, 'epoch': 0.74}\n","{'loss': 0.0012, 'learning_rate': 4.474535165723525e-06, 'epoch': 0.75}\n","{'loss': 0.0004, 'learning_rate': 4.46443007275667e-06, 'epoch': 0.76}\n","{'loss': 0.0023, 'learning_rate': 4.454324979789815e-06, 'epoch': 0.76}\n","{'loss': 0.0001, 'learning_rate': 4.4442198868229595e-06, 'epoch': 0.77}\n","{'loss': 0.001, 'learning_rate': 4.434114793856104e-06, 'epoch': 0.78}\n","{'loss': 0.0007, 'learning_rate': 4.424009700889249e-06, 'epoch': 0.79}\n","{'loss': 0.0008, 'learning_rate': 4.413904607922393e-06, 'epoch': 0.79}\n","{'loss': 0.0017, 'learning_rate': 4.403799514955538e-06, 'epoch': 0.8}\n","{'loss': 0.1559, 'learning_rate': 4.393694421988683e-06, 'epoch': 0.81}\n","{'loss': 0.001, 'learning_rate': 4.383589329021828e-06, 'epoch': 0.81}\n","{'loss': 0.0022, 'learning_rate': 4.373484236054972e-06, 'epoch': 0.82}\n","{'loss': 0.0009, 'learning_rate': 4.363379143088117e-06, 'epoch': 0.83}\n","{'loss': 0.0483, 'learning_rate': 4.353274050121262e-06, 'epoch': 0.84}\n","{'loss': 0.0004, 'learning_rate': 4.343168957154406e-06, 'epoch': 0.84}\n","{'loss': 0.0004, 'learning_rate': 4.333063864187551e-06, 'epoch': 0.85}\n","{'loss': 0.0201, 'learning_rate': 4.322958771220696e-06, 'epoch': 0.86}\n","{'loss': 0.0015, 'learning_rate': 4.31285367825384e-06, 'epoch': 0.87}\n","{'loss': 0.265, 'learning_rate': 4.302748585286985e-06, 'epoch': 0.87}\n","{'loss': 0.0112, 'learning_rate': 4.29264349232013e-06, 'epoch': 0.88}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"88efb5fe4ae04139a13895459c801d38","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1362 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.011074275709688663, 'eval_recall': 0.9526542324246772, 'eval_precision': 0.6384615384615384, 'eval_f1': 0.9349580287029515, 'eval_runtime': 45.7237, 'eval_samples_per_second': 29.788, 'eval_steps_per_second': 29.788, 'epoch': 0.88}\n","{'loss': 0.0019, 'learning_rate': 4.282538399353275e-06, 'epoch': 0.89}\n","{'loss': 0.0387, 'learning_rate': 4.272433306386419e-06, 'epoch': 0.9}\n","{'loss': 0.002, 'learning_rate': 4.262328213419564e-06, 'epoch': 0.9}\n","{'loss': 0.0025, 'learning_rate': 4.252223120452708e-06, 'epoch': 0.91}\n","{'loss': 0.1546, 'learning_rate': 4.242118027485853e-06, 'epoch': 0.92}\n","{'loss': 0.0326, 'learning_rate': 4.232012934518998e-06, 'epoch': 0.93}\n","{'loss': 0.1364, 'learning_rate': 4.221907841552143e-06, 'epoch': 0.93}\n","{'loss': 0.0003, 'learning_rate': 4.211802748585287e-06, 'epoch': 0.94}\n","{'loss': 0.0064, 'learning_rate': 4.201697655618432e-06, 'epoch': 0.95}\n","{'loss': 0.001, 'learning_rate': 4.191592562651577e-06, 'epoch': 0.95}\n","{'loss': 0.0019, 'learning_rate': 4.181487469684721e-06, 'epoch': 0.96}\n","{'loss': 0.0001, 'learning_rate': 4.171382376717866e-06, 'epoch': 0.97}\n","{'loss': 0.0344, 'learning_rate': 4.161277283751011e-06, 'epoch': 0.98}\n","{'loss': 0.0002, 'learning_rate': 4.1511721907841554e-06, 'epoch': 0.98}\n","{'loss': 0.0005, 'learning_rate': 4.1410670978173e-06, 'epoch': 0.99}\n","{'loss': 0.0003, 'learning_rate': 4.130962004850445e-06, 'epoch': 1.0}\n","{'loss': 0.0088, 'learning_rate': 4.12085691188359e-06, 'epoch': 1.01}\n","{'loss': 0.0002, 'learning_rate': 4.1107518189167345e-06, 'epoch': 1.01}\n","{'loss': 0.0028, 'learning_rate': 4.100646725949879e-06, 'epoch': 1.02}\n","{'loss': 0.1107, 'learning_rate': 4.0905416329830235e-06, 'epoch': 1.03}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5416b05d97c34e828b509c7c08641469","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1362 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.010243733413517475, 'eval_recall': 0.9182209469153515, 'eval_precision': 0.6280667320902846, 'eval_f1': 0.902190414226849, 'eval_runtime': 50.3562, 'eval_samples_per_second': 27.047, 'eval_steps_per_second': 27.047, 'epoch': 1.03}\n","{'loss': 0.0001, 'learning_rate': 4.080436540016168e-06, 'epoch': 1.04}\n","{'loss': 0.0011, 'learning_rate': 4.0703314470493135e-06, 'epoch': 1.04}\n","{'loss': 0.0872, 'learning_rate': 4.060226354082458e-06, 'epoch': 1.05}\n","{'loss': 0.0013, 'learning_rate': 4.0501212611156026e-06, 'epoch': 1.06}\n","{'loss': 0.0016, 'learning_rate': 4.040016168148747e-06, 'epoch': 1.06}\n","{'loss': 0.0001, 'learning_rate': 4.0299110751818925e-06, 'epoch': 1.07}\n","{'loss': 0.0007, 'learning_rate': 4.019805982215036e-06, 'epoch': 1.08}\n","{'loss': 0.0017, 'learning_rate': 4.0097008892481816e-06, 'epoch': 1.09}\n","{'loss': 0.0063, 'learning_rate': 3.999595796281326e-06, 'epoch': 1.09}\n","{'loss': 0.0003, 'learning_rate': 3.989490703314471e-06, 'epoch': 1.1}\n","{'loss': 0.0001, 'learning_rate': 3.979385610347615e-06, 'epoch': 1.11}\n","{'loss': 0.0019, 'learning_rate': 3.969280517380761e-06, 'epoch': 1.12}\n","{'loss': 0.0022, 'learning_rate': 3.959175424413904e-06, 'epoch': 1.12}\n","{'loss': 0.0018, 'learning_rate': 3.94907033144705e-06, 'epoch': 1.13}\n","{'loss': 0.0007, 'learning_rate': 3.938965238480194e-06, 'epoch': 1.14}\n","{'loss': 0.0002, 'learning_rate': 3.928860145513339e-06, 'epoch': 1.15}\n","{'loss': 0.0003, 'learning_rate': 3.918755052546483e-06, 'epoch': 1.15}\n","{'loss': 0.0027, 'learning_rate': 3.908649959579629e-06, 'epoch': 1.16}\n","{'loss': 0.0003, 'learning_rate': 3.898544866612773e-06, 'epoch': 1.17}\n","{'loss': 0.0004, 'learning_rate': 3.888439773645918e-06, 'epoch': 1.17}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4b333abe0fd8455aa06593c68b4daa0e","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1362 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.008026955649256706, 'eval_recall': 0.93974175035868, 'eval_precision': 0.5987202925045704, 'eval_f1': 0.9195960905016469, 'eval_runtime': 47.0298, 'eval_samples_per_second': 28.96, 'eval_steps_per_second': 28.96, 'epoch': 1.17}\n","{'loss': 0.0003, 'learning_rate': 3.878334680679063e-06, 'epoch': 1.18}\n","{'loss': 0.0006, 'learning_rate': 3.868229587712207e-06, 'epoch': 1.19}\n","{'loss': 0.0017, 'learning_rate': 3.858124494745352e-06, 'epoch': 1.2}\n","{'loss': 0.0008, 'learning_rate': 3.848019401778497e-06, 'epoch': 1.2}\n","{'loss': 0.0003, 'learning_rate': 3.837914308811641e-06, 'epoch': 1.21}\n","{'loss': 0.003, 'learning_rate': 3.827809215844786e-06, 'epoch': 1.22}\n","{'loss': 0.0009, 'learning_rate': 3.817704122877931e-06, 'epoch': 1.23}\n","{'loss': 0.0, 'learning_rate': 3.8075990299110754e-06, 'epoch': 1.23}\n","{'loss': 0.0004, 'learning_rate': 3.7974939369442203e-06, 'epoch': 1.24}\n","{'loss': 0.0004, 'learning_rate': 3.787388843977365e-06, 'epoch': 1.25}\n","{'loss': 0.0001, 'learning_rate': 3.77728375101051e-06, 'epoch': 1.26}\n","{'loss': 0.0001, 'learning_rate': 3.7671786580436544e-06, 'epoch': 1.26}\n","{'loss': 0.0003, 'learning_rate': 3.7570735650767993e-06, 'epoch': 1.27}\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn[18], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m parameter[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m parameter[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m*\u001b[39m parameter[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr_scale_unfreeze\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m      4\u001b[0m trainer\u001b[38;5;241m=\u001b[39mget_trainer(model, train_ds, valid_ds)\n\u001b[1;32m----> 5\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\Bernd\\anaconda3\\envs\\mytorch\\lib\\site-packages\\transformers\\trainer.py:1539\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1534\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_wrapped \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\n\u001b[0;32m   1536\u001b[0m inner_training_loop \u001b[38;5;241m=\u001b[39m find_executable_batch_size(\n\u001b[0;32m   1537\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inner_training_loop, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_batch_size, args\u001b[38;5;241m.\u001b[39mauto_find_batch_size\n\u001b[0;32m   1538\u001b[0m )\n\u001b[1;32m-> 1539\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1540\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1541\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1542\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1544\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\Bernd\\anaconda3\\envs\\mytorch\\lib\\site-packages\\transformers\\trainer.py:1814\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1808\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m   1809\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs)\n\u001b[0;32m   1811\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   1812\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m   1813\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m-> 1814\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misinf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss_step\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1815\u001b[0m ):\n\u001b[0;32m   1816\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[0;32m   1817\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n\u001b[0;32m   1818\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["unfreeze(model)\n","parameter[\"lr\"] = parameter[\"lr\"] * parameter[\"lr_scale_unfreeze\"]\n","trainer=get_trainer(model, train_ds, valid_ds)\n","trainer.train()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","c:\\Users\\Bernd\\anaconda3\\envs\\mytorch\\lib\\site-packages\\transformers\\convert_slow_tokenizer.py:470: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n","  warnings.warn(\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"ename":"AttributeError","evalue":"'TokenClassifierOutput' object has no attribute 'argmax'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mcreate_submission\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msubmission.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n","Cell \u001b[1;32mIn[10], line 161\u001b[0m, in \u001b[0;36mcreate_submission\u001b[1;34m(model, filename)\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mid\u001b[39m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m    160\u001b[0m attention_mask\u001b[38;5;241m=\u001b[39mattention_mask\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m--> 161\u001b[0m preds\u001b[38;5;241m=\u001b[39m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmax\u001b[49m(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    162\u001b[0m all_preds\u001b[38;5;241m.\u001b[39mappend(preds)\n\u001b[0;32m    163\u001b[0m \u001b[38;5;66;03m#for pred, id in zip(preds.flatten(), id.flatten()):\u001b[39;00m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;66;03m#    if pred != 12:\u001b[39;00m\n\u001b[0;32m    165\u001b[0m         \u001b[38;5;66;03m#print(f\"Document: {document_id.item()} TOKEN:{tokenizer.decode(id)}  --- pred:{id2label[pred.item()]}\")\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;66;03m#    if pred != 12:\u001b[39;00m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;66;03m#        print(f\"TOKEN:{tokenizer.decode(id)}  --- pred:{id2label[pred.item()]}\")\u001b[39;00m\n","\u001b[1;31mAttributeError\u001b[0m: 'TokenClassifierOutput' object has no attribute 'argmax'"]}],"source":["create_submission(model, f\"submission.csv\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"databundleVersionId":7500999,"sourceId":66653,"sourceType":"competition"},{"datasetId":4319117,"sourceId":7429898,"sourceType":"datasetVersion"}],"dockerImageVersionId":30636,"isGpuEnabled":true,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
