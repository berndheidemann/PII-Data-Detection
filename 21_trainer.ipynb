{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["from transformers import AutoTokenizer, TrainingArguments, Trainer, AutoModelForTokenClassification\n","from pathlib import Path\n","import numpy as np\n","import torch\n","from tokenizers import AddedToken\n","from tqdm.notebook import tqdm\n","from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n","import pandas as pd\n","from seqeval.metrics import recall_score, precision_score, f1_score, accuracy_score\n","from datasets import Dataset\n","\n","\n","\n","\n","kaggle=False\n","\n","path=\"/kaggle/input/pii-detection-removal-from-educational-data\" if kaggle else \"data\"\n","train_path = path + \"/train.json\"\n","test_path = path + \"/test.json\"\n","\n","model_path = \"/kaggle/input/huggingfacedebertav3variants/deberta-v3-base\" if kaggle else \"microsoft/deberta-v3-base\"\n","\n","\n","if not kaggle: import neptune\n"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-01-25T21:37:35.578114Z","iopub.status.busy":"2024-01-25T21:37:35.577723Z","iopub.status.idle":"2024-01-25T21:37:35.587366Z","shell.execute_reply":"2024-01-25T21:37:35.5858Z","shell.execute_reply.started":"2024-01-25T21:37:35.578083Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["{'model': 'microsoft/deberta-v3-base', 'max_length': 1024, 'inference_max_length': 2000, 'batch_size': 4, 'inference_batch_size': 1, 'lr': 0.001, 'lr_scale_unfreeze': 0.1, 'filter_no_pii_percent_allow': 0.2, 'notebook': '20_deberta base_1024len.ipynb', 'CROSS_ENTROPY_WEIGHT_MULTI': 400, 'epochs_before_unfreeze': 4, 'epochs_after_unfreeze': 6, 'repeat_unfreeze_train_n_times': 2, 'validate_every_n_epochs': 2, 'train_test_split': 0.2, 'num_proc': 16, 'freeze_embeddings': False, 'freeze_layers': 6}\n"]}],"source":["cross_entropy_weight_multi = 400\n","\n","CROSS_ENTROPY_WEIGHTS = [cross_entropy_weight_multi]*12\n","CROSS_ENTROPY_WEIGHTS.append(1)\n","\n","parameter= {\n","    \"model\": model_path,\n","    \"max_length\": 1024,\n","    \"inference_max_length\": 2000,\n","    \"batch_size\": 4,\n","    \"inference_batch_size\": 1,\n","    \"lr\": 1e-3,\n","    \"lr_scale_unfreeze\": 0.1,\n","    \"filter_no_pii_percent_allow\": 0.2,\n","    \"notebook\": \"20_deberta base_1024len.ipynb\",\n","    \"CROSS_ENTROPY_WEIGHT_MULTI\": cross_entropy_weight_multi,\n","    \"epochs_before_unfreeze\": 4,\n","    \"epochs_after_unfreeze\": 6,\n","    \"repeat_unfreeze_train_n_times\": 2,\n","    \"validate_every_n_epochs\": 2,\n","    \"train_test_split\": 0.2,\n","    \"num_proc\": 16, \n","    \"freeze_embeddings\": False,\n","    \"freeze_layers\": 6\n","}\n","\n","print(parameter)"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["target = [\n","    'B-EMAIL', 'B-ID_NUM', 'B-NAME_STUDENT', 'B-PHONE_NUM', \n","    'B-STREET_ADDRESS', 'B-URL_PERSONAL', 'B-USERNAME', 'I-ID_NUM', \n","    'I-NAME_STUDENT', 'I-PHONE_NUM', 'I-STREET_ADDRESS', 'I-URL_PERSONAL'\n","]"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-01-25T21:37:35.606208Z","iopub.status.busy":"2024-01-25T21:37:35.605889Z","iopub.status.idle":"2024-01-25T21:37:35.62164Z","shell.execute_reply":"2024-01-25T21:37:35.620746Z","shell.execute_reply.started":"2024-01-25T21:37:35.606175Z"},"trusted":true},"outputs":[],"source":["from itertools import chain\n","import json\n","\n","data = json.load(open(train_path))\n","all_labels = sorted(list(set(chain(*[x[\"labels\"] for x in data]))))\n","label2id = {l: i for i,l in enumerate(all_labels)}\n","id2label = {v:k for k,v in label2id.items()}"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["import random\n","\n","def tokenize(example, tokenizer, label2id, max_length, all_labels_list):\n","    text = []\n","    import numpy as np\n","\n","    # these are at the character level\n","    labels = []\n","    targets = []\n","\n","    for t, l, ws in zip(example[\"tokens\"], example[\"labels\"], example[\"trailing_whitespace\"]):\n","\n","        text.append(t)\n","        labels.extend([l]*len(t))\n","        \n","        if l in all_labels_list:\n","            targets.append(1)\n","        else:\n","            targets.append(0)\n","        # if there is trailing whitespace\n","        if ws:\n","            text.append(\" \")\n","            labels.append(\"O\")\n","\n","    tokenized = tokenizer(\"\".join(text), return_offsets_mapping=True, truncation=True, max_length=max_length, padding=\"max_length\")\n","    \n","    target_num = sum(targets)\n","    labels = np.array(labels)\n","\n","    text = \"\".join(text)\n","    token_labels = []\n","\n","    for start_idx, end_idx in tokenized.offset_mapping:\n","\n","        # CLS token\n","        if start_idx == 0 and end_idx == 0: \n","            token_labels.append(label2id[\"O\"])\n","            continue\n","\n","        # case when token starts with whitespace\n","        if text[start_idx].isspace():\n","            start_idx += 1\n","\n","        try:\n","            token_labels.append(label2id[labels[start_idx]])\n","        except:\n","            token_labels.append(label2id[\"O\"])\n","\n","    length = len(tokenized.input_ids)\n","\n","    return {\n","        **tokenized,\n","        \"labels\": token_labels,\n","        \"length\": length,\n","        \"target_num\": target_num,\n","        \"group\": 1 if target_num>0 else 0\n","    }\n","\n","# https://www.kaggle.com/competitions/pii-detection-removal-from-educational-data/discussion/468844\n","def filter_no_pii(example, percent_allow=parameter[\"filter_no_pii_percent_allow\"]):\n","    # Return True if there is PII\n","    # Or 20% of the time if there isn't\n","    has_pii = set(\"O\") != set(example[\"labels\"])\n","    return has_pii or (random.random() < percent_allow)"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["dict_keys(['document', 'full_text', 'tokens', 'trailing_whitespace', 'labels'])\n"]},{"name":"stderr","output_type":"stream","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","c:\\Users\\Bernd\\anaconda3\\envs\\mytorch\\lib\\site-packages\\transformers\\convert_slow_tokenizer.py:470: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n","  warnings.warn(\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4b8e59f3cf604fdf815a8140ab607b6c","version_major":2,"version_minor":0},"text/plain":["Map (num_proc=16):   0%|          | 0/6807 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["class PiiDataset(torch.utils.data.Dataset):\n","    def __init__(self, ds):\n","        self.dataset = ds\n","        \n","    def __getitem__(self, idx):\n","        vals=self.dataset[idx]\n","        input_ids = torch.tensor(vals[\"input_ids\"])\n","        attention_mask = torch.tensor(vals[\"attention_mask\"])\n","        labels = torch.tensor(vals[\"labels\"], dtype=torch.long)\n","        return input_ids, attention_mask, labels\n","    \n","    def __len__(self):\n","        return len(self.dataset)\n","\n","data = json.load(open(train_path))\n","print(data[0].keys())\n","ds = Dataset.from_dict({\n","    \"full_text\": [x[\"full_text\"] for x in data],\n","    \"document\": [str(x[\"document\"]) for x in data],\n","    \"tokens\": [x[\"tokens\"] for x in data],\n","    \"trailing_whitespace\": [x[\"trailing_whitespace\"] for x in data],\n","    \"labels\": [x[\"labels\"] for x in data],\n","})\n","    \n","tokenizer = AutoTokenizer.from_pretrained(parameter[\"model\"])\n","ds = ds.map(tokenize, fn_kwargs={\"tokenizer\": tokenizer, \"label2id\": label2id, \"max_length\": parameter[\"max_length\"], \"all_labels_list\": target}, num_proc=parameter[\"num_proc\"])\n","\n","my_dataset=PiiDataset(ds)\n","\n"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([8, 1024])\n","torch.Size([8, 1024])\n","torch.Size([8, 1024])\n"]}],"source":["loader=torch.utils.data.DataLoader(my_dataset, batch_size=8, shuffle=True)\n","\n","for id, attention_mask, labels in loader:\n","    print(id.shape)\n","    print(attention_mask.shape)\n","    print(labels.shape)\n","    break"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of DebertaV2ForTokenClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"name":"stdout","output_type":"stream","text":["torch.Size([8, 1024])\n","torch.Size([8, 1024])\n","torch.Size([8, 1024])\n","tensor([[12, 12, 12,  ..., 12, 12, 12],\n","        [12, 12, 12,  ..., 12, 12, 12],\n","        [12, 12, 12,  ..., 12, 12, 12],\n","        ...,\n","        [12, 12, 12,  ..., 12, 12, 12],\n","        [12, 12, 12,  ..., 12, 12, 12],\n","        [12, 12, 12,  ..., 12, 12, 12]])\n","torch.Size([8, 1024, 13])\n"]}],"source":["device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","class MyModel(torch.nn.Module):\n","    def __init__(self, model_name, num_labels, dropout_p=0.4):\n","        super().__init__()\n","        self.model = AutoModelForTokenClassification.from_pretrained(model_name, num_labels=num_labels, id2label=id2label,\n","    label2id=label2id,\n","    ignore_mismatched_sizes=True)\n","        self.softmax=torch.nn.Softmax(dim=-1)\n","        self.freeze()\n","\n","    def freeze(self):\n","        if parameter['freeze_embeddings']:\n","            for param in self.model.deberta.embeddings.parameters():\n","                param.requires_grad = False\n","                \n","        if parameter['freeze_layers'] > 0:\n","            for layer in self.model.deberta.encoder.layer[:parameter['freeze_layers']]:\n","                for param in layer.parameters():\n","                    param.requires_grad = False\n","\n","    def unfreeze(self):\n","        for param in self.model.parameters():\n","            param.requires_grad = True\n","        \n","    def forward(self, input_ids, attention_mask, labels=None):\n","        if labels is not None:\n","            out=self.model(input_ids, attention_mask=attention_mask, labels=labels)['logits']\n","        else:\n","            out=self.model(input_ids, attention_mask=attention_mask)['logits']\n","        out=self.softmax(out)\n","        return out\n","\n","model = MyModel(parameter[\"model\"], len(label2id))\n","\n","model= model.to(device)\n","for id, attention_mask, labels in loader:\n","    print(id.shape)\n","    print(attention_mask.shape)\n","    print(labels.shape)\n","    print(labels)\n","    id = id.to(device)\n","    attention_mask = attention_mask.to(device)\n","    labels = labels.to(device)\n","    print(model(id, attention_mask, labels).shape)\n","    break\n","\n","#free gpu memory\n","del model\n","torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"data":{"text/plain":["{'model': 'microsoft/deberta-v3-base',\n"," 'max_length': 1024,\n"," 'inference_max_length': 2000,\n"," 'batch_size': 4,\n"," 'inference_batch_size': 1,\n"," 'lr': 0.001,\n"," 'lr_scale_unfreeze': 0.1,\n"," 'filter_no_pii_percent_allow': 0.2,\n"," 'notebook': '20_deberta base_1024len.ipynb',\n"," 'CROSS_ENTROPY_WEIGHT_MULTI': 400,\n"," 'epochs_before_unfreeze': 4,\n"," 'epochs_after_unfreeze': 6,\n"," 'repeat_unfreeze_train_n_times': 2,\n"," 'validate_every_n_epochs': 2,\n"," 'train_test_split': 0.2,\n"," 'num_proc': 16,\n"," 'freeze_embeddings': False,\n"," 'freeze_layers': 6}"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["parameter"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"name":"stdout","output_type":"stream","text":["    row_id  document  token           label\n","0        0         7      9  B-NAME_STUDENT\n","1        1         7     10  I-NAME_STUDENT\n","2        2         7    482  B-NAME_STUDENT\n","3        3         7    483  I-NAME_STUDENT\n","4        4         7    741  B-NAME_STUDENT\n","5        5         7    742  I-NAME_STUDENT\n","6        6        10      0  B-NAME_STUDENT\n","7        7        10      1  I-NAME_STUDENT\n","8        8        10    464  B-NAME_STUDENT\n","9        9        10    465  I-NAME_STUDENT\n","10      10        16      4  B-NAME_STUDENT\n","11      11        16      5  I-NAME_STUDENT\n","12      12        20      5  B-NAME_STUDENT\n","13      13        20      6  I-NAME_STUDENT\n","14      14        56     12  B-NAME_STUDENT\n","15      15        56     13  I-NAME_STUDENT\n","16      16        86      6  B-NAME_STUDENT\n","17      17        86      7  I-NAME_STUDENT\n","18      18        93      0  B-NAME_STUDENT\n","19      19        93      1  I-NAME_STUDENT\n","20      20       104      8  B-NAME_STUDENT\n","21      21       104      9  I-NAME_STUDENT\n","22      22       112      5  B-NAME_STUDENT\n","23      23       112      6  I-NAME_STUDENT\n","24      24       123     32  B-NAME_STUDENT\n","25      25       123     33  I-NAME_STUDENT\n","26      26       123   1549        B-ID_NUM\n","27      27       123   1575        B-ID_NUM\n"]}],"source":["def tokenize_inference(example, tokenizer, max_length):\n","        text = []\n","        for t,  ws in zip(example[\"tokens\"], example[\"trailing_whitespace\"]):\n","            text.append(t)\n","            if ws:\n","                text.append(\" \")\n","        tokenized = tokenizer(\"\".join(text), return_offsets_mapping=True, truncation=True, max_length=max_length, padding=\"max_length\")\n","        text = \"\".join(text)\n","        length = len(tokenized.input_ids)\n","        return {\n","            **tokenized,\n","            \"length\": length,\n","        }\n","        \n","class TestTokenizer():\n","    def __init__(self, tokenizer):\n","        self.tokenizer = tokenizer\n","    \n","    def preprocess(self, example):\n","        # Preprocess the tokens and labels by adding trailing whitespace and labels\n","        tokens = []\n","        tokens_without_ws = []\n","        token_map = [] # Use the index as labels\n","        index = 0\n","        for token, t_ws in zip(example[\"tokens\"], example[\"trailing_whitespace\"]):\n","            tokens_without_ws.append(token)\n","            tokens.append(token)\n","            token_map.extend([index] * len(token))\n","            # Added trailing whitespace and label if true and \n","            if t_ws:\n","                tokens.append(\" \")\n","                token_map.append(-1)\n","            index += 1\n","        return tokens, token_map, tokens_without_ws\n","    \n","    def tokenize(self, example):\n","        tokens, token_map, tokens_without_ws = self.preprocess(example)\n","        text = \"\".join(tokens)\n","        tokenized = self.tokenizer(text, return_offsets_mapping=True, padding=\"max_length\",\n","                                   truncation=True, max_length=parameter[\"inference_max_length\"])\n","        return {**tokenized, \"token_map\": token_map, \"tokens\": tokens, \"tokens_without_ws\": tokens_without_ws} \n","\n","class PiiDatasetInference(torch.utils.data.Dataset):\n","        def __init__(self, dataset, tokenizer):\n","            self.dataset = dataset\n","            self.tokenizer=TestTokenizer(tokenizer)\n","            \n","        def __getitem__(self, idx):\n","            vals=self.tokenizer.tokenize(self.dataset[idx])\n","            input_ids = torch.tensor(vals[\"input_ids\"])\n","            attention_mask = torch.tensor(vals[\"attention_mask\"])\n","            document_id = self.dataset[idx][\"document\"]\n","            return input_ids, attention_mask, document_id, vals\n","        \n","        def __len__(self):\n","            return len(self.dataset)\n","\n","def inference(model):\n","    data = json.load(open(train_path))\n","    from itertools import chain\n","    all_labels = sorted(list(set(chain(*[x[\"labels\"] for x in data]))))\n","    label2id = {l: i for i,l in enumerate(all_labels)}\n","    id2label = {v:k for k,v in label2id.items()}\n","\n","    tokenizer = AutoTokenizer.from_pretrained(parameter[\"model\"])\n","    data = json.load(open(test_path))\n","    my_dataset=PiiDatasetInference(data, tokenizer)\n","    loader=torch.utils.data.DataLoader(my_dataset, batch_size=parameter['batch_size'])\n","    for id, attention_mask, document_id, vals  in loader:\n","        id = id.to(device)\n","        print(id.shape)\n","        attention_mask = attention_mask.to(device)\n","        preds=model(id, attention_mask).argmax(dim=2)\n","\n","        for pred, id in zip(preds.flatten(), id.flatten()):\n","            if pred != 12:\n","                print(f\"TOKEN:{tokenizer.decode(id)}  --- pred:{id2label[pred.item()]}\")\n","        print(\"next\")\n","\n","# Convert preds to a list of dictionaries\n","def to_test_submission(preds=None, dataset=None, document_ids=None, id2label=None):\n","    triplets = []\n","    row_id = 0\n","    results = []\n","    \n","    for i in range(len(preds)):\n","        input_ids, attention_mask, document_id, vals = dataset[i]\n","        token_map=vals[\"token_map\"]\n","        offsets=vals[\"offset_mapping\"]\n","        tokens=vals[\"tokens_without_ws\"]\n","        #print(\"tokens\", tokens)\n","        pred=preds[i]\n","        original_text = tokenizer.decode(input_ids)[6:] # skip CLS token\n","        #print(\"original_text\", original_text)\n","        #print(\"token_map\", token_map)\n","        #print(\"offsets\", offsets)   \n","        #print(\"pred\", pred)\n","\n","        for token_pred, input_id, (start_idx, end_idx) in zip(pred, input_ids, offsets):\n","            #print(\"\\nnow doing \", start_idx,  end_idx, token_pred)\n","            if start_idx == 0 and end_idx == 0: # Skip 0 offset\n","                continue\n","            # Skip spaces \n","            while start_idx < len(token_map):\n","                #print(\"loop, start_idx now\", start_idx) \n","                #print(\" tokens[token_map[start_idx]]: \", tokens[token_map[start_idx]] if not tokens[token_map[start_idx]].isspace() else \"WHITESPACE\")          \n","                if token_map[start_idx] == -1: # Skip unknown tokens               \n","                    start_idx += 1\n","                elif tokens[token_map[start_idx]].isspace(): # Skip white space\n","                    start_idx += 1\n","                else:\n","                    break\n","            # Ensure start index < length\n","            if start_idx < len(token_map):\n","                token_id = token_map[start_idx]\n","                #print(\"token_id\", token_id)\n","                #token_id= input_id.item()\n","                label_pred = id2label[token_pred.item()]\n","                #print(\"label_pred\", label_pred)\n","                # ignore \"O\" and whitespace preds\n","                if label_pred != \"O\" and token_id != -1:\n","                    #print(\"is PII\", token_id, label_pred)\n","                    token_str = tokens[token_id]\n","                    triplet = (label_pred, token_id, token_str)\n","                    if triplet not in triplets:\n","                        results.append({\n","                            \"row_id\": row_id, \n","                            \"document\": document_id,\n","                            \"token\": token_id, \n","                            \"label\": label_pred,\n","                            \"token_str\": token_str\n","                        })\n","                        triplets.append(triplet)\n","                        row_id += 1\n","\n","    # Create a dataframe \n","    return results\n","\n","def create_submission(model, filename=\"submission.csv\"):\n","    data = json.load(open(train_path))\n","    from itertools import chain\n","    all_labels = sorted(list(set(chain(*[x[\"labels\"] for x in data]))))\n","    label2id = {l: i for i,l in enumerate(all_labels)}\n","    id2label = {v:k for k,v in label2id.items()}\n","\n","    data=json.load(open(test_path))\n","    tokenizer = AutoTokenizer.from_pretrained(parameter[\"model\"])\n","    my_dataset=PiiDatasetInference(data, tokenizer)\n","    loader=torch.utils.data.DataLoader(my_dataset, batch_size=1, shuffle=False)\n","\n","    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    model.eval()\n","    \n","\n","    # stack all predictions into tensor\n","    all_preds = []\n","\n","    for id, attention_mask, document_ids, vals in loader:\n","        id=id.to(device)\n","        attention_mask=attention_mask.to(device)\n","        preds=model(id, attention_mask).get('logits').argmax(dim=2)\n","        all_preds.append(preds)\n","        #for pred, id in zip(preds.flatten(), id.flatten()):\n","        #    if pred != 12:\n","                #print(f\"Document: {document_id.item()} TOKEN:{tokenizer.decode(id)}  --- pred:{id2label[pred.item()]}\")\n","        #        output[row_id]={\"document\":document_id.item(), \"token\":id.item(), \"label\":id2label[pred.item()]}\n","        #        row_id+=1\n","        #for pred, id in zip(preds.flatten(), id.flatten()):\n","        #    if pred != 12:\n","        #        print(f\"TOKEN:{tokenizer.decode(id)}  --- pred:{id2label[pred.item()]}\")\n","    \n","   \n","    all_preds = torch.cat(all_preds, dim=0)\n","    \n","    results = to_test_submission(preds=all_preds, dataset=my_dataset, document_ids=document_ids, id2label=id2label)\n","    if len(results) == 0:\n","        print(\"Error in create_submission(): No predictions made, probably because the model is not learning. Check the model and the data.\")\n","        return\n","    df = pd.DataFrame(results)\n","    df=df[[\"row_id\", \"document\", \"token\", \"label\"]]\n","    print(df)\n","    df.to_csv(filename, index=False)\n","\n","#create_submission(MyModel(parameter['model'], len(label2id)).to(device), \"submission_just_dumb.csv\")\n","create_submission(model, \"submission.csv\")\n"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","c:\\Users\\Bernd\\anaconda3\\envs\\mytorch\\lib\\site-packages\\transformers\\convert_slow_tokenizer.py:470: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n","  warnings.warn(\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f6db47d104ac4a3ea550be14ff40b15c","version_major":2,"version_minor":0},"text/plain":["Map (num_proc=16):   0%|          | 0/6807 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5e84987e64c14f2382170b3e606ad734","version_major":2,"version_minor":0},"text/plain":["Filter (num_proc=16):   0%|          | 0/6807 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["train_len 5445\n","valid_len 1362\n"]}],"source":["data = json.load(open(train_path))\n","ds = Dataset.from_dict({\n","    \"full_text\": [x[\"full_text\"] for x in data],\n","    \"document\": [str(x[\"document\"]) for x in data],\n","    \"tokens\": [x[\"tokens\"] for x in data],\n","    \"trailing_whitespace\": [x[\"trailing_whitespace\"] for x in data],\n","    \"labels\": [x[\"labels\"] for x in data],\n","})\n","    \n","tokenizer = AutoTokenizer.from_pretrained(parameter[\"model\"])\n","ds = ds.map(tokenize, fn_kwargs={\"tokenizer\": tokenizer, \"label2id\": label2id, \"max_length\": parameter[\"max_length\"], \"all_labels_list\": target}, num_proc=parameter[\"num_proc\"])\n","ds=ds.filter(filter_no_pii, num_proc=parameter[\"num_proc\"])\n","\n","\n","data_len=len(ds)\n","train_len=int(len(ds)*(1-parameter[\"train_test_split\"]))\n","valid_len=len(ds)-train_len\n","train_data_idx=np.random.choice(data_len, train_len, replace=False)\n","valid_data_idx=np.array(list(set(range(data_len))-set(train_data_idx)))\n","print(\"train_len\", train_len)\n","print(\"valid_len\", valid_len)\n","\n","# split ds in train and valid\n","train_ds=ds.select(train_data_idx)\n","valid_ds=ds.select(valid_data_idx)\n","\n"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["from transformers import DataCollatorForTokenClassification\n","\n","collator = DataCollatorForTokenClassification(tokenizer, pad_to_multiple_of=16)"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\Bernd\\anaconda3\\envs\\mytorch\\lib\\site-packages\\neptune\\common\\warnings.py:71: NeptuneWarning: The following monitoring options are disabled by default in interactive sessions: 'capture_stdout', 'capture_stderr', 'capture_traceback', and 'capture_hardware_metrics'. To enable them, set each parameter to 'True' when initializing the run. The monitoring will continue until you call run.stop() or the kernel stops. Also note: Your source files can only be tracked if you pass the path(s) to the 'source_code' argument. For help, see the Neptune docs: https://docs.neptune.ai/logging/source_code/\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["https://app.neptune.ai/bernd.heidemann/PII/e/PII-212\n"]}],"source":["# using Trainer and TrainingArguments from transformers\n","\n","from transformers.integrations import NeptuneCallback\n","\n","def compute_metrics(p, all_labels):\n","    predictions, labels = p\n","    predictions = np.argmax(predictions, axis=2)\n","\n","    # Remove ignored index (special tokens)\n","    true_predictions = [\n","        [all_labels[p] for (p, l) in zip(prediction, label) if l != -100]\n","        for prediction, label in zip(predictions, labels)\n","    ]\n","    true_labels = [\n","        [all_labels[l] for (p, l) in zip(prediction, label) if l != -100]\n","        for prediction, label in zip(predictions, labels)\n","    ]\n","    \n","    recall = recall_score(true_labels, true_predictions)\n","    precision = precision_score(true_labels, true_predictions)\n","    f1_score = (1 + 5*5) * recall * precision / (5*5*precision + recall)\n","    \n","    results = {\n","        'recall': recall,\n","        'precision': precision,\n","        'f1': f1_score\n","    }\n","    return results\n","\n","\n","run = neptune.init_run(\n","    project=\"bernd.heidemann/PII\",\n","    api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiIzNjBlYzVkNi0zZTUwLTQ1ODYtODhlNC02NDUxNDg0MDdjNzUifQ==\",\n",")  # your credentials\n","run[\"parameters\"] = {\n","**parameter\n","}\n","\n","neptune_callback = NeptuneCallback(run=run, log_model_weights=False, log_parameters=False)\n","from functools import partial\n","from torch.nn import CrossEntropyLoss\n","\n","def get_trainer(model, train_dataloader, valid_dataloader):\n","    training_args = TrainingArguments(\n","        output_dir='./results',          # output directory\n","        num_train_epochs=parameter[\"epochs_before_unfreeze\"],              # total number of training epochs\n","        per_device_train_batch_size=parameter[\"batch_size\"],  # batch size per device during training\n","        per_device_eval_batch_size=parameter[\"inference_batch_size\"],   # batch size for evaluation\n","        warmup_steps=500,                # number of warmup steps for learning rate scheduler\n","        weight_decay=0.01,               # strength of weight decay\n","        logging_dir='./logs',            # directory for storing logs\n","        logging_steps=10,\n","        evaluation_strategy=\"steps\",\n","        eval_steps=1000,\n","        save_steps=5000,\n","        save_total_limit=2,\n","        load_best_model_at_end=True,\n","        metric_for_best_model=\"f1\",\n","        greater_is_better=True,\n","        overwrite_output_dir=True,\n","        report_to=\"none\"\n","        #callback for neptune\n","    )\n","\n","    class MyTrainer(Trainer):\n","        def __init__(self, model=None, args=None, train_dataset=None, eval_dataset=None, compute_metrics=None, callbacks=None):\n","            super().__init__(model=model, args=args, train_dataset=train_dataset, eval_dataset=eval_dataset, compute_metrics=compute_metrics, callbacks=callbacks)\n","            # Definieren Sie hier Ihre Gewichte fÃ¼r die Klassen, z.B. torch.tensor([1.0, 2.0, 0.5])\n","            self.weight = torch.tensor(CROSS_ENTROPY_WEIGHTS).to(device)\n","            self.loss_func=torch.nn.CrossEntropyLoss(ignore_index=-100, weight=torch.tensor(CROSS_ENTROPY_WEIGHTS, dtype=torch.float32).to(device))\n","\n","        def compute_loss(self, model, inputs, return_outputs=False):\n","            labels = inputs.get(\"labels\")\n","            outputs = model(**inputs)\n","            logits = outputs.get('logits')\n","            loss = self.loss_func(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n","            return (loss, outputs) if return_outputs else loss\n","\n","    trainer = MyTrainer(\n","        model=model,                         # the instantiated ðŸ¤— Transformers model to be trained\n","        args=training_args,                  # training arguments, defined above\n","        train_dataset=train_dataloader,         # training dataset\n","        eval_dataset=valid_dataloader,             # evaluation dataset\n","        compute_metrics=partial(compute_metrics, all_labels=all_labels),\n","        callbacks=[neptune_callback]\n","    )\n","    return trainer"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","Some weights of DebertaV2ForTokenClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"name":"stdout","output_type":"stream","text":["DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"B-EMAIL\",\n","    \"1\": \"B-ID_NUM\",\n","    \"2\": \"B-NAME_STUDENT\",\n","    \"3\": \"B-PHONE_NUM\",\n","    \"4\": \"B-STREET_ADDRESS\",\n","    \"5\": \"B-URL_PERSONAL\",\n","    \"6\": \"B-USERNAME\",\n","    \"7\": \"I-ID_NUM\",\n","    \"8\": \"I-NAME_STUDENT\",\n","    \"9\": \"I-PHONE_NUM\",\n","    \"10\": \"I-STREET_ADDRESS\",\n","    \"11\": \"I-URL_PERSONAL\",\n","    \"12\": \"O\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"B-EMAIL\": 0,\n","    \"B-ID_NUM\": 1,\n","    \"B-NAME_STUDENT\": 2,\n","    \"B-PHONE_NUM\": 3,\n","    \"B-STREET_ADDRESS\": 4,\n","    \"B-URL_PERSONAL\": 5,\n","    \"B-USERNAME\": 6,\n","    \"I-ID_NUM\": 7,\n","    \"I-NAME_STUDENT\": 8,\n","    \"I-PHONE_NUM\": 9,\n","    \"I-STREET_ADDRESS\": 10,\n","    \"I-URL_PERSONAL\": 11,\n","    \"O\": 12\n","  },\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.31.0\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\Bernd\\anaconda3\\envs\\mytorch\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c3adb79bfc99450cac1f2a46312473b6","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/5448 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'loss': 2.4254, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.01}\n","{'loss': 2.3065, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.01}\n","{'loss': 2.1029, 'learning_rate': 3e-06, 'epoch': 0.02}\n","{'loss': 1.8207, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.03}\n","{'loss': 1.6205, 'learning_rate': 5e-06, 'epoch': 0.04}\n","{'loss': 1.0979, 'learning_rate': 6e-06, 'epoch': 0.04}\n","{'loss': 0.5702, 'learning_rate': 7.000000000000001e-06, 'epoch': 0.05}\n","{'loss': 0.7246, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.06}\n","{'loss': 0.2169, 'learning_rate': 9e-06, 'epoch': 0.07}\n","{'loss': 0.4508, 'learning_rate': 1e-05, 'epoch': 0.07}\n","{'loss': 0.1627, 'learning_rate': 1.1000000000000001e-05, 'epoch': 0.08}\n","{'loss': 0.2357, 'learning_rate': 1.2e-05, 'epoch': 0.09}\n","{'loss': 0.7856, 'learning_rate': 1.3000000000000001e-05, 'epoch': 0.1}\n","{'loss': 0.1613, 'learning_rate': 1.4000000000000001e-05, 'epoch': 0.1}\n","{'loss': 0.0486, 'learning_rate': 1.5e-05, 'epoch': 0.11}\n","{'loss': 0.6389, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.12}\n","{'loss': 0.1033, 'learning_rate': 1.7000000000000003e-05, 'epoch': 0.12}\n","{'loss': 0.0962, 'learning_rate': 1.8e-05, 'epoch': 0.13}\n","{'loss': 0.2669, 'learning_rate': 1.9e-05, 'epoch': 0.14}\n","{'loss': 0.1884, 'learning_rate': 2e-05, 'epoch': 0.15}\n","{'loss': 0.0358, 'learning_rate': 2.1e-05, 'epoch': 0.15}\n","{'loss': 0.4243, 'learning_rate': 2.2000000000000003e-05, 'epoch': 0.16}\n","{'loss': 0.811, 'learning_rate': 2.3000000000000003e-05, 'epoch': 0.17}\n","{'loss': 0.0243, 'learning_rate': 2.4e-05, 'epoch': 0.18}\n","{'loss': 0.0816, 'learning_rate': 2.5e-05, 'epoch': 0.18}\n","{'loss': 0.0092, 'learning_rate': 2.6000000000000002e-05, 'epoch': 0.19}\n","{'loss': 0.2049, 'learning_rate': 2.7000000000000002e-05, 'epoch': 0.2}\n","{'loss': 0.156, 'learning_rate': 2.8000000000000003e-05, 'epoch': 0.21}\n","{'loss': 0.1188, 'learning_rate': 2.9e-05, 'epoch': 0.21}\n","{'loss': 0.1726, 'learning_rate': 3e-05, 'epoch': 0.22}\n","{'loss': 0.0023, 'learning_rate': 3.1e-05, 'epoch': 0.23}\n","{'loss': 0.2396, 'learning_rate': 3.2000000000000005e-05, 'epoch': 0.23}\n","{'loss': 0.0546, 'learning_rate': 3.3e-05, 'epoch': 0.24}\n","{'loss': 0.004, 'learning_rate': 3.4000000000000007e-05, 'epoch': 0.25}\n","{'loss': 0.0035, 'learning_rate': 3.5e-05, 'epoch': 0.26}\n","{'loss': 0.207, 'learning_rate': 3.6e-05, 'epoch': 0.26}\n","{'loss': 0.0224, 'learning_rate': 3.7e-05, 'epoch': 0.27}\n","{'loss': 0.0138, 'learning_rate': 3.8e-05, 'epoch': 0.28}\n","{'loss': 0.0028, 'learning_rate': 3.9000000000000006e-05, 'epoch': 0.29}\n","{'loss': 0.3774, 'learning_rate': 4e-05, 'epoch': 0.29}\n","{'loss': 0.1704, 'learning_rate': 4.1e-05, 'epoch': 0.3}\n","{'loss': 0.008, 'learning_rate': 4.2e-05, 'epoch': 0.31}\n","{'loss': 0.0549, 'learning_rate': 4.3e-05, 'epoch': 0.32}\n","{'loss': 0.0644, 'learning_rate': 4.4000000000000006e-05, 'epoch': 0.32}\n","{'loss': 0.0493, 'learning_rate': 4.5e-05, 'epoch': 0.33}\n","{'loss': 0.0183, 'learning_rate': 4.600000000000001e-05, 'epoch': 0.34}\n","{'loss': 0.0353, 'learning_rate': 4.7e-05, 'epoch': 0.35}\n","{'loss': 0.0007, 'learning_rate': 4.8e-05, 'epoch': 0.35}\n","{'loss': 0.4409, 'learning_rate': 4.9e-05, 'epoch': 0.36}\n","{'loss': 0.2376, 'learning_rate': 5e-05, 'epoch': 0.37}\n","{'loss': 0.1198, 'learning_rate': 4.9898949070331455e-05, 'epoch': 0.37}\n","{'loss': 0.01, 'learning_rate': 4.979789814066289e-05, 'epoch': 0.38}\n","{'loss': 0.1262, 'learning_rate': 4.9696847210994345e-05, 'epoch': 0.39}\n","{'loss': 0.0477, 'learning_rate': 4.959579628132579e-05, 'epoch': 0.4}\n","{'loss': 0.7752, 'learning_rate': 4.949474535165724e-05, 'epoch': 0.4}\n","{'loss': 0.0114, 'learning_rate': 4.939369442198868e-05, 'epoch': 0.41}\n","{'loss': 0.0006, 'learning_rate': 4.9292643492320134e-05, 'epoch': 0.42}\n","{'loss': 0.0026, 'learning_rate': 4.919159256265158e-05, 'epoch': 0.43}\n","{'loss': 0.0826, 'learning_rate': 4.909054163298303e-05, 'epoch': 0.43}\n","{'loss': 0.0067, 'learning_rate': 4.898949070331447e-05, 'epoch': 0.44}\n","{'loss': 0.1724, 'learning_rate': 4.888843977364592e-05, 'epoch': 0.45}\n","{'loss': 0.4052, 'learning_rate': 4.878738884397737e-05, 'epoch': 0.46}\n","{'loss': 0.009, 'learning_rate': 4.868633791430881e-05, 'epoch': 0.46}\n","{'loss': 0.0793, 'learning_rate': 4.858528698464026e-05, 'epoch': 0.47}\n","{'loss': 0.1671, 'learning_rate': 4.848423605497171e-05, 'epoch': 0.48}\n","{'loss': 0.0462, 'learning_rate': 4.8383185125303156e-05, 'epoch': 0.48}\n","{'loss': 0.0029, 'learning_rate': 4.82821341956346e-05, 'epoch': 0.49}\n","{'loss': 0.0805, 'learning_rate': 4.818108326596605e-05, 'epoch': 0.5}\n","{'loss': 0.399, 'learning_rate': 4.80800323362975e-05, 'epoch': 0.51}\n","{'loss': 0.1792, 'learning_rate': 4.7978981406628945e-05, 'epoch': 0.51}\n","{'loss': 0.0612, 'learning_rate': 4.787793047696039e-05, 'epoch': 0.52}\n","{'loss': 0.012, 'learning_rate': 4.7776879547291835e-05, 'epoch': 0.53}\n","{'loss': 0.0273, 'learning_rate': 4.767582861762329e-05, 'epoch': 0.54}\n","{'loss': 0.0221, 'learning_rate': 4.757477768795473e-05, 'epoch': 0.54}\n","{'loss': 0.0464, 'learning_rate': 4.747372675828618e-05, 'epoch': 0.55}\n","{'loss': 0.0148, 'learning_rate': 4.7372675828617624e-05, 'epoch': 0.56}\n","{'loss': 0.0037, 'learning_rate': 4.7271624898949076e-05, 'epoch': 0.57}\n","{'loss': 0.0043, 'learning_rate': 4.717057396928052e-05, 'epoch': 0.57}\n","{'loss': 0.0028, 'learning_rate': 4.706952303961197e-05, 'epoch': 0.58}\n","{'loss': 0.373, 'learning_rate': 4.696847210994341e-05, 'epoch': 0.59}\n","{'loss': 0.0812, 'learning_rate': 4.6867421180274864e-05, 'epoch': 0.59}\n","{'loss': 0.012, 'learning_rate': 4.67663702506063e-05, 'epoch': 0.6}\n","{'loss': 0.0478, 'learning_rate': 4.6665319320937755e-05, 'epoch': 0.61}\n","{'loss': 0.0025, 'learning_rate': 4.65642683912692e-05, 'epoch': 0.62}\n","{'loss': 0.0945, 'learning_rate': 4.646321746160065e-05, 'epoch': 0.62}\n","{'loss': 0.032, 'learning_rate': 4.636216653193209e-05, 'epoch': 0.63}\n","{'loss': 0.001, 'learning_rate': 4.6261115602263544e-05, 'epoch': 0.64}\n","{'loss': 0.0207, 'learning_rate': 4.616006467259499e-05, 'epoch': 0.65}\n","{'loss': 0.0062, 'learning_rate': 4.6059013742926435e-05, 'epoch': 0.65}\n","{'loss': 0.0905, 'learning_rate': 4.595796281325788e-05, 'epoch': 0.66}\n","{'loss': 0.0084, 'learning_rate': 4.585691188358933e-05, 'epoch': 0.67}\n","{'loss': 0.1854, 'learning_rate': 4.575586095392078e-05, 'epoch': 0.68}\n","{'loss': 0.004, 'learning_rate': 4.565481002425222e-05, 'epoch': 0.68}\n","{'loss': 0.0305, 'learning_rate': 4.555375909458367e-05, 'epoch': 0.69}\n","{'loss': 0.0217, 'learning_rate': 4.545270816491512e-05, 'epoch': 0.7}\n","{'loss': 0.0199, 'learning_rate': 4.5351657235246566e-05, 'epoch': 0.7}\n","{'loss': 0.0126, 'learning_rate': 4.525060630557801e-05, 'epoch': 0.71}\n","{'loss': 0.0036, 'learning_rate': 4.514955537590946e-05, 'epoch': 0.72}\n","{'loss': 0.1965, 'learning_rate': 4.504850444624091e-05, 'epoch': 0.73}\n","{'loss': 0.0269, 'learning_rate': 4.4947453516572354e-05, 'epoch': 0.73}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3cd4fd5d37ee4a348999d47cff68464a","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1362 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.03185591101646423, 'eval_recall': 0.8960280373831776, 'eval_precision': 0.37341772151898733, 'eval_f1': 0.8502600835678351, 'eval_runtime': 43.7415, 'eval_samples_per_second': 31.137, 'eval_steps_per_second': 31.137, 'epoch': 0.73}\n","{'loss': 0.1881, 'learning_rate': 4.48464025869038e-05, 'epoch': 0.74}\n","{'loss': 0.303, 'learning_rate': 4.4745351657235245e-05, 'epoch': 0.75}\n","{'loss': 0.0492, 'learning_rate': 4.46443007275667e-05, 'epoch': 0.76}\n","{'loss': 0.1303, 'learning_rate': 4.454324979789814e-05, 'epoch': 0.76}\n","{'loss': 0.0036, 'learning_rate': 4.444219886822959e-05, 'epoch': 0.77}\n","{'loss': 0.0185, 'learning_rate': 4.434114793856104e-05, 'epoch': 0.78}\n","{'loss': 0.0315, 'learning_rate': 4.4240097008892486e-05, 'epoch': 0.79}\n","{'loss': 0.0069, 'learning_rate': 4.413904607922393e-05, 'epoch': 0.79}\n","{'loss': 0.0783, 'learning_rate': 4.403799514955538e-05, 'epoch': 0.8}\n","{'loss': 0.0107, 'learning_rate': 4.393694421988683e-05, 'epoch': 0.81}\n","{'loss': 0.2209, 'learning_rate': 4.3835893290218274e-05, 'epoch': 0.81}\n","{'loss': 0.0062, 'learning_rate': 4.373484236054972e-05, 'epoch': 0.82}\n","{'loss': 0.3034, 'learning_rate': 4.3633791430881165e-05, 'epoch': 0.83}\n","{'loss': 0.0105, 'learning_rate': 4.353274050121262e-05, 'epoch': 0.84}\n","{'loss': 0.1643, 'learning_rate': 4.343168957154406e-05, 'epoch': 0.84}\n","{'loss': 0.0026, 'learning_rate': 4.333063864187551e-05, 'epoch': 0.85}\n","{'loss': 0.0104, 'learning_rate': 4.3229587712206954e-05, 'epoch': 0.86}\n","{'loss': 0.0081, 'learning_rate': 4.3128536782538406e-05, 'epoch': 0.87}\n","{'loss': 0.002, 'learning_rate': 4.3027485852869844e-05, 'epoch': 0.87}\n","{'loss': 0.0942, 'learning_rate': 4.29264349232013e-05, 'epoch': 0.88}\n","{'loss': 0.0069, 'learning_rate': 4.282538399353274e-05, 'epoch': 0.89}\n","{'loss': 0.3186, 'learning_rate': 4.2724333063864194e-05, 'epoch': 0.9}\n","{'loss': 0.7576, 'learning_rate': 4.262328213419563e-05, 'epoch': 0.9}\n","{'loss': 0.0441, 'learning_rate': 4.2522231204527085e-05, 'epoch': 0.91}\n","{'loss': 0.3279, 'learning_rate': 4.242118027485853e-05, 'epoch': 0.92}\n","{'loss': 0.0088, 'learning_rate': 4.232012934518998e-05, 'epoch': 0.93}\n","{'loss': 0.0096, 'learning_rate': 4.221907841552142e-05, 'epoch': 0.93}\n","{'loss': 0.0429, 'learning_rate': 4.2118027485852873e-05, 'epoch': 0.94}\n","{'loss': 0.1263, 'learning_rate': 4.201697655618432e-05, 'epoch': 0.95}\n","{'loss': 0.0029, 'learning_rate': 4.1915925626515764e-05, 'epoch': 0.95}\n","{'loss': 0.0076, 'learning_rate': 4.181487469684721e-05, 'epoch': 0.96}\n","{'loss': 0.0012, 'learning_rate': 4.171382376717866e-05, 'epoch': 0.97}\n","{'loss': 0.0231, 'learning_rate': 4.161277283751011e-05, 'epoch': 0.98}\n","{'loss': 0.0002, 'learning_rate': 4.151172190784155e-05, 'epoch': 0.98}\n","{'loss': 0.0019, 'learning_rate': 4.1410670978173e-05, 'epoch': 0.99}\n","{'loss': 0.0005, 'learning_rate': 4.130962004850445e-05, 'epoch': 1.0}\n","{'loss': 0.4862, 'learning_rate': 4.1208569118835896e-05, 'epoch': 1.01}\n","{'loss': 0.0034, 'learning_rate': 4.110751818916734e-05, 'epoch': 1.01}\n","{'loss': 0.0271, 'learning_rate': 4.100646725949879e-05, 'epoch': 1.02}\n","{'loss': 0.0012, 'learning_rate': 4.090541632983024e-05, 'epoch': 1.03}\n","{'loss': 0.0529, 'learning_rate': 4.0804365400161684e-05, 'epoch': 1.04}\n","{'loss': 0.0029, 'learning_rate': 4.070331447049313e-05, 'epoch': 1.04}\n","{'loss': 0.004, 'learning_rate': 4.0602263540824575e-05, 'epoch': 1.05}\n","{'loss': 0.062, 'learning_rate': 4.050121261115603e-05, 'epoch': 1.06}\n","{'loss': 0.0024, 'learning_rate': 4.040016168148747e-05, 'epoch': 1.06}\n","{'loss': 0.0011, 'learning_rate': 4.029911075181892e-05, 'epoch': 1.07}\n","{'loss': 0.0489, 'learning_rate': 4.0198059822150363e-05, 'epoch': 1.08}\n","{'loss': 0.0053, 'learning_rate': 4.0097008892481816e-05, 'epoch': 1.09}\n","{'loss': 0.0008, 'learning_rate': 3.9995957962813254e-05, 'epoch': 1.09}\n","{'loss': 0.0003, 'learning_rate': 3.9894907033144707e-05, 'epoch': 1.1}\n","{'loss': 0.0007, 'learning_rate': 3.979385610347615e-05, 'epoch': 1.11}\n","{'loss': 0.0017, 'learning_rate': 3.9692805173807604e-05, 'epoch': 1.12}\n","{'loss': 0.0053, 'learning_rate': 3.959175424413904e-05, 'epoch': 1.12}\n","{'loss': 0.342, 'learning_rate': 3.9490703314470495e-05, 'epoch': 1.13}\n","{'loss': 0.0009, 'learning_rate': 3.938965238480194e-05, 'epoch': 1.14}\n","{'loss': 0.0027, 'learning_rate': 3.928860145513339e-05, 'epoch': 1.15}\n","{'loss': 0.0005, 'learning_rate': 3.918755052546483e-05, 'epoch': 1.15}\n","{'loss': 0.0005, 'learning_rate': 3.908649959579628e-05, 'epoch': 1.16}\n","{'loss': 0.0005, 'learning_rate': 3.8985448666127736e-05, 'epoch': 1.17}\n","{'loss': 0.0007, 'learning_rate': 3.8884397736459174e-05, 'epoch': 1.17}\n","{'loss': 0.0164, 'learning_rate': 3.8783346806790626e-05, 'epoch': 1.18}\n","{'loss': 0.3694, 'learning_rate': 3.868229587712207e-05, 'epoch': 1.19}\n","{'loss': 0.0014, 'learning_rate': 3.8581244947453524e-05, 'epoch': 1.2}\n","{'loss': 0.2258, 'learning_rate': 3.848019401778496e-05, 'epoch': 1.2}\n","{'loss': 0.0023, 'learning_rate': 3.8379143088116415e-05, 'epoch': 1.21}\n","{'loss': 0.0007, 'learning_rate': 3.827809215844786e-05, 'epoch': 1.22}\n","{'loss': 0.0003, 'learning_rate': 3.8177041228779306e-05, 'epoch': 1.23}\n","{'loss': 0.0009, 'learning_rate': 3.807599029911075e-05, 'epoch': 1.23}\n","{'loss': 0.0131, 'learning_rate': 3.79749393694422e-05, 'epoch': 1.24}\n","{'loss': 0.0101, 'learning_rate': 3.787388843977365e-05, 'epoch': 1.25}\n","{'loss': 0.0742, 'learning_rate': 3.7772837510105094e-05, 'epoch': 1.26}\n","{'loss': 0.0021, 'learning_rate': 3.767178658043654e-05, 'epoch': 1.26}\n","{'loss': 0.0005, 'learning_rate': 3.757073565076799e-05, 'epoch': 1.27}\n","{'loss': 0.0026, 'learning_rate': 3.746968472109944e-05, 'epoch': 1.28}\n","{'loss': 0.0019, 'learning_rate': 3.736863379143088e-05, 'epoch': 1.28}\n","{'loss': 0.001, 'learning_rate': 3.726758286176233e-05, 'epoch': 1.29}\n","{'loss': 0.3367, 'learning_rate': 3.716653193209378e-05, 'epoch': 1.3}\n","{'loss': 0.1587, 'learning_rate': 3.7065481002425226e-05, 'epoch': 1.31}\n","{'loss': 0.0275, 'learning_rate': 3.696443007275667e-05, 'epoch': 1.31}\n","{'loss': 0.0005, 'learning_rate': 3.6863379143088116e-05, 'epoch': 1.32}\n","{'loss': 0.0006, 'learning_rate': 3.676232821341957e-05, 'epoch': 1.33}\n","{'loss': 0.3567, 'learning_rate': 3.6661277283751014e-05, 'epoch': 1.34}\n","{'loss': 0.0123, 'learning_rate': 3.656022635408246e-05, 'epoch': 1.34}\n","{'loss': 0.0074, 'learning_rate': 3.6459175424413905e-05, 'epoch': 1.35}\n","{'loss': 0.0499, 'learning_rate': 3.635812449474536e-05, 'epoch': 1.36}\n","{'loss': 0.1113, 'learning_rate': 3.6257073565076796e-05, 'epoch': 1.37}\n","{'loss': 0.0018, 'learning_rate': 3.615602263540825e-05, 'epoch': 1.37}\n","{'loss': 0.135, 'learning_rate': 3.605497170573969e-05, 'epoch': 1.38}\n","{'loss': 0.0016, 'learning_rate': 3.5953920776071145e-05, 'epoch': 1.39}\n","{'loss': 0.1694, 'learning_rate': 3.5852869846402584e-05, 'epoch': 1.4}\n","{'loss': 0.0021, 'learning_rate': 3.5751818916734036e-05, 'epoch': 1.4}\n","{'loss': 0.0017, 'learning_rate': 3.565076798706548e-05, 'epoch': 1.41}\n","{'loss': 0.0009, 'learning_rate': 3.5549717057396934e-05, 'epoch': 1.42}\n","{'loss': 0.003, 'learning_rate': 3.544866612772837e-05, 'epoch': 1.42}\n","{'loss': 0.3333, 'learning_rate': 3.5347615198059825e-05, 'epoch': 1.43}\n","{'loss': 0.2274, 'learning_rate': 3.524656426839127e-05, 'epoch': 1.44}\n","{'loss': 0.0004, 'learning_rate': 3.5145513338722716e-05, 'epoch': 1.45}\n","{'loss': 0.0008, 'learning_rate': 3.504446240905416e-05, 'epoch': 1.45}\n","{'loss': 0.0004, 'learning_rate': 3.494341147938561e-05, 'epoch': 1.46}\n","{'loss': 0.005, 'learning_rate': 3.484236054971706e-05, 'epoch': 1.47}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b8072c710b314a0485ab5d977bc0c7e3","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1362 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.016046762466430664, 'eval_recall': 0.9485981308411215, 'eval_precision': 0.4945188794153471, 'eval_f1': 0.9162399097300582, 'eval_runtime': 43.6274, 'eval_samples_per_second': 31.219, 'eval_steps_per_second': 31.219, 'epoch': 1.47}\n","{'loss': 0.002, 'learning_rate': 3.4741309620048504e-05, 'epoch': 1.48}\n","{'loss': 0.0007, 'learning_rate': 3.464025869037995e-05, 'epoch': 1.48}\n","{'loss': 0.0011, 'learning_rate': 3.45392077607114e-05, 'epoch': 1.49}\n","{'loss': 0.0016, 'learning_rate': 3.443815683104285e-05, 'epoch': 1.5}\n","{'loss': 0.0072, 'learning_rate': 3.433710590137429e-05, 'epoch': 1.51}\n","{'loss': 0.1971, 'learning_rate': 3.423605497170574e-05, 'epoch': 1.51}\n","{'loss': 0.0002, 'learning_rate': 3.413500404203719e-05, 'epoch': 1.52}\n","{'loss': 0.0015, 'learning_rate': 3.4033953112368635e-05, 'epoch': 1.53}\n","{'loss': 0.0529, 'learning_rate': 3.393290218270008e-05, 'epoch': 1.53}\n","{'loss': 0.0018, 'learning_rate': 3.3831851253031526e-05, 'epoch': 1.54}\n","{'loss': 0.0014, 'learning_rate': 3.373080032336298e-05, 'epoch': 1.55}\n","{'loss': 0.0216, 'learning_rate': 3.3629749393694424e-05, 'epoch': 1.56}\n","{'loss': 0.0019, 'learning_rate': 3.352869846402587e-05, 'epoch': 1.56}\n","{'loss': 0.1256, 'learning_rate': 3.342764753435732e-05, 'epoch': 1.57}\n","{'loss': 0.4893, 'learning_rate': 3.332659660468877e-05, 'epoch': 1.58}\n","{'loss': 0.0124, 'learning_rate': 3.322554567502021e-05, 'epoch': 1.59}\n","{'loss': 0.0652, 'learning_rate': 3.312449474535166e-05, 'epoch': 1.59}\n","{'loss': 0.0056, 'learning_rate': 3.302344381568311e-05, 'epoch': 1.6}\n","{'loss': 0.0014, 'learning_rate': 3.2922392886014555e-05, 'epoch': 1.61}\n","{'loss': 0.0139, 'learning_rate': 3.2821341956346e-05, 'epoch': 1.62}\n","{'loss': 0.0015, 'learning_rate': 3.2720291026677446e-05, 'epoch': 1.62}\n","{'loss': 0.0032, 'learning_rate': 3.26192400970089e-05, 'epoch': 1.63}\n","{'loss': 0.0024, 'learning_rate': 3.2518189167340344e-05, 'epoch': 1.64}\n","{'loss': 0.0018, 'learning_rate': 3.241713823767179e-05, 'epoch': 1.64}\n","{'loss': 0.0006, 'learning_rate': 3.2316087308003235e-05, 'epoch': 1.65}\n","{'loss': 0.0113, 'learning_rate': 3.221503637833469e-05, 'epoch': 1.66}\n","{'loss': 0.0733, 'learning_rate': 3.2113985448666125e-05, 'epoch': 1.67}\n","{'loss': 0.1257, 'learning_rate': 3.201293451899758e-05, 'epoch': 1.67}\n","{'loss': 0.0637, 'learning_rate': 3.191188358932902e-05, 'epoch': 1.68}\n","{'loss': 0.0017, 'learning_rate': 3.1810832659660475e-05, 'epoch': 1.69}\n","{'loss': 0.0014, 'learning_rate': 3.1709781729991914e-05, 'epoch': 1.7}\n","{'loss': 0.0011, 'learning_rate': 3.1608730800323366e-05, 'epoch': 1.7}\n","{'loss': 0.0003, 'learning_rate': 3.150767987065481e-05, 'epoch': 1.71}\n","{'loss': 0.0005, 'learning_rate': 3.140662894098626e-05, 'epoch': 1.72}\n","{'loss': 0.0003, 'learning_rate': 3.13055780113177e-05, 'epoch': 1.73}\n","{'loss': 0.0001, 'learning_rate': 3.1204527081649154e-05, 'epoch': 1.73}\n","{'loss': 0.0004, 'learning_rate': 3.11034761519806e-05, 'epoch': 1.74}\n","{'loss': 0.0005, 'learning_rate': 3.1002425222312045e-05, 'epoch': 1.75}\n","{'loss': 0.3315, 'learning_rate': 3.090137429264349e-05, 'epoch': 1.75}\n","{'loss': 0.0009, 'learning_rate': 3.080032336297494e-05, 'epoch': 1.76}\n","{'loss': 0.0007, 'learning_rate': 3.069927243330639e-05, 'epoch': 1.77}\n","{'loss': 0.0225, 'learning_rate': 3.0598221503637834e-05, 'epoch': 1.78}\n","{'loss': 0.0008, 'learning_rate': 3.049717057396928e-05, 'epoch': 1.78}\n","{'loss': 0.0015, 'learning_rate': 3.039611964430073e-05, 'epoch': 1.79}\n","{'loss': 0.0008, 'learning_rate': 3.0295068714632173e-05, 'epoch': 1.8}\n","{'loss': 0.0918, 'learning_rate': 3.0194017784963626e-05, 'epoch': 1.81}\n","{'loss': 0.0014, 'learning_rate': 3.0092966855295068e-05, 'epoch': 1.81}\n","{'loss': 0.001, 'learning_rate': 2.9991915925626516e-05, 'epoch': 1.82}\n","{'loss': 0.0002, 'learning_rate': 2.9890864995957962e-05, 'epoch': 1.83}\n","{'loss': 0.1742, 'learning_rate': 2.978981406628941e-05, 'epoch': 1.84}\n","{'loss': 0.0008, 'learning_rate': 2.9688763136620856e-05, 'epoch': 1.84}\n","{'loss': 0.0018, 'learning_rate': 2.9587712206952305e-05, 'epoch': 1.85}\n","{'loss': 0.0191, 'learning_rate': 2.948666127728375e-05, 'epoch': 1.86}\n","{'loss': 0.0003, 'learning_rate': 2.93856103476152e-05, 'epoch': 1.86}\n","{'loss': 0.0081, 'learning_rate': 2.9284559417946644e-05, 'epoch': 1.87}\n","{'loss': 0.0007, 'learning_rate': 2.9183508488278093e-05, 'epoch': 1.88}\n","{'loss': 0.0032, 'learning_rate': 2.908245755860954e-05, 'epoch': 1.89}\n","{'loss': 0.0002, 'learning_rate': 2.8981406628940987e-05, 'epoch': 1.89}\n","{'loss': 0.0057, 'learning_rate': 2.8880355699272433e-05, 'epoch': 1.9}\n","{'loss': 0.0006, 'learning_rate': 2.8779304769603882e-05, 'epoch': 1.91}\n","{'loss': 0.0307, 'learning_rate': 2.8678253839935327e-05, 'epoch': 1.92}\n","{'loss': 0.0013, 'learning_rate': 2.8577202910266776e-05, 'epoch': 1.92}\n","{'loss': 0.0651, 'learning_rate': 2.847615198059822e-05, 'epoch': 1.93}\n","{'loss': 0.0005, 'learning_rate': 2.837510105092967e-05, 'epoch': 1.94}\n","{'loss': 0.0005, 'learning_rate': 2.8274050121261116e-05, 'epoch': 1.95}\n","{'loss': 0.0008, 'learning_rate': 2.8172999191592564e-05, 'epoch': 1.95}\n","{'loss': 0.0009, 'learning_rate': 2.8071948261924013e-05, 'epoch': 1.96}\n","{'loss': 0.004, 'learning_rate': 2.797089733225546e-05, 'epoch': 1.97}\n","{'loss': 0.0016, 'learning_rate': 2.7869846402586907e-05, 'epoch': 1.98}\n","{'loss': 0.0013, 'learning_rate': 2.7768795472918353e-05, 'epoch': 1.98}\n","{'loss': 0.1997, 'learning_rate': 2.76677445432498e-05, 'epoch': 1.99}\n","{'loss': 0.0007, 'learning_rate': 2.7566693613581247e-05, 'epoch': 2.0}\n","{'loss': 0.0275, 'learning_rate': 2.7465642683912696e-05, 'epoch': 2.0}\n","{'loss': 0.001, 'learning_rate': 2.736459175424414e-05, 'epoch': 2.01}\n","{'loss': 0.0016, 'learning_rate': 2.726354082457559e-05, 'epoch': 2.02}\n","{'loss': 0.001, 'learning_rate': 2.7162489894907035e-05, 'epoch': 2.03}\n","{'loss': 0.0079, 'learning_rate': 2.7061438965238484e-05, 'epoch': 2.03}\n","{'loss': 0.0001, 'learning_rate': 2.6960388035569926e-05, 'epoch': 2.04}\n","{'loss': 0.001, 'learning_rate': 2.685933710590138e-05, 'epoch': 2.05}\n","{'loss': 0.0004, 'learning_rate': 2.675828617623282e-05, 'epoch': 2.06}\n","{'loss': 0.0026, 'learning_rate': 2.6657235246564273e-05, 'epoch': 2.06}\n","{'loss': 0.0001, 'learning_rate': 2.6556184316895715e-05, 'epoch': 2.07}\n","{'loss': 0.0002, 'learning_rate': 2.6455133387227167e-05, 'epoch': 2.08}\n","{'loss': 0.0, 'learning_rate': 2.635408245755861e-05, 'epoch': 2.09}\n","{'loss': 0.0039, 'learning_rate': 2.625303152789006e-05, 'epoch': 2.09}\n","{'loss': 0.0004, 'learning_rate': 2.6151980598221503e-05, 'epoch': 2.1}\n","{'loss': 0.0009, 'learning_rate': 2.6050929668552952e-05, 'epoch': 2.11}\n","{'loss': 0.0016, 'learning_rate': 2.5949878738884397e-05, 'epoch': 2.11}\n","{'loss': 0.0658, 'learning_rate': 2.5848827809215846e-05, 'epoch': 2.12}\n","{'loss': 0.0004, 'learning_rate': 2.574777687954729e-05, 'epoch': 2.13}\n","{'loss': 0.0015, 'learning_rate': 2.564672594987874e-05, 'epoch': 2.14}\n","{'loss': 0.0026, 'learning_rate': 2.5545675020210186e-05, 'epoch': 2.14}\n","{'loss': 0.0016, 'learning_rate': 2.5444624090541635e-05, 'epoch': 2.15}\n","{'loss': 0.003, 'learning_rate': 2.534357316087308e-05, 'epoch': 2.16}\n","{'loss': 0.0007, 'learning_rate': 2.524252223120453e-05, 'epoch': 2.17}\n","{'loss': 0.0, 'learning_rate': 2.5141471301535974e-05, 'epoch': 2.17}\n","{'loss': 0.0051, 'learning_rate': 2.5040420371867423e-05, 'epoch': 2.18}\n","{'loss': 0.0011, 'learning_rate': 2.4939369442198872e-05, 'epoch': 2.19}\n","{'loss': 0.0042, 'learning_rate': 2.4838318512530317e-05, 'epoch': 2.2}\n","{'loss': 0.0008, 'learning_rate': 2.4737267582861766e-05, 'epoch': 2.2}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"843f516e0aa24db5b31b131e07709587","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1362 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.054401662200689316, 'eval_recall': 0.8656542056074766, 'eval_precision': 0.6365979381443299, 'eval_f1': 0.8538379719907817, 'eval_runtime': 41.4238, 'eval_samples_per_second': 32.88, 'eval_steps_per_second': 32.88, 'epoch': 2.2}\n","{'loss': 0.001, 'learning_rate': 2.463621665319321e-05, 'epoch': 2.21}\n","{'loss': 0.0001, 'learning_rate': 2.4535165723524657e-05, 'epoch': 2.22}\n","{'loss': 0.0009, 'learning_rate': 2.4434114793856106e-05, 'epoch': 2.22}\n","{'loss': 0.0009, 'learning_rate': 2.433306386418755e-05, 'epoch': 2.23}\n","{'loss': 0.0001, 'learning_rate': 2.4232012934519e-05, 'epoch': 2.24}\n","{'loss': 0.1066, 'learning_rate': 2.4130962004850445e-05, 'epoch': 2.25}\n","{'loss': 0.0778, 'learning_rate': 2.4029911075181894e-05, 'epoch': 2.25}\n","{'loss': 0.0002, 'learning_rate': 2.392886014551334e-05, 'epoch': 2.26}\n","{'loss': 0.0003, 'learning_rate': 2.382780921584479e-05, 'epoch': 2.27}\n","{'loss': 0.0012, 'learning_rate': 2.3726758286176234e-05, 'epoch': 2.28}\n","{'loss': 0.0006, 'learning_rate': 2.3625707356507683e-05, 'epoch': 2.28}\n","{'loss': 0.0034, 'learning_rate': 2.3524656426839128e-05, 'epoch': 2.29}\n","{'loss': 0.0001, 'learning_rate': 2.3423605497170577e-05, 'epoch': 2.3}\n","{'loss': 0.1683, 'learning_rate': 2.3322554567502022e-05, 'epoch': 2.31}\n","{'loss': 0.0001, 'learning_rate': 2.322150363783347e-05, 'epoch': 2.31}\n","{'loss': 0.0335, 'learning_rate': 2.3120452708164916e-05, 'epoch': 2.32}\n","{'loss': 0.0913, 'learning_rate': 2.3019401778496362e-05, 'epoch': 2.33}\n","{'loss': 0.0006, 'learning_rate': 2.291835084882781e-05, 'epoch': 2.33}\n","{'loss': 0.004, 'learning_rate': 2.2817299919159256e-05, 'epoch': 2.34}\n","{'loss': 0.0025, 'learning_rate': 2.2716248989490705e-05, 'epoch': 2.35}\n","{'loss': 0.0003, 'learning_rate': 2.261519805982215e-05, 'epoch': 2.36}\n","{'loss': 0.0001, 'learning_rate': 2.25141471301536e-05, 'epoch': 2.36}\n","{'loss': 0.0024, 'learning_rate': 2.2413096200485044e-05, 'epoch': 2.37}\n","{'loss': 0.0013, 'learning_rate': 2.2312045270816493e-05, 'epoch': 2.38}\n","{'loss': 0.0001, 'learning_rate': 2.221099434114794e-05, 'epoch': 2.39}\n","{'loss': 0.0002, 'learning_rate': 2.2109943411479387e-05, 'epoch': 2.39}\n","{'loss': 0.0014, 'learning_rate': 2.2008892481810833e-05, 'epoch': 2.4}\n","{'loss': 0.0009, 'learning_rate': 2.1907841552142282e-05, 'epoch': 2.41}\n","{'loss': 0.0016, 'learning_rate': 2.1806790622473727e-05, 'epoch': 2.42}\n","{'loss': 0.3121, 'learning_rate': 2.1705739692805176e-05, 'epoch': 2.42}\n","{'loss': 0.0082, 'learning_rate': 2.160468876313662e-05, 'epoch': 2.43}\n","{'loss': 0.0032, 'learning_rate': 2.1503637833468067e-05, 'epoch': 2.44}\n","{'loss': 0.2145, 'learning_rate': 2.1402586903799516e-05, 'epoch': 2.44}\n","{'loss': 0.2789, 'learning_rate': 2.130153597413096e-05, 'epoch': 2.45}\n","{'loss': 0.0408, 'learning_rate': 2.120048504446241e-05, 'epoch': 2.46}\n","{'loss': 0.0357, 'learning_rate': 2.1099434114793855e-05, 'epoch': 2.47}\n","{'loss': 0.0012, 'learning_rate': 2.0998383185125304e-05, 'epoch': 2.47}\n","{'loss': 0.0958, 'learning_rate': 2.089733225545675e-05, 'epoch': 2.48}\n","{'loss': 0.0009, 'learning_rate': 2.0796281325788198e-05, 'epoch': 2.49}\n","{'loss': 0.1208, 'learning_rate': 2.0695230396119644e-05, 'epoch': 2.5}\n","{'loss': 0.0003, 'learning_rate': 2.0594179466451092e-05, 'epoch': 2.5}\n","{'loss': 0.0008, 'learning_rate': 2.0493128536782538e-05, 'epoch': 2.51}\n","{'loss': 0.0019, 'learning_rate': 2.0392077607113987e-05, 'epoch': 2.52}\n","{'loss': 0.0005, 'learning_rate': 2.0291026677445432e-05, 'epoch': 2.53}\n","{'loss': 0.0005, 'learning_rate': 2.0189975747776877e-05, 'epoch': 2.53}\n","{'loss': 0.0026, 'learning_rate': 2.008892481810833e-05, 'epoch': 2.54}\n","{'loss': 0.0006, 'learning_rate': 1.9987873888439775e-05, 'epoch': 2.55}\n","{'loss': 0.0001, 'learning_rate': 1.9886822958771224e-05, 'epoch': 2.56}\n","{'loss': 0.0, 'learning_rate': 1.978577202910267e-05, 'epoch': 2.56}\n","{'loss': 0.0018, 'learning_rate': 1.9684721099434118e-05, 'epoch': 2.57}\n","{'loss': 0.0009, 'learning_rate': 1.9583670169765564e-05, 'epoch': 2.58}\n","{'loss': 0.0003, 'learning_rate': 1.9482619240097012e-05, 'epoch': 2.58}\n","{'loss': 0.0002, 'learning_rate': 1.9381568310428458e-05, 'epoch': 2.59}\n","{'loss': 0.0009, 'learning_rate': 1.9280517380759907e-05, 'epoch': 2.6}\n","{'loss': 0.0001, 'learning_rate': 1.9179466451091352e-05, 'epoch': 2.61}\n","{'loss': 0.0002, 'learning_rate': 1.9078415521422797e-05, 'epoch': 2.61}\n","{'loss': 0.2794, 'learning_rate': 1.8977364591754246e-05, 'epoch': 2.62}\n","{'loss': 0.0002, 'learning_rate': 1.887631366208569e-05, 'epoch': 2.63}\n","{'loss': 0.0015, 'learning_rate': 1.877526273241714e-05, 'epoch': 2.64}\n","{'loss': 0.0006, 'learning_rate': 1.8674211802748586e-05, 'epoch': 2.64}\n","{'loss': 0.0086, 'learning_rate': 1.8573160873080035e-05, 'epoch': 2.65}\n","{'loss': 0.0014, 'learning_rate': 1.847210994341148e-05, 'epoch': 2.66}\n","{'loss': 0.0705, 'learning_rate': 1.837105901374293e-05, 'epoch': 2.67}\n","{'loss': 0.003, 'learning_rate': 1.8270008084074374e-05, 'epoch': 2.67}\n","{'loss': 0.0004, 'learning_rate': 1.8168957154405823e-05, 'epoch': 2.68}\n","{'loss': 0.0014, 'learning_rate': 1.806790622473727e-05, 'epoch': 2.69}\n","{'loss': 0.0002, 'learning_rate': 1.7966855295068717e-05, 'epoch': 2.69}\n","{'loss': 0.0003, 'learning_rate': 1.7865804365400163e-05, 'epoch': 2.7}\n","{'loss': 0.0003, 'learning_rate': 1.7764753435731608e-05, 'epoch': 2.71}\n","{'loss': 0.2256, 'learning_rate': 1.7663702506063057e-05, 'epoch': 2.72}\n","{'loss': 0.061, 'learning_rate': 1.7562651576394502e-05, 'epoch': 2.72}\n","{'loss': 0.0658, 'learning_rate': 1.746160064672595e-05, 'epoch': 2.73}\n","{'loss': 0.0055, 'learning_rate': 1.7360549717057397e-05, 'epoch': 2.74}\n","{'loss': 0.0005, 'learning_rate': 1.7259498787388845e-05, 'epoch': 2.75}\n","{'loss': 0.0032, 'learning_rate': 1.715844785772029e-05, 'epoch': 2.75}\n","{'loss': 0.0021, 'learning_rate': 1.705739692805174e-05, 'epoch': 2.76}\n","{'loss': 0.0019, 'learning_rate': 1.6956345998383185e-05, 'epoch': 2.77}\n","{'loss': 0.0095, 'learning_rate': 1.6855295068714634e-05, 'epoch': 2.78}\n","{'loss': 0.0055, 'learning_rate': 1.675424413904608e-05, 'epoch': 2.78}\n","{'loss': 0.0004, 'learning_rate': 1.6653193209377528e-05, 'epoch': 2.79}\n","{'loss': 0.002, 'learning_rate': 1.6552142279708973e-05, 'epoch': 2.8}\n","{'loss': 0.0011, 'learning_rate': 1.6451091350040422e-05, 'epoch': 2.8}\n","{'loss': 0.0001, 'learning_rate': 1.6350040420371868e-05, 'epoch': 2.81}\n","{'loss': 0.0214, 'learning_rate': 1.6248989490703313e-05, 'epoch': 2.82}\n","{'loss': 0.0001, 'learning_rate': 1.6147938561034762e-05, 'epoch': 2.83}\n","{'loss': 0.0007, 'learning_rate': 1.6046887631366207e-05, 'epoch': 2.83}\n","{'loss': 0.0045, 'learning_rate': 1.5945836701697656e-05, 'epoch': 2.84}\n","{'loss': 0.0003, 'learning_rate': 1.58447857720291e-05, 'epoch': 2.85}\n","{'loss': 0.1203, 'learning_rate': 1.574373484236055e-05, 'epoch': 2.86}\n","{'loss': 0.0009, 'learning_rate': 1.5642683912691996e-05, 'epoch': 2.86}\n","{'loss': 0.0029, 'learning_rate': 1.5541632983023444e-05, 'epoch': 2.87}\n","{'loss': 0.0257, 'learning_rate': 1.544058205335489e-05, 'epoch': 2.88}\n","{'loss': 0.0021, 'learning_rate': 1.533953112368634e-05, 'epoch': 2.89}\n","{'loss': 0.0017, 'learning_rate': 1.5238480194017784e-05, 'epoch': 2.89}\n","{'loss': 0.0001, 'learning_rate': 1.5137429264349231e-05, 'epoch': 2.9}\n","{'loss': 0.0169, 'learning_rate': 1.5036378334680678e-05, 'epoch': 2.91}\n","{'loss': 0.0001, 'learning_rate': 1.4935327405012125e-05, 'epoch': 2.91}\n","{'loss': 0.0333, 'learning_rate': 1.4834276475343573e-05, 'epoch': 2.92}\n","{'loss': 0.0011, 'learning_rate': 1.473322554567502e-05, 'epoch': 2.93}\n","{'loss': 0.0004, 'learning_rate': 1.463217461600647e-05, 'epoch': 2.94}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b98fabad45624baa901e627166baa1e1","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1362 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.016192439943552017, 'eval_recall': 0.9544392523364486, 'eval_precision': 0.5985347985347985, 'eval_f1': 0.9330990555677574, 'eval_runtime': 40.6021, 'eval_samples_per_second': 33.545, 'eval_steps_per_second': 33.545, 'epoch': 2.94}\n","{'loss': 0.0376, 'learning_rate': 1.4531123686337916e-05, 'epoch': 2.94}\n","{'loss': 0.0059, 'learning_rate': 1.4430072756669363e-05, 'epoch': 2.95}\n","{'loss': 0.0018, 'learning_rate': 1.432902182700081e-05, 'epoch': 2.96}\n","{'loss': 0.1039, 'learning_rate': 1.4227970897332257e-05, 'epoch': 2.97}\n","{'loss': 0.0002, 'learning_rate': 1.4126919967663704e-05, 'epoch': 2.97}\n","{'loss': 0.0234, 'learning_rate': 1.4025869037995151e-05, 'epoch': 2.98}\n","{'loss': 0.0007, 'learning_rate': 1.3924818108326598e-05, 'epoch': 2.99}\n","{'loss': 0.0021, 'learning_rate': 1.3823767178658045e-05, 'epoch': 3.0}\n","{'loss': 0.0012, 'learning_rate': 1.3722716248989492e-05, 'epoch': 3.0}\n","{'loss': 0.0005, 'learning_rate': 1.362166531932094e-05, 'epoch': 3.01}\n","{'loss': 0.0043, 'learning_rate': 1.3520614389652387e-05, 'epoch': 3.02}\n","{'loss': 0.001, 'learning_rate': 1.3419563459983834e-05, 'epoch': 3.02}\n","{'loss': 0.0138, 'learning_rate': 1.3318512530315281e-05, 'epoch': 3.03}\n","{'loss': 0.0022, 'learning_rate': 1.3217461600646728e-05, 'epoch': 3.04}\n","{'loss': 0.1884, 'learning_rate': 1.3116410670978173e-05, 'epoch': 3.05}\n","{'loss': 0.0003, 'learning_rate': 1.301535974130962e-05, 'epoch': 3.05}\n","{'loss': 0.0002, 'learning_rate': 1.2914308811641068e-05, 'epoch': 3.06}\n","{'loss': 0.0012, 'learning_rate': 1.2813257881972515e-05, 'epoch': 3.07}\n","{'loss': 0.0002, 'learning_rate': 1.2712206952303962e-05, 'epoch': 3.08}\n","{'loss': 0.0001, 'learning_rate': 1.2611156022635409e-05, 'epoch': 3.08}\n","{'loss': 0.0, 'learning_rate': 1.2510105092966856e-05, 'epoch': 3.09}\n","{'loss': 0.0005, 'learning_rate': 1.2409054163298303e-05, 'epoch': 3.1}\n","{'loss': 0.0001, 'learning_rate': 1.230800323362975e-05, 'epoch': 3.11}\n","{'loss': 0.0002, 'learning_rate': 1.2206952303961197e-05, 'epoch': 3.11}\n","{'loss': 0.0004, 'learning_rate': 1.2105901374292644e-05, 'epoch': 3.12}\n","{'loss': 0.002, 'learning_rate': 1.2004850444624092e-05, 'epoch': 3.13}\n","{'loss': 0.0002, 'learning_rate': 1.1903799514955539e-05, 'epoch': 3.14}\n","{'loss': 0.0, 'learning_rate': 1.1802748585286986e-05, 'epoch': 3.14}\n","{'loss': 0.0, 'learning_rate': 1.1701697655618433e-05, 'epoch': 3.15}\n","{'loss': 0.0001, 'learning_rate': 1.1600646725949878e-05, 'epoch': 3.16}\n","{'loss': 0.025, 'learning_rate': 1.1499595796281325e-05, 'epoch': 3.16}\n","{'loss': 0.0005, 'learning_rate': 1.1398544866612773e-05, 'epoch': 3.17}\n","{'loss': 0.0003, 'learning_rate': 1.129749393694422e-05, 'epoch': 3.18}\n","{'loss': 0.0009, 'learning_rate': 1.1196443007275667e-05, 'epoch': 3.19}\n","{'loss': 0.0002, 'learning_rate': 1.1095392077607114e-05, 'epoch': 3.19}\n","{'loss': 0.0005, 'learning_rate': 1.0994341147938561e-05, 'epoch': 3.2}\n","{'loss': 0.0002, 'learning_rate': 1.0893290218270008e-05, 'epoch': 3.21}\n","{'loss': 0.0005, 'learning_rate': 1.0792239288601455e-05, 'epoch': 3.22}\n","{'loss': 0.0001, 'learning_rate': 1.0691188358932902e-05, 'epoch': 3.22}\n","{'loss': 0.0126, 'learning_rate': 1.0590137429264351e-05, 'epoch': 3.23}\n","{'loss': 0.0007, 'learning_rate': 1.0489086499595798e-05, 'epoch': 3.24}\n","{'loss': 0.0023, 'learning_rate': 1.0388035569927244e-05, 'epoch': 3.25}\n","{'loss': 0.0004, 'learning_rate': 1.028698464025869e-05, 'epoch': 3.25}\n","{'loss': 0.0002, 'learning_rate': 1.0185933710590138e-05, 'epoch': 3.26}\n","{'loss': 0.1052, 'learning_rate': 1.0084882780921585e-05, 'epoch': 3.27}\n","{'loss': 0.0004, 'learning_rate': 9.983831851253032e-06, 'epoch': 3.27}\n","{'loss': 0.0005, 'learning_rate': 9.88278092158448e-06, 'epoch': 3.28}\n","{'loss': 0.0, 'learning_rate': 9.781729991915926e-06, 'epoch': 3.29}\n","{'loss': 0.0143, 'learning_rate': 9.680679062247373e-06, 'epoch': 3.3}\n","{'loss': 0.0009, 'learning_rate': 9.57962813257882e-06, 'epoch': 3.3}\n","{'loss': 0.0001, 'learning_rate': 9.478577202910268e-06, 'epoch': 3.31}\n","{'loss': 0.0, 'learning_rate': 9.377526273241715e-06, 'epoch': 3.32}\n","{'loss': 0.0, 'learning_rate': 9.276475343573162e-06, 'epoch': 3.33}\n","{'loss': 0.0014, 'learning_rate': 9.175424413904609e-06, 'epoch': 3.33}\n","{'loss': 0.0006, 'learning_rate': 9.074373484236056e-06, 'epoch': 3.34}\n","{'loss': 0.0002, 'learning_rate': 8.973322554567501e-06, 'epoch': 3.35}\n","{'loss': 0.0007, 'learning_rate': 8.872271624898949e-06, 'epoch': 3.36}\n","{'loss': 0.0007, 'learning_rate': 8.771220695230396e-06, 'epoch': 3.36}\n","{'loss': 0.0001, 'learning_rate': 8.670169765561843e-06, 'epoch': 3.37}\n","{'loss': 0.0028, 'learning_rate': 8.56911883589329e-06, 'epoch': 3.38}\n","{'loss': 0.0003, 'learning_rate': 8.468067906224737e-06, 'epoch': 3.38}\n","{'loss': 0.0, 'learning_rate': 8.367016976556184e-06, 'epoch': 3.39}\n","{'loss': 0.0003, 'learning_rate': 8.265966046887631e-06, 'epoch': 3.4}\n","{'loss': 0.0001, 'learning_rate': 8.164915117219078e-06, 'epoch': 3.41}\n","{'loss': 0.0001, 'learning_rate': 8.063864187550525e-06, 'epoch': 3.41}\n","{'loss': 0.0013, 'learning_rate': 7.962813257881973e-06, 'epoch': 3.42}\n","{'loss': 0.0004, 'learning_rate': 7.861762328213421e-06, 'epoch': 3.43}\n","{'loss': 0.0001, 'learning_rate': 7.760711398544867e-06, 'epoch': 3.44}\n","{'loss': 0.0001, 'learning_rate': 7.659660468876314e-06, 'epoch': 3.44}\n","{'loss': 0.0005, 'learning_rate': 7.558609539207762e-06, 'epoch': 3.45}\n","{'loss': 0.0011, 'learning_rate': 7.457558609539209e-06, 'epoch': 3.46}\n","{'loss': 0.0001, 'learning_rate': 7.356507679870655e-06, 'epoch': 3.47}\n","{'loss': 0.0004, 'learning_rate': 7.255456750202102e-06, 'epoch': 3.47}\n","{'loss': 0.0001, 'learning_rate': 7.1544058205335494e-06, 'epoch': 3.48}\n","{'loss': 0.0014, 'learning_rate': 7.0533548908649965e-06, 'epoch': 3.49}\n","{'loss': 0.0003, 'learning_rate': 6.952303961196444e-06, 'epoch': 3.49}\n","{'loss': 0.0002, 'learning_rate': 6.851253031527891e-06, 'epoch': 3.5}\n","{'loss': 0.0001, 'learning_rate': 6.750202101859338e-06, 'epoch': 3.51}\n","{'loss': 0.0274, 'learning_rate': 6.649151172190784e-06, 'epoch': 3.52}\n","{'loss': 0.0001, 'learning_rate': 6.548100242522231e-06, 'epoch': 3.52}\n","{'loss': 0.0283, 'learning_rate': 6.447049312853678e-06, 'epoch': 3.53}\n","{'loss': 0.0009, 'learning_rate': 6.3459983831851255e-06, 'epoch': 3.54}\n","{'loss': 0.0002, 'learning_rate': 6.2449474535165726e-06, 'epoch': 3.55}\n","{'loss': 0.0, 'learning_rate': 6.14389652384802e-06, 'epoch': 3.55}\n","{'loss': 0.0002, 'learning_rate': 6.042845594179467e-06, 'epoch': 3.56}\n","{'loss': 0.0005, 'learning_rate': 5.941794664510914e-06, 'epoch': 3.57}\n","{'loss': 0.0002, 'learning_rate': 5.840743734842361e-06, 'epoch': 3.58}\n","{'loss': 0.0002, 'learning_rate': 5.739692805173808e-06, 'epoch': 3.58}\n","{'loss': 0.0017, 'learning_rate': 5.638641875505255e-06, 'epoch': 3.59}\n","{'loss': 0.1464, 'learning_rate': 5.537590945836702e-06, 'epoch': 3.6}\n","{'loss': 0.0005, 'learning_rate': 5.4365400161681494e-06, 'epoch': 3.6}\n","{'loss': 0.0001, 'learning_rate': 5.3354890864995965e-06, 'epoch': 3.61}\n","{'loss': 0.0001, 'learning_rate': 5.234438156831043e-06, 'epoch': 3.62}\n","{'loss': 0.0004, 'learning_rate': 5.13338722716249e-06, 'epoch': 3.63}\n","{'loss': 0.0001, 'learning_rate': 5.032336297493937e-06, 'epoch': 3.63}\n","{'loss': 0.0005, 'learning_rate': 4.931285367825384e-06, 'epoch': 3.64}\n","{'loss': 0.0025, 'learning_rate': 4.830234438156831e-06, 'epoch': 3.65}\n","{'loss': 0.0, 'learning_rate': 4.729183508488278e-06, 'epoch': 3.66}\n","{'loss': 0.0699, 'learning_rate': 4.6281325788197255e-06, 'epoch': 3.66}\n","{'loss': 0.0028, 'learning_rate': 4.527081649151172e-06, 'epoch': 3.67}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4c8000c745834213810f82b14b6488c7","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1362 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.0364062525331974, 'eval_recall': 0.8936915887850467, 'eval_precision': 0.697992700729927, 'eval_f1': 0.8841571834992887, 'eval_runtime': 40.5677, 'eval_samples_per_second': 33.574, 'eval_steps_per_second': 33.574, 'epoch': 3.67}\n","{'loss': 0.0001, 'learning_rate': 4.42603071948262e-06, 'epoch': 3.68}\n","{'loss': 0.0024, 'learning_rate': 4.324979789814067e-06, 'epoch': 3.69}\n","{'loss': 0.0001, 'learning_rate': 4.223928860145514e-06, 'epoch': 3.69}\n","{'loss': 0.0096, 'learning_rate': 4.122877930476961e-06, 'epoch': 3.7}\n","{'loss': 0.0001, 'learning_rate': 4.021827000808408e-06, 'epoch': 3.71}\n","{'loss': 0.0009, 'learning_rate': 3.920776071139854e-06, 'epoch': 3.72}\n","{'loss': 0.001, 'learning_rate': 3.8197251414713015e-06, 'epoch': 3.72}\n","{'loss': 0.0037, 'learning_rate': 3.7186742118027486e-06, 'epoch': 3.73}\n","{'loss': 0.0046, 'learning_rate': 3.6176232821341957e-06, 'epoch': 3.74}\n","{'loss': 0.0005, 'learning_rate': 3.516572352465643e-06, 'epoch': 3.74}\n","{'loss': 0.0011, 'learning_rate': 3.4155214227970895e-06, 'epoch': 3.75}\n","{'loss': 0.0784, 'learning_rate': 3.3144704931285366e-06, 'epoch': 3.76}\n","{'loss': 0.0015, 'learning_rate': 3.2134195634599837e-06, 'epoch': 3.77}\n","{'loss': 0.0025, 'learning_rate': 3.112368633791431e-06, 'epoch': 3.77}\n","{'loss': 0.0057, 'learning_rate': 3.011317704122878e-06, 'epoch': 3.78}\n","{'loss': 0.0019, 'learning_rate': 2.910266774454325e-06, 'epoch': 3.79}\n","{'loss': 0.1591, 'learning_rate': 2.809215844785772e-06, 'epoch': 3.8}\n","{'loss': 0.0, 'learning_rate': 2.7081649151172193e-06, 'epoch': 3.8}\n","{'loss': 0.0015, 'learning_rate': 2.6071139854486664e-06, 'epoch': 3.81}\n","{'loss': 0.0, 'learning_rate': 2.5060630557801135e-06, 'epoch': 3.82}\n","{'loss': 0.0077, 'learning_rate': 2.40501212611156e-06, 'epoch': 3.83}\n","{'loss': 0.0004, 'learning_rate': 2.3039611964430073e-06, 'epoch': 3.83}\n","{'loss': 0.0003, 'learning_rate': 2.2029102667744544e-06, 'epoch': 3.84}\n","{'loss': 0.0014, 'learning_rate': 2.1018593371059015e-06, 'epoch': 3.85}\n","{'loss': 0.0006, 'learning_rate': 2.0008084074373486e-06, 'epoch': 3.85}\n","{'loss': 0.0017, 'learning_rate': 1.8997574777687957e-06, 'epoch': 3.86}\n","{'loss': 0.003, 'learning_rate': 1.7987065481002426e-06, 'epoch': 3.87}\n","{'loss': 0.0011, 'learning_rate': 1.6976556184316897e-06, 'epoch': 3.88}\n","{'loss': 0.0, 'learning_rate': 1.5966046887631366e-06, 'epoch': 3.88}\n","{'loss': 0.0005, 'learning_rate': 1.4955537590945837e-06, 'epoch': 3.89}\n","{'loss': 0.0002, 'learning_rate': 1.3945028294260308e-06, 'epoch': 3.9}\n","{'loss': 0.0014, 'learning_rate': 1.2934518997574777e-06, 'epoch': 3.91}\n","{'loss': 0.0007, 'learning_rate': 1.1924009700889248e-06, 'epoch': 3.91}\n","{'loss': 0.0001, 'learning_rate': 1.091350040420372e-06, 'epoch': 3.92}\n","{'loss': 0.0, 'learning_rate': 9.902991107518188e-07, 'epoch': 3.93}\n","{'loss': 0.0003, 'learning_rate': 8.892481810832661e-07, 'epoch': 3.94}\n","{'loss': 0.0329, 'learning_rate': 7.881972514147131e-07, 'epoch': 3.94}\n","{'loss': 0.1589, 'learning_rate': 6.871463217461601e-07, 'epoch': 3.95}\n","{'loss': 0.0002, 'learning_rate': 5.860953920776072e-07, 'epoch': 3.96}\n","{'loss': 0.0003, 'learning_rate': 4.850444624090542e-07, 'epoch': 3.96}\n","{'loss': 0.002, 'learning_rate': 3.8399353274050123e-07, 'epoch': 3.97}\n","{'loss': 0.0007, 'learning_rate': 2.8294260307194823e-07, 'epoch': 3.98}\n","{'loss': 0.0005, 'learning_rate': 1.8189167340339532e-07, 'epoch': 3.99}\n","{'loss': 0.0021, 'learning_rate': 8.084074373484236e-08, 'epoch': 3.99}\n","{'train_runtime': 1972.6208, 'train_samples_per_second': 11.041, 'train_steps_per_second': 2.762, 'train_loss': 0.06913414063511027, 'epoch': 4.0}\n","Shutting down background jobs, please wait a moment...\n","Done!\n","Waiting for the remaining 6 operations to synchronize with Neptune. Do not kill this process.\n","All 6 operations synced, thanks for waiting!\n","Explore the metadata in the Neptune app:\n","https://app.neptune.ai/bernd.heidemann/PII/e/PII-212/metadata\n"]},{"data":{"text/plain":["TrainOutput(global_step=5448, training_loss=0.06913414063511027, metrics={'train_runtime': 1972.6208, 'train_samples_per_second': 11.041, 'train_steps_per_second': 2.762, 'train_loss': 0.06913414063511027, 'epoch': 4.0})"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["# set environment variables: TOKENIZERS_PARALLELISM=false\n","import os\n","os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n","\n","tokenizer = AutoTokenizer.from_pretrained(parameter[\"model\"])\n","tokenizer.add_tokens(AddedToken(\"\\n\", normalized=False))\n","\n","model = AutoModelForTokenClassification.from_pretrained(\n","    parameter[\"model\"],\n","    num_labels=len(all_labels),\n","    id2label=id2label,\n","    label2id=label2id,\n","    ignore_mismatched_sizes=True\n",")\n","print(model.config)\n","#my_model=MyModel(parameter['model'], len(label2id))\n","\n","trainer=get_trainer(model, train_ds, valid_ds)\n","trainer.train()"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","c:\\Users\\Bernd\\anaconda3\\envs\\mytorch\\lib\\site-packages\\transformers\\convert_slow_tokenizer.py:470: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n","  warnings.warn(\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"ename":"AttributeError","evalue":"'TokenClassifierOutput' object has no attribute 'argmax'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mcreate_submission\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msubmission.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n","Cell \u001b[1;32mIn[10], line 161\u001b[0m, in \u001b[0;36mcreate_submission\u001b[1;34m(model, filename)\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mid\u001b[39m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m    160\u001b[0m attention_mask\u001b[38;5;241m=\u001b[39mattention_mask\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m--> 161\u001b[0m preds\u001b[38;5;241m=\u001b[39m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmax\u001b[49m(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    162\u001b[0m all_preds\u001b[38;5;241m.\u001b[39mappend(preds)\n\u001b[0;32m    163\u001b[0m \u001b[38;5;66;03m#for pred, id in zip(preds.flatten(), id.flatten()):\u001b[39;00m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;66;03m#    if pred != 12:\u001b[39;00m\n\u001b[0;32m    165\u001b[0m         \u001b[38;5;66;03m#print(f\"Document: {document_id.item()} TOKEN:{tokenizer.decode(id)}  --- pred:{id2label[pred.item()]}\")\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;66;03m#    if pred != 12:\u001b[39;00m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;66;03m#        print(f\"TOKEN:{tokenizer.decode(id)}  --- pred:{id2label[pred.item()]}\")\u001b[39;00m\n","\u001b[1;31mAttributeError\u001b[0m: 'TokenClassifierOutput' object has no attribute 'argmax'"]}],"source":["create_submission(model, f\"submission.csv\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"databundleVersionId":7500999,"sourceId":66653,"sourceType":"competition"},{"datasetId":4319117,"sourceId":7429898,"sourceType":"datasetVersion"}],"dockerImageVersionId":30636,"isGpuEnabled":true,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
