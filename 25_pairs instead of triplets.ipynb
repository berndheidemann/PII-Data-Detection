{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["from transformers import AutoTokenizer, TrainingArguments, Trainer, AutoModelForTokenClassification\n","from pathlib import Path\n","import numpy as np\n","import torch\n","from tokenizers import AddedToken\n","from tqdm.notebook import tqdm\n","from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n","import pandas as pd\n","from datasets import Dataset\n","\n","kaggle=False\n","\n","path=\"/kaggle/input/pii-detection-removal-from-educational-data\" if kaggle else \"data\"\n","train_path = path + \"/train.json\"\n","test_path = path + \"/test.json\"\n","\n","mixtral_path=\"data/mpware_mixtral8x7b_v1.1.json\" if not kaggle else \"/kaggle/input/mixtral-8x7b-v11/mixtral8x7b_v1.1.json\"\n","\n","model_path = \"/kaggle/input/huggingfacedebertav3variants/deberta-v3-base\" if kaggle else \"microsoft/deberta-v3-base\"\n","\n","if not kaggle: import neptune\n","if not kaggle: from seqeval.metrics import recall_score, precision_score, f1_score, accuracy_score"]},{"cell_type":"markdown","metadata":{},"source":["https://www.kaggle.com/datasets/mpware/pii-mixtral8x7b-generated-essays"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-01-25T21:37:35.578114Z","iopub.status.busy":"2024-01-25T21:37:35.577723Z","iopub.status.idle":"2024-01-25T21:37:35.587366Z","shell.execute_reply":"2024-01-25T21:37:35.5858Z","shell.execute_reply.started":"2024-01-25T21:37:35.578083Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["{'model': 'microsoft/deberta-v3-base', 'max_length': 1024, 'inference_max_length': 2000, 'batch_size': 4, 'inference_batch_size': 1, 'lr': 5e-05, 'lr_scale_unfreeze': 0.1, 'filter_no_pii_percent_allow': 0.2, 'notebook': '20_deberta base_1024len.ipynb', 'CROSS_ENTROPY_WEIGHT_MULTI': 400, 'epochs_before_unfreeze': 2, 'epochs_after_unfreeze': 6, 'repeat_unfreeze_train_n_times': 2, 'validate_every_n_epochs': 2, 'train_test_split': 0.2, 'num_proc': 16, 'freeze_embeddings': False, 'freeze_layers': 6}\n"]}],"source":["cross_entropy_weight_multi = 400\n","\n","CROSS_ENTROPY_WEIGHTS = [cross_entropy_weight_multi]*12\n","CROSS_ENTROPY_WEIGHTS.append(1)\n","\n","parameter= {\n","    \"model\": model_path,\n","    \"max_length\": 1024,\n","    \"inference_max_length\": 2000,\n","    \"batch_size\": 4,\n","    \"inference_batch_size\": 1,\n","    \"lr\": 5e-05,\n","    \"lr_scale_unfreeze\": 0.1,\n","    \"filter_no_pii_percent_allow\": 0.2,\n","    \"notebook\": \"20_deberta base_1024len.ipynb\",\n","    \"CROSS_ENTROPY_WEIGHT_MULTI\": cross_entropy_weight_multi,\n","    \"epochs_before_unfreeze\": 2,\n","    \"epochs_after_unfreeze\": 6,\n","    \"repeat_unfreeze_train_n_times\": 2,\n","    \"validate_every_n_epochs\": 2,\n","    \"train_test_split\": 0.2,\n","    \"num_proc\": 16 if not kaggle else 2, \n","    \"freeze_embeddings\": False,\n","    \"freeze_layers\": 6\n","}\n","\n","print(parameter)"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["target = [\n","    'B-EMAIL', 'B-ID_NUM', 'B-NAME_STUDENT', 'B-PHONE_NUM', \n","    'B-STREET_ADDRESS', 'B-URL_PERSONAL', 'B-USERNAME', 'I-ID_NUM', \n","    'I-NAME_STUDENT', 'I-PHONE_NUM', 'I-STREET_ADDRESS', 'I-URL_PERSONAL'\n","]"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-01-25T21:37:35.606208Z","iopub.status.busy":"2024-01-25T21:37:35.605889Z","iopub.status.idle":"2024-01-25T21:37:35.62164Z","shell.execute_reply":"2024-01-25T21:37:35.620746Z","shell.execute_reply.started":"2024-01-25T21:37:35.606175Z"},"trusted":true},"outputs":[],"source":["from itertools import chain\n","import json\n","\n","data = json.load(open(train_path))\n","all_labels = sorted(list(set(chain(*[x[\"labels\"] for x in data]))))\n","label2id = {l: i for i,l in enumerate(all_labels)}\n","id2label = {v:k for k,v in label2id.items()}"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["import random\n","\n","def tokenize(example, tokenizer, label2id, max_length, all_labels_list):\n","    text = []\n","    import numpy as np\n","\n","    # these are at the character level\n","    labels = []\n","    targets = []\n","\n","    for t, l, ws in zip(example[\"tokens\"], example[\"labels\"], example[\"trailing_whitespace\"]):\n","\n","        text.append(t)\n","        labels.extend([l]*len(t))\n","        \n","        if l in all_labels_list:\n","            targets.append(1)\n","        else:\n","            targets.append(0)\n","        # if there is trailing whitespace\n","        if ws:\n","            text.append(\" \")\n","            labels.append(\"O\")\n","\n","    tokenized = tokenizer(\"\".join(text), return_offsets_mapping=True, truncation=True, max_length=max_length, padding=\"max_length\")\n","    \n","    target_num = sum(targets)\n","    labels = np.array(labels)\n","\n","    text = \"\".join(text)\n","    token_labels = []\n","\n","    for start_idx, end_idx in tokenized.offset_mapping:\n","\n","        # CLS token\n","        if start_idx == 0 and end_idx == 0: \n","            token_labels.append(label2id[\"O\"])\n","            continue\n","\n","        # case when token starts with whitespace\n","        if text[start_idx].isspace():\n","            start_idx += 1\n","\n","        try:\n","            token_labels.append(label2id[labels[start_idx]])\n","        except:\n","            token_labels.append(label2id[\"O\"])\n","\n","    length = len(tokenized.input_ids)\n","\n","    return {\n","        **tokenized,\n","        \"labels\": token_labels,\n","        \"length\": length,\n","        \"target_num\": target_num,\n","        \"group\": 1 if target_num>0 else 0\n","    }\n","\n","# https://www.kaggle.com/competitions/pii-detection-removal-from-educational-data/discussion/468844\n","def filter_no_pii(example, percent_allow=parameter[\"filter_no_pii_percent_allow\"]):\n","    # Return True if there is PII\n","    # Or 20% of the time if there isn't\n","    has_pii = set(\"O\") != set(example[\"labels\"])\n","    return has_pii or (random.random() < percent_allow)"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","c:\\Users\\Bernd\\anaconda3\\envs\\mytorch\\lib\\site-packages\\transformers\\convert_slow_tokenizer.py:470: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n","  warnings.warn(\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"data":{"text/plain":["1"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["tokenizer = AutoTokenizer.from_pretrained(parameter[\"model\"])\n","tokenizer.add_tokens(AddedToken(\"\\n\", normalized=False)) "]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["mixtral_data=json.load(open(mixtral_path))\n","dict_mixtral={\n","    \"full_text\": [x[\"full_text\"] for x in mixtral_data],\n","    \"document\": [str(x[\"document\"]) for x in mixtral_data],\n","    \"tokens\": [x[\"tokens\"] for x in mixtral_data],\n","    \"trailing_whitespace\": [x[\"trailing_whitespace\"] for x in mixtral_data],\n","    \"labels\": [x[\"labels\"] for x in mixtral_data],\n","}\n","data = json.load(open(train_path))\n","dict_train={\n","    \"full_text\": [x[\"full_text\"] for x in data],\n","    \"document\": [str(x[\"document\"]) for x in data],\n","    \"tokens\": [x[\"tokens\"] for x in data],\n","    \"trailing_whitespace\": [x[\"trailing_whitespace\"] for x in data],\n","    \"labels\": [x[\"labels\"] for x in data],\n","}\n","\n","full_data = {\n","    \"full_text\": dict_train[\"full_text\"] + dict_mixtral[\"full_text\"],\n","    \"document\": dict_train[\"document\"] + dict_mixtral[\"document\"],\n","    \"tokens\": dict_train[\"tokens\"] + dict_mixtral[\"tokens\"],\n","    \"trailing_whitespace\": dict_train[\"trailing_whitespace\"] + dict_mixtral[\"trailing_whitespace\"],\n","    \"labels\": dict_train[\"labels\"] + dict_mixtral[\"labels\"],\n","}"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5dd7ed07ebc24eb19104f5253a7abbc6","version_major":2,"version_minor":0},"text/plain":["Map (num_proc=16):   0%|          | 0/9499 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"daa86b10069646aa9e2f8d24d5ee2e31","version_major":2,"version_minor":0},"text/plain":["Filter (num_proc=16):   0%|          | 0/9499 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["train_len 7599\n","valid_len 1900\n"]}],"source":["ds = Dataset.from_dict(full_data)\n","\n","ds = ds.map(tokenize, fn_kwargs={\"tokenizer\": tokenizer, \"label2id\": label2id, \"max_length\": parameter[\"max_length\"], \"all_labels_list\": target}, num_proc=parameter[\"num_proc\"])\n","ds=ds.filter(filter_no_pii, num_proc=parameter[\"num_proc\"])\n","\n","\n","data_len=len(ds)\n","train_len=int(len(ds)*(1-parameter[\"train_test_split\"]))\n","valid_len=len(ds)-train_len\n","train_data_idx=np.random.choice(data_len, train_len, replace=False)\n","valid_data_idx=np.array(list(set(range(data_len))-set(train_data_idx)))\n","print(\"train_len\", train_len)\n","print(\"valid_len\", valid_len)\n","\n","# split ds in train and valid\n","train_ds=ds.select(train_data_idx)\n","valid_ds=ds.select(valid_data_idx)"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["def tokenize_inference(example, tokenizer, max_length):\n","        text = []\n","        for t,  ws in zip(example[\"tokens\"], example[\"trailing_whitespace\"]):\n","            text.append(t)\n","            if ws:\n","                text.append(\" \")\n","        tokenized = tokenizer(\"\".join(text), return_offsets_mapping=True, truncation=True, max_length=max_length, padding=\"max_length\")\n","        text = \"\".join(text)\n","        length = len(tokenized.input_ids)\n","        return {\n","            **tokenized,\n","            \"length\": length,\n","        }\n","        \n","class TestTokenizer():\n","    def __init__(self, tokenizer):\n","        self.tokenizer = tokenizer\n","    \n","    def preprocess(self, example):\n","        # Preprocess the tokens and labels by adding trailing whitespace and labels\n","        tokens = []\n","        tokens_without_ws = []\n","        token_map = [] # Use the index as labels\n","        index = 0\n","        for token, t_ws in zip(example[\"tokens\"], example[\"trailing_whitespace\"]):\n","            tokens_without_ws.append(token)\n","            tokens.append(token)\n","            token_map.extend([index] * len(token))\n","            # Added trailing whitespace and label if true and \n","            if t_ws:\n","                tokens.append(\" \")\n","                token_map.append(-1)\n","            index += 1\n","        return tokens, token_map, tokens_without_ws\n","    \n","    def tokenize(self, example):\n","        tokens, token_map, tokens_without_ws = self.preprocess(example)\n","        text = \"\".join(tokens)\n","        tokenized = self.tokenizer(text, return_offsets_mapping=True, padding=\"max_length\",\n","                                   truncation=True, max_length=parameter[\"inference_max_length\"])\n","        return {**tokenized, \"token_map\": token_map, \"tokens\": tokens, \"tokens_without_ws\": tokens_without_ws} \n","\n","class PiiDatasetInference(torch.utils.data.Dataset):\n","        def __init__(self, dataset, tokenizer):\n","            self.dataset = dataset\n","            self.tokenizer=TestTokenizer(tokenizer)\n","            \n","        def __getitem__(self, idx):\n","            vals=self.tokenizer.tokenize(self.dataset[idx])\n","            input_ids = torch.tensor(vals[\"input_ids\"])\n","            attention_mask = torch.tensor(vals[\"attention_mask\"])\n","            document_id = self.dataset[idx][\"document\"]\n","            return input_ids, attention_mask, document_id, vals\n","        \n","        def __len__(self):\n","            return len(self.dataset)\n","\n","# Convert preds to a list of dictionaries\n","def to_test_submission(preds=None, dataset=None, document_ids=None, id2label=None):\n","    pairs = []\n","    row_id = 0\n","    results = []\n","    \n","    for i in range(len(preds)):\n","        input_ids, attention_mask, document_id, vals = dataset[i]\n","        token_map=vals[\"token_map\"]\n","        offsets=vals[\"offset_mapping\"]\n","        tokens=vals[\"tokens_without_ws\"]\n","        #print(\"tokens\", tokens)\n","        pred=preds[i]\n","        #print(\"original_text\", original_text)\n","        #print(\"token_map\", token_map)\n","        #print(\"offsets\", offsets)   \n","        #print(\"pred\", pred)\n","\n","\n","        for token_pred, input_id, (start_idx, end_idx) in zip(pred, input_ids, offsets):\n","            #print(\"\\nnow doing \", start_idx,  end_idx, token_pred)\n","            if start_idx == 0 and end_idx == 0: # Skip 0 offset\n","                continue\n","            # Skip spaces \n","            while start_idx < len(token_map):\n","                #print(\"loop, start_idx now\", start_idx) \n","                #print(\" tokens[token_map[start_idx]]: \", tokens[token_map[start_idx]] if not tokens[token_map[start_idx]].isspace() else \"WHITESPACE\")          \n","                if token_map[start_idx] == -1: # Skip unknown tokens               \n","                    start_idx += 1\n","                elif tokens[token_map[start_idx]].isspace(): # Skip white space\n","                    start_idx += 1\n","                else:\n","                    break\n","            # Ensure start index < length\n","            if start_idx < len(token_map):\n","                token_id = token_map[start_idx]\n","                #print(\"token_id\", token_id)\n","                #token_id= input_id.item()\n","                label_pred = id2label[token_pred.item()]\n","                #print(\"label_pred\", label_pred)\n","                # ignore \"O\" and whitespace preds\n","                if label_pred != \"O\" and token_id != -1:\n","                    #print(\"is PII\", token_id, label_pred)\n","                    token_str = tokens[token_id]\n","                    pair=(document_id, token_id)\n","                    if pair not in pairs:\n","                        results.append({\n","                            \"row_id\": row_id, \n","                            \"document\": document_id,\n","                            \"token\": token_id, \n","                            \"label\": label_pred,\n","                            \"token_str\": token_str\n","                        })\n","                        pairs.append(pair)\n","                        row_id += 1\n","\n","    # Create a dataframe \n","    return results\n","\n","def create_submission(model, filename=\"submission.csv\"):\n","    data = json.load(open(train_path))\n","    from itertools import chain\n","    all_labels = sorted(list(set(chain(*[x[\"labels\"] for x in data]))))\n","    label2id = {l: i for i,l in enumerate(all_labels)}\n","    id2label = {v:k for k,v in label2id.items()}\n","\n","    data=json.load(open(test_path))\n","    tokenizer = AutoTokenizer.from_pretrained(parameter[\"model\"])\n","    my_dataset=PiiDatasetInference(data, tokenizer)\n","    loader=torch.utils.data.DataLoader(my_dataset, batch_size=1, shuffle=False)\n","\n","    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    model.eval()\n","    \n","    # stack all predictions into tensor\n","    all_preds = []\n","\n","    for id, attention_mask, document_ids, vals in loader:\n","        id=id.to(device)\n","        attention_mask=attention_mask.to(device)\n","        preds=model(id, attention_mask).get('logits').argmax(dim=2)\n","        all_preds.append(preds)\n","        #for pred, id in zip(preds.flatten(), id.flatten()):\n","        #    if pred != 12:\n","                #print(f\"Document: {document_id.item()} TOKEN:{tokenizer.decode(id)}  --- pred:{id2label[pred.item()]}\")\n","        #        output[row_id]={\"document\":document_id.item(), \"token\":id.item(), \"label\":id2label[pred.item()]}\n","        #        row_id+=1\n","        #for pred, id in zip(preds.flatten(), id.flatten()):\n","        #    if pred != 12:\n","        #        print(f\"TOKEN:{tokenizer.decode(id)}  --- pred:{id2label[pred.item()]}\")\n","    \n","   \n","    all_preds = torch.cat(all_preds, dim=0)\n","    \n","    results = to_test_submission(preds=all_preds, dataset=my_dataset, document_ids=document_ids, id2label=id2label)\n","    if len(results) == 0:\n","        print(\"Error in create_submission(): No predictions made, probably because the model is not learning. Check the model and the data.\")\n","        return\n","    df = pd.DataFrame(results)\n","    df=df[[\"row_id\", \"document\", \"token\", \"label\"]]\n","    print(df)\n","    df.to_csv(filename, index=False)\n","\n","#create_submission(MyModel(parameter['model'], len(label2id)).to(device), \"submission_just_dumb.csv\")\n","# create_submission(model, \"submission.csv\")\n","    \n","\n","\n"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["from transformers import DataCollatorForTokenClassification\n","\n","collator = DataCollatorForTokenClassification(tokenizer, pad_to_multiple_of=16)"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["# using Trainer and TrainingArguments from transformers\n","\n","\n","def compute_metrics(p, all_labels):\n","    predictions, labels = p\n","    predictions = np.argmax(predictions, axis=2)\n","\n","    # Remove ignored index (special tokens)\n","    true_predictions = [\n","        [all_labels[p] for (p, l) in zip(prediction, label) if l != -100]\n","        for prediction, label in zip(predictions, labels)\n","    ]\n","    true_labels = [\n","        [all_labels[l] for (p, l) in zip(prediction, label) if l != -100]\n","        for prediction, label in zip(predictions, labels)\n","    ]\n","    \n","    recall = recall_score(true_labels, true_predictions)\n","    precision = precision_score(true_labels, true_predictions)\n","    f1_score = (1 + 5*5) * recall * precision / (5*5*precision + recall)\n","    \n","    results = {\n","        'recall': recall,\n","        'precision': precision,\n","        'f1': f1_score\n","    }\n","    return results\n","\n","from functools import partial\n","\n","def get_trainer(model, train_dataloader, valid_dataloader, learnrate_multiplier=1.0):\n","\n","    if not kaggle:\n","        from transformers.integrations import NeptuneCallback\n","\n","        run = neptune.init_run(\n","            project=\"bernd.heidemann/PII\",\n","            api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiIzNjBlYzVkNi0zZTUwLTQ1ODYtODhlNC02NDUxNDg0MDdjNzUifQ==\",\n","        )  # your credentials\n","        run[\"parameters\"] = {\n","        **parameter\n","        }\n","\n","        neptune_callback = NeptuneCallback(run=run, log_model_weights=False, log_parameters=False)\n","\n","    training_args = TrainingArguments(\n","        output_dir='./results',          # output directory\n","        num_train_epochs=parameter[\"epochs_before_unfreeze\"],              # total number of training epochs\n","        per_device_train_batch_size=parameter[\"batch_size\"],  # batch size per device during training\n","        per_device_eval_batch_size=parameter[\"inference_batch_size\"],   # batch size for evaluation\n","        warmup_steps=500,                # number of warmup steps for learning rate scheduler\n","        weight_decay=0.01,               # strength of weight decay\n","        logging_dir='./logs',            # directory for storing logs\n","        logging_steps=10,\n","        evaluation_strategy=\"steps\",\n","        eval_steps=400,\n","        save_steps=400,\n","        save_total_limit=3,\n","        load_best_model_at_end=False,\n","        metric_for_best_model=\"f1\" if not kaggle else \"eval_loss\",\n","        greater_is_better=True,\n","        overwrite_output_dir=True,\n","        report_to=\"none\",\n","        learning_rate=parameter[\"lr\"]*learnrate_multiplier\n","    )\n","\n","    class MyTrainer(Trainer):\n","        def __init__(self, model=None, args=None, train_dataset=None, eval_dataset=None, compute_metrics=None, callbacks=None):\n","            super().__init__(model=model, args=args, train_dataset=train_dataset, eval_dataset=eval_dataset, compute_metrics=compute_metrics, callbacks=callbacks)\n","            # Definieren Sie hier Ihre Gewichte fÃ¼r die Klassen, z.B. torch.tensor([1.0, 2.0, 0.5])\n","            self.weight = torch.tensor(CROSS_ENTROPY_WEIGHTS).to(device)\n","            self.loss_func=torch.nn.CrossEntropyLoss(ignore_index=-100, weight=torch.tensor(CROSS_ENTROPY_WEIGHTS, dtype=torch.float32).to(device))\n","\n","        def compute_loss(self, model, inputs, return_outputs=False):\n","            labels = inputs.get(\"labels\")\n","            outputs = model(**inputs)\n","            logits = outputs.get('logits')\n","            loss = self.loss_func(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n","            return (loss, outputs) if return_outputs else loss\n","        \n","\n","    trainer = MyTrainer(\n","        model=model,                         # the instantiated ðŸ¤— Transformers model to be trained\n","        args=training_args,                  # training arguments, defined above\n","        train_dataset=train_dataloader,         # training dataset\n","        eval_dataset=valid_dataloader,             # evaluation dataset\n","        compute_metrics=partial(compute_metrics, all_labels=all_labels) if not kaggle else None,\n","        callbacks=[neptune_callback] if not kaggle else None\n","    )\n","    return trainer"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["def unfreeze(model):\n","    for param in model.base_model.parameters():\n","        param.requires_grad = True\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of DebertaV2ForTokenClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","c:\\Users\\Bernd\\anaconda3\\envs\\mytorch\\lib\\site-packages\\neptune\\common\\warnings.py:71: NeptuneWarning: The following monitoring options are disabled by default in interactive sessions: 'capture_stdout', 'capture_stderr', 'capture_traceback', and 'capture_hardware_metrics'. To enable them, set each parameter to 'True' when initializing the run. The monitoring will continue until you call run.stop() or the kernel stops. Also note: Your source files can only be tracked if you pass the path(s) to the 'source_code' argument. For help, see the Neptune docs: https://docs.neptune.ai/logging/source_code/\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"B-EMAIL\",\n","    \"1\": \"B-ID_NUM\",\n","    \"2\": \"B-NAME_STUDENT\",\n","    \"3\": \"B-PHONE_NUM\",\n","    \"4\": \"B-STREET_ADDRESS\",\n","    \"5\": \"B-URL_PERSONAL\",\n","    \"6\": \"B-USERNAME\",\n","    \"7\": \"I-ID_NUM\",\n","    \"8\": \"I-NAME_STUDENT\",\n","    \"9\": \"I-PHONE_NUM\",\n","    \"10\": \"I-STREET_ADDRESS\",\n","    \"11\": \"I-URL_PERSONAL\",\n","    \"12\": \"O\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"B-EMAIL\": 0,\n","    \"B-ID_NUM\": 1,\n","    \"B-NAME_STUDENT\": 2,\n","    \"B-PHONE_NUM\": 3,\n","    \"B-STREET_ADDRESS\": 4,\n","    \"B-URL_PERSONAL\": 5,\n","    \"B-USERNAME\": 6,\n","    \"I-ID_NUM\": 7,\n","    \"I-NAME_STUDENT\": 8,\n","    \"I-PHONE_NUM\": 9,\n","    \"I-STREET_ADDRESS\": 10,\n","    \"I-URL_PERSONAL\": 11,\n","    \"O\": 12\n","  },\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.31.0\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","https://app.neptune.ai/bernd.heidemann/PII/e/PII-222\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\Bernd\\anaconda3\\envs\\mytorch\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f335f4b16c984bbba46281b67e675fea","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/3800 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'loss': 2.6708, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.01}\n","{'loss': 2.6521, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.01}\n","{'loss': 2.5128, 'learning_rate': 3e-06, 'epoch': 0.02}\n","{'loss': 2.428, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.02}\n","{'loss': 2.3913, 'learning_rate': 5e-06, 'epoch': 0.03}\n","{'loss': 1.9391, 'learning_rate': 6e-06, 'epoch': 0.03}\n","{'loss': 1.8615, 'learning_rate': 7.000000000000001e-06, 'epoch': 0.04}\n","{'loss': 1.458, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.04}\n","{'loss': 1.2186, 'learning_rate': 9e-06, 'epoch': 0.05}\n","{'loss': 1.1076, 'learning_rate': 1e-05, 'epoch': 0.05}\n","{'loss': 0.8905, 'learning_rate': 1.1000000000000001e-05, 'epoch': 0.06}\n","{'loss': 0.8465, 'learning_rate': 1.2e-05, 'epoch': 0.06}\n","{'loss': 1.3269, 'learning_rate': 1.3000000000000001e-05, 'epoch': 0.07}\n","{'loss': 0.8295, 'learning_rate': 1.4000000000000001e-05, 'epoch': 0.07}\n","{'loss': 0.7895, 'learning_rate': 1.5e-05, 'epoch': 0.08}\n","{'loss': 0.9105, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.08}\n","{'loss': 0.6292, 'learning_rate': 1.7000000000000003e-05, 'epoch': 0.09}\n","{'loss': 0.6644, 'learning_rate': 1.8e-05, 'epoch': 0.09}\n","{'loss': 0.5737, 'learning_rate': 1.9e-05, 'epoch': 0.1}\n","{'loss': 0.7443, 'learning_rate': 2e-05, 'epoch': 0.11}\n","{'loss': 0.7853, 'learning_rate': 2.1e-05, 'epoch': 0.11}\n","{'loss': 0.5704, 'learning_rate': 2.2000000000000003e-05, 'epoch': 0.12}\n","{'loss': 0.4581, 'learning_rate': 2.3000000000000003e-05, 'epoch': 0.12}\n","{'loss': 0.4299, 'learning_rate': 2.4e-05, 'epoch': 0.13}\n","{'loss': 0.1547, 'learning_rate': 2.5e-05, 'epoch': 0.13}\n","{'loss': 0.3599, 'learning_rate': 2.6000000000000002e-05, 'epoch': 0.14}\n","{'loss': 0.3966, 'learning_rate': 2.7000000000000002e-05, 'epoch': 0.14}\n","{'loss': 0.151, 'learning_rate': 2.8000000000000003e-05, 'epoch': 0.15}\n","{'loss': 0.2691, 'learning_rate': 2.9e-05, 'epoch': 0.15}\n","{'loss': 0.1875, 'learning_rate': 3e-05, 'epoch': 0.16}\n","{'loss': 0.2313, 'learning_rate': 3.1e-05, 'epoch': 0.16}\n","{'loss': 0.2348, 'learning_rate': 3.2000000000000005e-05, 'epoch': 0.17}\n","{'loss': 0.0587, 'learning_rate': 3.3e-05, 'epoch': 0.17}\n","{'loss': 0.2046, 'learning_rate': 3.4000000000000007e-05, 'epoch': 0.18}\n","{'loss': 0.1906, 'learning_rate': 3.5e-05, 'epoch': 0.18}\n","{'loss': 0.0603, 'learning_rate': 3.6e-05, 'epoch': 0.19}\n","{'loss': 0.165, 'learning_rate': 3.7e-05, 'epoch': 0.19}\n","{'loss': 0.1303, 'learning_rate': 3.8e-05, 'epoch': 0.2}\n","{'loss': 0.2217, 'learning_rate': 3.9000000000000006e-05, 'epoch': 0.21}\n","{'loss': 0.1258, 'learning_rate': 4e-05, 'epoch': 0.21}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"591340b91f98488596ca100a2d3d7b4a","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1900 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.04443526640534401, 'eval_recall': 0.9085017155928327, 'eval_precision': 0.5760212714527435, 'eval_f1': 0.8887709433096167, 'eval_runtime': 59.7059, 'eval_samples_per_second': 31.823, 'eval_steps_per_second': 31.823, 'epoch': 0.21}\n","{'loss': 0.1398, 'learning_rate': 4.1e-05, 'epoch': 0.22}\n","{'loss': 0.1358, 'learning_rate': 4.2e-05, 'epoch': 0.22}\n","{'loss': 0.1983, 'learning_rate': 4.3e-05, 'epoch': 0.23}\n","{'loss': 0.1682, 'learning_rate': 4.4000000000000006e-05, 'epoch': 0.23}\n","{'loss': 0.0754, 'learning_rate': 4.5e-05, 'epoch': 0.24}\n","{'loss': 0.1455, 'learning_rate': 4.600000000000001e-05, 'epoch': 0.24}\n","{'loss': 0.2356, 'learning_rate': 4.7e-05, 'epoch': 0.25}\n","{'loss': 0.1719, 'learning_rate': 4.8e-05, 'epoch': 0.25}\n","{'loss': 0.1367, 'learning_rate': 4.9e-05, 'epoch': 0.26}\n","{'loss': 0.0431, 'learning_rate': 5e-05, 'epoch': 0.26}\n","{'loss': 0.2647, 'learning_rate': 4.984848484848485e-05, 'epoch': 0.27}\n","{'loss': 0.0537, 'learning_rate': 4.9696969696969694e-05, 'epoch': 0.27}\n","{'loss': 0.2632, 'learning_rate': 4.9545454545454553e-05, 'epoch': 0.28}\n","{'loss': 0.1653, 'learning_rate': 4.93939393939394e-05, 'epoch': 0.28}\n","{'loss': 0.103, 'learning_rate': 4.9242424242424245e-05, 'epoch': 0.29}\n","{'loss': 0.16, 'learning_rate': 4.909090909090909e-05, 'epoch': 0.29}\n","{'loss': 0.0303, 'learning_rate': 4.8939393939393944e-05, 'epoch': 0.3}\n","{'loss': 0.0541, 'learning_rate': 4.878787878787879e-05, 'epoch': 0.31}\n","{'loss': 0.2502, 'learning_rate': 4.863636363636364e-05, 'epoch': 0.31}\n","{'loss': 0.0659, 'learning_rate': 4.848484848484849e-05, 'epoch': 0.32}\n","{'loss': 0.0901, 'learning_rate': 4.8333333333333334e-05, 'epoch': 0.32}\n","{'loss': 0.0507, 'learning_rate': 4.8181818181818186e-05, 'epoch': 0.33}\n","{'loss': 0.2143, 'learning_rate': 4.803030303030303e-05, 'epoch': 0.33}\n","{'loss': 0.175, 'learning_rate': 4.787878787878788e-05, 'epoch': 0.34}\n","{'loss': 0.1754, 'learning_rate': 4.772727272727273e-05, 'epoch': 0.34}\n","{'loss': 0.1015, 'learning_rate': 4.7575757575757576e-05, 'epoch': 0.35}\n","{'loss': 0.0361, 'learning_rate': 4.742424242424243e-05, 'epoch': 0.35}\n","{'loss': 0.0538, 'learning_rate': 4.7272727272727275e-05, 'epoch': 0.36}\n","{'loss': 0.2102, 'learning_rate': 4.712121212121212e-05, 'epoch': 0.36}\n","{'loss': 0.0263, 'learning_rate': 4.696969696969697e-05, 'epoch': 0.37}\n","{'loss': 0.1703, 'learning_rate': 4.681818181818182e-05, 'epoch': 0.37}\n","{'loss': 0.0801, 'learning_rate': 4.666666666666667e-05, 'epoch': 0.38}\n","{'loss': 0.0199, 'learning_rate': 4.651515151515152e-05, 'epoch': 0.38}\n","{'loss': 0.2114, 'learning_rate': 4.636363636363636e-05, 'epoch': 0.39}\n","{'loss': 0.0253, 'learning_rate': 4.621212121212121e-05, 'epoch': 0.39}\n","{'loss': 0.0309, 'learning_rate': 4.606060606060607e-05, 'epoch': 0.4}\n","{'loss': 0.3978, 'learning_rate': 4.5909090909090914e-05, 'epoch': 0.41}\n","{'loss': 0.0349, 'learning_rate': 4.575757575757576e-05, 'epoch': 0.41}\n","{'loss': 0.0708, 'learning_rate': 4.5606060606060606e-05, 'epoch': 0.42}\n","{'loss': 0.0068, 'learning_rate': 4.545454545454546e-05, 'epoch': 0.42}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"aaa066eed34d424f934eb2b0995ac8fe","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1900 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.011398006230592728, 'eval_recall': 0.98131910026687, 'eval_precision': 0.8414514547237659, 'eval_f1': 0.9750852347233148, 'eval_runtime': 63.7345, 'eval_samples_per_second': 29.811, 'eval_steps_per_second': 29.811, 'epoch': 0.42}\n","{'loss': 0.0043, 'learning_rate': 4.5303030303030304e-05, 'epoch': 0.43}\n","{'loss': 0.0218, 'learning_rate': 4.515151515151516e-05, 'epoch': 0.43}\n","{'loss': 0.0976, 'learning_rate': 4.5e-05, 'epoch': 0.44}\n","{'loss': 0.0687, 'learning_rate': 4.484848484848485e-05, 'epoch': 0.44}\n","{'loss': 0.0653, 'learning_rate': 4.46969696969697e-05, 'epoch': 0.45}\n","{'loss': 0.102, 'learning_rate': 4.454545454545455e-05, 'epoch': 0.45}\n","{'loss': 0.0707, 'learning_rate': 4.43939393939394e-05, 'epoch': 0.46}\n","{'loss': 0.0138, 'learning_rate': 4.4242424242424246e-05, 'epoch': 0.46}\n","{'loss': 0.0684, 'learning_rate': 4.409090909090909e-05, 'epoch': 0.47}\n","{'loss': 0.0806, 'learning_rate': 4.3939393939393944e-05, 'epoch': 0.47}\n","{'loss': 0.0305, 'learning_rate': 4.378787878787879e-05, 'epoch': 0.48}\n","{'loss': 0.1081, 'learning_rate': 4.3636363636363636e-05, 'epoch': 0.48}\n","{'loss': 0.0826, 'learning_rate': 4.348484848484849e-05, 'epoch': 0.49}\n","{'loss': 0.1047, 'learning_rate': 4.3333333333333334e-05, 'epoch': 0.49}\n","{'loss': 0.0329, 'learning_rate': 4.318181818181819e-05, 'epoch': 0.5}\n","{'loss': 0.0035, 'learning_rate': 4.303030303030303e-05, 'epoch': 0.51}\n","{'loss': 0.0507, 'learning_rate': 4.287878787878788e-05, 'epoch': 0.51}\n","{'loss': 0.0238, 'learning_rate': 4.2727272727272724e-05, 'epoch': 0.52}\n","{'loss': 0.0152, 'learning_rate': 4.257575757575758e-05, 'epoch': 0.52}\n","{'loss': 0.0594, 'learning_rate': 4.242424242424243e-05, 'epoch': 0.53}\n","{'loss': 0.1144, 'learning_rate': 4.2272727272727275e-05, 'epoch': 0.53}\n","{'loss': 0.0464, 'learning_rate': 4.212121212121212e-05, 'epoch': 0.54}\n","{'loss': 0.0367, 'learning_rate': 4.196969696969697e-05, 'epoch': 0.54}\n","{'loss': 0.0549, 'learning_rate': 4.181818181818182e-05, 'epoch': 0.55}\n","{'loss': 0.0649, 'learning_rate': 4.166666666666667e-05, 'epoch': 0.55}\n","{'loss': 0.0186, 'learning_rate': 4.151515151515152e-05, 'epoch': 0.56}\n","{'loss': 0.0711, 'learning_rate': 4.1363636363636364e-05, 'epoch': 0.56}\n","{'loss': 0.0064, 'learning_rate': 4.1212121212121216e-05, 'epoch': 0.57}\n","{'loss': 0.09, 'learning_rate': 4.106060606060606e-05, 'epoch': 0.57}\n","{'loss': 0.0175, 'learning_rate': 4.0909090909090915e-05, 'epoch': 0.58}\n","{'loss': 0.0053, 'learning_rate': 4.075757575757576e-05, 'epoch': 0.58}\n","{'loss': 0.0319, 'learning_rate': 4.0606060606060606e-05, 'epoch': 0.59}\n","{'loss': 0.1286, 'learning_rate': 4.045454545454546e-05, 'epoch': 0.59}\n","{'loss': 0.0812, 'learning_rate': 4.0303030303030305e-05, 'epoch': 0.6}\n","{'loss': 0.0152, 'learning_rate': 4.015151515151515e-05, 'epoch': 0.61}\n","{'loss': 0.0131, 'learning_rate': 4e-05, 'epoch': 0.61}\n","{'loss': 0.0463, 'learning_rate': 3.984848484848485e-05, 'epoch': 0.62}\n","{'loss': 0.0446, 'learning_rate': 3.96969696969697e-05, 'epoch': 0.62}\n","{'loss': 0.0086, 'learning_rate': 3.954545454545455e-05, 'epoch': 0.63}\n","{'loss': 0.0199, 'learning_rate': 3.939393939393939e-05, 'epoch': 0.63}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9a9fa640b18843ffbac4056a2e70ad08","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1900 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.014275087043642998, 'eval_recall': 0.967848519506926, 'eval_precision': 0.8439716312056738, 'eval_f1': 0.9624153701840594, 'eval_runtime': 58.6956, 'eval_samples_per_second': 32.37, 'eval_steps_per_second': 32.37, 'epoch': 0.63}\n","{'loss': 0.0722, 'learning_rate': 3.924242424242424e-05, 'epoch': 0.64}\n","{'loss': 0.0507, 'learning_rate': 3.909090909090909e-05, 'epoch': 0.64}\n","{'loss': 0.0051, 'learning_rate': 3.8939393939393944e-05, 'epoch': 0.65}\n","{'loss': 0.0834, 'learning_rate': 3.878787878787879e-05, 'epoch': 0.65}\n","{'loss': 0.0637, 'learning_rate': 3.8636363636363636e-05, 'epoch': 0.66}\n","{'loss': 0.0132, 'learning_rate': 3.848484848484848e-05, 'epoch': 0.66}\n","{'loss': 0.0096, 'learning_rate': 3.8333333333333334e-05, 'epoch': 0.67}\n","{'loss': 0.0055, 'learning_rate': 3.818181818181819e-05, 'epoch': 0.67}\n","{'loss': 0.1119, 'learning_rate': 3.803030303030303e-05, 'epoch': 0.68}\n","{'loss': 0.0053, 'learning_rate': 3.787878787878788e-05, 'epoch': 0.68}\n","{'loss': 0.0969, 'learning_rate': 3.7727272727272725e-05, 'epoch': 0.69}\n","{'loss': 0.0206, 'learning_rate': 3.757575757575758e-05, 'epoch': 0.69}\n","{'loss': 0.0027, 'learning_rate': 3.742424242424243e-05, 'epoch': 0.7}\n","{'loss': 0.0266, 'learning_rate': 3.7272727272727276e-05, 'epoch': 0.71}\n","{'loss': 0.0054, 'learning_rate': 3.712121212121212e-05, 'epoch': 0.71}\n","{'loss': 0.0203, 'learning_rate': 3.6969696969696974e-05, 'epoch': 0.72}\n","{'loss': 0.2027, 'learning_rate': 3.681818181818182e-05, 'epoch': 0.72}\n","{'loss': 0.0135, 'learning_rate': 3.6666666666666666e-05, 'epoch': 0.73}\n","{'loss': 0.0053, 'learning_rate': 3.651515151515152e-05, 'epoch': 0.73}\n","{'loss': 0.0203, 'learning_rate': 3.6363636363636364e-05, 'epoch': 0.74}\n","{'loss': 0.1547, 'learning_rate': 3.621212121212122e-05, 'epoch': 0.74}\n","{'loss': 0.0077, 'learning_rate': 3.606060606060606e-05, 'epoch': 0.75}\n","{'loss': 0.0516, 'learning_rate': 3.590909090909091e-05, 'epoch': 0.75}\n","{'loss': 0.0111, 'learning_rate': 3.575757575757576e-05, 'epoch': 0.76}\n","{'loss': 0.0146, 'learning_rate': 3.560606060606061e-05, 'epoch': 0.76}\n","{'loss': 0.0012, 'learning_rate': 3.545454545454546e-05, 'epoch': 0.77}\n","{'loss': 0.0015, 'learning_rate': 3.5303030303030305e-05, 'epoch': 0.77}\n","{'loss': 0.0013, 'learning_rate': 3.515151515151515e-05, 'epoch': 0.78}\n","{'loss': 0.0183, 'learning_rate': 3.5e-05, 'epoch': 0.78}\n","{'loss': 0.0086, 'learning_rate': 3.484848484848485e-05, 'epoch': 0.79}\n","{'loss': 0.0076, 'learning_rate': 3.46969696969697e-05, 'epoch': 0.79}\n","{'loss': 0.0044, 'learning_rate': 3.454545454545455e-05, 'epoch': 0.8}\n","{'loss': 0.0031, 'learning_rate': 3.4393939393939394e-05, 'epoch': 0.81}\n","{'loss': 0.0029, 'learning_rate': 3.424242424242424e-05, 'epoch': 0.81}\n","{'loss': 0.005, 'learning_rate': 3.409090909090909e-05, 'epoch': 0.82}\n","{'loss': 0.0368, 'learning_rate': 3.3939393939393945e-05, 'epoch': 0.82}\n","{'loss': 0.0096, 'learning_rate': 3.378787878787879e-05, 'epoch': 0.83}\n","{'loss': 0.0265, 'learning_rate': 3.3636363636363636e-05, 'epoch': 0.83}\n","{'loss': 0.0314, 'learning_rate': 3.348484848484848e-05, 'epoch': 0.84}\n","{'loss': 0.0234, 'learning_rate': 3.3333333333333335e-05, 'epoch': 0.84}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1864c68e5ac04218a98008450114284c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1900 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.020421413704752922, 'eval_recall': 0.9715338670733257, 'eval_precision': 0.8726172811322909, 'eval_f1': 0.9673165081806061, 'eval_runtime': 58.8324, 'eval_samples_per_second': 32.295, 'eval_steps_per_second': 32.295, 'epoch': 0.84}\n","{'loss': 0.0107, 'learning_rate': 3.318181818181819e-05, 'epoch': 0.85}\n","{'loss': 0.0183, 'learning_rate': 3.303030303030303e-05, 'epoch': 0.85}\n","{'loss': 0.0075, 'learning_rate': 3.287878787878788e-05, 'epoch': 0.86}\n","{'loss': 0.0239, 'learning_rate': 3.272727272727273e-05, 'epoch': 0.86}\n","{'loss': 0.0568, 'learning_rate': 3.257575757575758e-05, 'epoch': 0.87}\n","{'loss': 0.0106, 'learning_rate': 3.2424242424242423e-05, 'epoch': 0.87}\n","{'loss': 0.0784, 'learning_rate': 3.2272727272727276e-05, 'epoch': 0.88}\n","{'loss': 0.0337, 'learning_rate': 3.212121212121212e-05, 'epoch': 0.88}\n","{'loss': 0.0346, 'learning_rate': 3.1969696969696974e-05, 'epoch': 0.89}\n","{'loss': 0.0064, 'learning_rate': 3.181818181818182e-05, 'epoch': 0.89}\n","{'loss': 0.0153, 'learning_rate': 3.1666666666666666e-05, 'epoch': 0.9}\n","{'loss': 0.1104, 'learning_rate': 3.151515151515151e-05, 'epoch': 0.91}\n","{'loss': 0.3928, 'learning_rate': 3.1363636363636365e-05, 'epoch': 0.91}\n","{'loss': 0.0463, 'learning_rate': 3.121212121212122e-05, 'epoch': 0.92}\n","{'loss': 0.0208, 'learning_rate': 3.106060606060606e-05, 'epoch': 0.92}\n","{'loss': 0.0101, 'learning_rate': 3.090909090909091e-05, 'epoch': 0.93}\n","{'loss': 0.0236, 'learning_rate': 3.0757575757575755e-05, 'epoch': 0.93}\n","{'loss': 0.0041, 'learning_rate': 3.060606060606061e-05, 'epoch': 0.94}\n","{'loss': 0.0438, 'learning_rate': 3.0454545454545456e-05, 'epoch': 0.94}\n","{'loss': 0.0715, 'learning_rate': 3.0303030303030306e-05, 'epoch': 0.95}\n","{'loss': 0.0104, 'learning_rate': 3.015151515151515e-05, 'epoch': 0.95}\n","{'loss': 0.0144, 'learning_rate': 3e-05, 'epoch': 0.96}\n","{'loss': 0.0552, 'learning_rate': 2.9848484848484847e-05, 'epoch': 0.96}\n","{'loss': 0.018, 'learning_rate': 2.96969696969697e-05, 'epoch': 0.97}\n","{'loss': 0.0375, 'learning_rate': 2.954545454545455e-05, 'epoch': 0.97}\n","{'loss': 0.0945, 'learning_rate': 2.9393939393939394e-05, 'epoch': 0.98}\n","{'loss': 0.0053, 'learning_rate': 2.9242424242424243e-05, 'epoch': 0.98}\n","{'loss': 0.12, 'learning_rate': 2.909090909090909e-05, 'epoch': 0.99}\n","{'loss': 0.0075, 'learning_rate': 2.893939393939394e-05, 'epoch': 0.99}\n","{'loss': 0.0035, 'learning_rate': 2.878787878787879e-05, 'epoch': 1.0}\n","{'loss': 0.0738, 'learning_rate': 2.863636363636364e-05, 'epoch': 1.01}\n","{'loss': 0.0009, 'learning_rate': 2.8484848484848486e-05, 'epoch': 1.01}\n","{'loss': 0.0357, 'learning_rate': 2.8333333333333335e-05, 'epoch': 1.02}\n","{'loss': 0.0032, 'learning_rate': 2.818181818181818e-05, 'epoch': 1.02}\n","{'loss': 0.0034, 'learning_rate': 2.803030303030303e-05, 'epoch': 1.03}\n","{'loss': 0.0045, 'learning_rate': 2.7878787878787883e-05, 'epoch': 1.03}\n","{'loss': 0.0095, 'learning_rate': 2.772727272727273e-05, 'epoch': 1.04}\n","{'loss': 0.0114, 'learning_rate': 2.7575757575757578e-05, 'epoch': 1.04}\n","{'loss': 0.0047, 'learning_rate': 2.7424242424242424e-05, 'epoch': 1.05}\n","{'loss': 0.0085, 'learning_rate': 2.7272727272727273e-05, 'epoch': 1.05}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6edc03dee32946de919fc8c1b36ef246","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1900 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.02042432501912117, 'eval_recall': 0.9692464099631465, 'eval_precision': 0.8905885100420364, 'eval_f1': 0.9659650541431832, 'eval_runtime': 58.798, 'eval_samples_per_second': 32.314, 'eval_steps_per_second': 32.314, 'epoch': 1.05}\n","{'loss': 0.0015, 'learning_rate': 2.7121212121212126e-05, 'epoch': 1.06}\n","{'loss': 0.0002, 'learning_rate': 2.696969696969697e-05, 'epoch': 1.06}\n","{'loss': 0.0008, 'learning_rate': 2.681818181818182e-05, 'epoch': 1.07}\n","{'loss': 0.0004, 'learning_rate': 2.6666666666666667e-05, 'epoch': 1.07}\n","{'loss': 0.0027, 'learning_rate': 2.6515151515151516e-05, 'epoch': 1.08}\n","{'loss': 0.0171, 'learning_rate': 2.636363636363636e-05, 'epoch': 1.08}\n","{'loss': 0.0086, 'learning_rate': 2.6212121212121214e-05, 'epoch': 1.09}\n","{'loss': 0.0393, 'learning_rate': 2.6060606060606063e-05, 'epoch': 1.09}\n","{'loss': 0.0165, 'learning_rate': 2.590909090909091e-05, 'epoch': 1.1}\n","{'loss': 0.0017, 'learning_rate': 2.575757575757576e-05, 'epoch': 1.11}\n","{'loss': 0.0044, 'learning_rate': 2.5606060606060604e-05, 'epoch': 1.11}\n","{'loss': 0.0011, 'learning_rate': 2.5454545454545454e-05, 'epoch': 1.12}\n","{'loss': 0.0768, 'learning_rate': 2.5303030303030306e-05, 'epoch': 1.12}\n","{'loss': 0.0047, 'learning_rate': 2.5151515151515155e-05, 'epoch': 1.13}\n","{'loss': 0.0876, 'learning_rate': 2.5e-05, 'epoch': 1.13}\n","{'loss': 0.0003, 'learning_rate': 2.4848484848484847e-05, 'epoch': 1.14}\n","{'loss': 0.0038, 'learning_rate': 2.46969696969697e-05, 'epoch': 1.14}\n","{'loss': 0.0033, 'learning_rate': 2.4545454545454545e-05, 'epoch': 1.15}\n","{'loss': 0.0009, 'learning_rate': 2.4393939393939395e-05, 'epoch': 1.15}\n","{'loss': 0.0034, 'learning_rate': 2.4242424242424244e-05, 'epoch': 1.16}\n","{'loss': 0.0027, 'learning_rate': 2.4090909090909093e-05, 'epoch': 1.16}\n","{'loss': 0.0024, 'learning_rate': 2.393939393939394e-05, 'epoch': 1.17}\n","{'loss': 0.0002, 'learning_rate': 2.3787878787878788e-05, 'epoch': 1.17}\n","{'loss': 0.0014, 'learning_rate': 2.3636363636363637e-05, 'epoch': 1.18}\n","{'loss': 0.0008, 'learning_rate': 2.3484848484848487e-05, 'epoch': 1.18}\n","{'loss': 0.0009, 'learning_rate': 2.3333333333333336e-05, 'epoch': 1.19}\n","{'loss': 0.0008, 'learning_rate': 2.318181818181818e-05, 'epoch': 1.19}\n","{'loss': 0.0467, 'learning_rate': 2.3030303030303034e-05, 'epoch': 1.2}\n","{'loss': 0.0015, 'learning_rate': 2.287878787878788e-05, 'epoch': 1.21}\n","{'loss': 0.116, 'learning_rate': 2.272727272727273e-05, 'epoch': 1.21}\n","{'loss': 0.1233, 'learning_rate': 2.257575757575758e-05, 'epoch': 1.22}\n","{'loss': 0.0025, 'learning_rate': 2.2424242424242424e-05, 'epoch': 1.22}\n","{'loss': 0.0004, 'learning_rate': 2.2272727272727274e-05, 'epoch': 1.23}\n","{'loss': 0.0354, 'learning_rate': 2.2121212121212123e-05, 'epoch': 1.23}\n","{'loss': 0.0109, 'learning_rate': 2.1969696969696972e-05, 'epoch': 1.24}\n","{'loss': 0.0098, 'learning_rate': 2.1818181818181818e-05, 'epoch': 1.24}\n","{'loss': 0.0058, 'learning_rate': 2.1666666666666667e-05, 'epoch': 1.25}\n","{'loss': 0.0011, 'learning_rate': 2.1515151515151516e-05, 'epoch': 1.25}\n","{'loss': 0.0018, 'learning_rate': 2.1363636363636362e-05, 'epoch': 1.26}\n","{'loss': 0.0005, 'learning_rate': 2.1212121212121215e-05, 'epoch': 1.26}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7c6dcb3082c144419dbf00ed290c474b","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1900 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.020251477137207985, 'eval_recall': 0.9749650527385945, 'eval_precision': 0.9482140650105055, 'eval_f1': 0.9739082884149677, 'eval_runtime': 58.9342, 'eval_samples_per_second': 32.239, 'eval_steps_per_second': 32.239, 'epoch': 1.26}\n","{'loss': 0.124, 'learning_rate': 2.106060606060606e-05, 'epoch': 1.27}\n","{'loss': 0.003, 'learning_rate': 2.090909090909091e-05, 'epoch': 1.27}\n","{'loss': 0.002, 'learning_rate': 2.075757575757576e-05, 'epoch': 1.28}\n","{'loss': 0.0216, 'learning_rate': 2.0606060606060608e-05, 'epoch': 1.28}\n","{'loss': 0.0081, 'learning_rate': 2.0454545454545457e-05, 'epoch': 1.29}\n","{'loss': 0.0007, 'learning_rate': 2.0303030303030303e-05, 'epoch': 1.29}\n","{'loss': 0.0956, 'learning_rate': 2.0151515151515152e-05, 'epoch': 1.3}\n","{'loss': 0.0007, 'learning_rate': 2e-05, 'epoch': 1.31}\n","{'loss': 0.0022, 'learning_rate': 1.984848484848485e-05, 'epoch': 1.31}\n","{'loss': 0.0014, 'learning_rate': 1.9696969696969697e-05, 'epoch': 1.32}\n","{'loss': 0.0131, 'learning_rate': 1.9545454545454546e-05, 'epoch': 1.32}\n","{'loss': 0.0025, 'learning_rate': 1.9393939393939395e-05, 'epoch': 1.33}\n","{'loss': 0.0007, 'learning_rate': 1.924242424242424e-05, 'epoch': 1.33}\n","{'loss': 0.2104, 'learning_rate': 1.9090909090909094e-05, 'epoch': 1.34}\n","{'loss': 0.0063, 'learning_rate': 1.893939393939394e-05, 'epoch': 1.34}\n","{'loss': 0.001, 'learning_rate': 1.878787878787879e-05, 'epoch': 1.35}\n","{'loss': 0.0262, 'learning_rate': 1.8636363636363638e-05, 'epoch': 1.35}\n","{'loss': 0.0037, 'learning_rate': 1.8484848484848487e-05, 'epoch': 1.36}\n","{'loss': 0.001, 'learning_rate': 1.8333333333333333e-05, 'epoch': 1.36}\n","{'loss': 0.0317, 'learning_rate': 1.8181818181818182e-05, 'epoch': 1.37}\n","{'loss': 0.0006, 'learning_rate': 1.803030303030303e-05, 'epoch': 1.37}\n","{'loss': 0.0028, 'learning_rate': 1.787878787878788e-05, 'epoch': 1.38}\n","{'loss': 0.0028, 'learning_rate': 1.772727272727273e-05, 'epoch': 1.38}\n","{'loss': 0.0014, 'learning_rate': 1.7575757575757576e-05, 'epoch': 1.39}\n","{'loss': 0.0323, 'learning_rate': 1.7424242424242425e-05, 'epoch': 1.39}\n","{'loss': 0.0011, 'learning_rate': 1.7272727272727274e-05, 'epoch': 1.4}\n","{'loss': 0.0007, 'learning_rate': 1.712121212121212e-05, 'epoch': 1.41}\n","{'loss': 0.0029, 'learning_rate': 1.6969696969696972e-05, 'epoch': 1.41}\n","{'loss': 0.0026, 'learning_rate': 1.6818181818181818e-05, 'epoch': 1.42}\n","{'loss': 0.0014, 'learning_rate': 1.6666666666666667e-05, 'epoch': 1.42}\n","{'loss': 0.0009, 'learning_rate': 1.6515151515151517e-05, 'epoch': 1.43}\n","{'loss': 0.0015, 'learning_rate': 1.6363636363636366e-05, 'epoch': 1.43}\n","{'loss': 0.002, 'learning_rate': 1.6212121212121212e-05, 'epoch': 1.44}\n","{'loss': 0.0907, 'learning_rate': 1.606060606060606e-05, 'epoch': 1.44}\n","{'loss': 0.0003, 'learning_rate': 1.590909090909091e-05, 'epoch': 1.45}\n","{'loss': 0.0026, 'learning_rate': 1.5757575757575756e-05, 'epoch': 1.45}\n","{'loss': 0.0007, 'learning_rate': 1.560606060606061e-05, 'epoch': 1.46}\n","{'loss': 0.0006, 'learning_rate': 1.5454545454545454e-05, 'epoch': 1.46}\n","{'loss': 0.0023, 'learning_rate': 1.5303030303030304e-05, 'epoch': 1.47}\n","{'loss': 0.0013, 'learning_rate': 1.5151515151515153e-05, 'epoch': 1.47}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"602ddc50a92743a1beb962bcd1e17100","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1900 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.007594369817525148, 'eval_recall': 0.9960604905324691, 'eval_precision': 0.9080166821130676, 'eval_f1': 0.9923596468588849, 'eval_runtime': 59.0121, 'eval_samples_per_second': 32.197, 'eval_steps_per_second': 32.197, 'epoch': 1.47}\n","{'loss': 0.0024, 'learning_rate': 1.5e-05, 'epoch': 1.48}\n","{'loss': 0.0005, 'learning_rate': 1.484848484848485e-05, 'epoch': 1.48}\n","{'loss': 0.0017, 'learning_rate': 1.4696969696969697e-05, 'epoch': 1.49}\n","{'loss': 0.0009, 'learning_rate': 1.4545454545454545e-05, 'epoch': 1.49}\n","{'loss': 0.0012, 'learning_rate': 1.4393939393939396e-05, 'epoch': 1.5}\n","{'loss': 0.0002, 'learning_rate': 1.4242424242424243e-05, 'epoch': 1.51}\n","{'loss': 0.0008, 'learning_rate': 1.409090909090909e-05, 'epoch': 1.51}\n","{'loss': 0.0022, 'learning_rate': 1.3939393939393942e-05, 'epoch': 1.52}\n","{'loss': 0.0011, 'learning_rate': 1.3787878787878789e-05, 'epoch': 1.52}\n","{'loss': 0.0007, 'learning_rate': 1.3636363636363637e-05, 'epoch': 1.53}\n","{'loss': 0.0006, 'learning_rate': 1.3484848484848486e-05, 'epoch': 1.53}\n","{'loss': 0.0002, 'learning_rate': 1.3333333333333333e-05, 'epoch': 1.54}\n","{'loss': 0.0483, 'learning_rate': 1.318181818181818e-05, 'epoch': 1.54}\n","{'loss': 0.0019, 'learning_rate': 1.3030303030303032e-05, 'epoch': 1.55}\n","{'loss': 0.0025, 'learning_rate': 1.287878787878788e-05, 'epoch': 1.55}\n","{'loss': 0.0024, 'learning_rate': 1.2727272727272727e-05, 'epoch': 1.56}\n","{'loss': 0.002, 'learning_rate': 1.2575757575757578e-05, 'epoch': 1.56}\n","{'loss': 0.0005, 'learning_rate': 1.2424242424242424e-05, 'epoch': 1.57}\n","{'loss': 0.0036, 'learning_rate': 1.2272727272727273e-05, 'epoch': 1.57}\n","{'loss': 0.0025, 'learning_rate': 1.2121212121212122e-05, 'epoch': 1.58}\n","{'loss': 0.0416, 'learning_rate': 1.196969696969697e-05, 'epoch': 1.58}\n","{'loss': 0.0004, 'learning_rate': 1.1818181818181819e-05, 'epoch': 1.59}\n","{'loss': 0.0159, 'learning_rate': 1.1666666666666668e-05, 'epoch': 1.59}\n","{'loss': 0.0005, 'learning_rate': 1.1515151515151517e-05, 'epoch': 1.6}\n","{'loss': 0.0012, 'learning_rate': 1.1363636363636365e-05, 'epoch': 1.61}\n","{'loss': 0.108, 'learning_rate': 1.1212121212121212e-05, 'epoch': 1.61}\n","{'loss': 0.0038, 'learning_rate': 1.1060606060606061e-05, 'epoch': 1.62}\n","{'loss': 0.002, 'learning_rate': 1.0909090909090909e-05, 'epoch': 1.62}\n","{'loss': 0.0009, 'learning_rate': 1.0757575757575758e-05, 'epoch': 1.63}\n","{'loss': 0.0005, 'learning_rate': 1.0606060606060607e-05, 'epoch': 1.63}\n","{'loss': 0.0004, 'learning_rate': 1.0454545454545455e-05, 'epoch': 1.64}\n","{'loss': 0.0494, 'learning_rate': 1.0303030303030304e-05, 'epoch': 1.64}\n","{'loss': 0.0297, 'learning_rate': 1.0151515151515152e-05, 'epoch': 1.65}\n","{'loss': 0.0008, 'learning_rate': 1e-05, 'epoch': 1.65}\n","{'loss': 0.0013, 'learning_rate': 9.848484848484848e-06, 'epoch': 1.66}\n","{'loss': 0.0027, 'learning_rate': 9.696969696969698e-06, 'epoch': 1.66}\n","{'loss': 0.0013, 'learning_rate': 9.545454545454547e-06, 'epoch': 1.67}\n","{'loss': 0.1291, 'learning_rate': 9.393939393939394e-06, 'epoch': 1.67}\n","{'loss': 0.0028, 'learning_rate': 9.242424242424244e-06, 'epoch': 1.68}\n","{'loss': 0.0019, 'learning_rate': 9.090909090909091e-06, 'epoch': 1.68}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7d633e449a794003b2627f8820ab69a8","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1900 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.01808127947151661, 'eval_recall': 0.9796670479095184, 'eval_precision': 0.9252280364858377, 'eval_f1': 0.9774550490839132, 'eval_runtime': 59.075, 'eval_samples_per_second': 32.162, 'eval_steps_per_second': 32.162, 'epoch': 1.68}\n","{'loss': 0.0067, 'learning_rate': 8.93939393939394e-06, 'epoch': 1.69}\n","{'loss': 0.0005, 'learning_rate': 8.787878787878788e-06, 'epoch': 1.69}\n","{'loss': 0.0006, 'learning_rate': 8.636363636363637e-06, 'epoch': 1.7}\n","{'loss': 0.0012, 'learning_rate': 8.484848484848486e-06, 'epoch': 1.71}\n","{'loss': 0.0004, 'learning_rate': 8.333333333333334e-06, 'epoch': 1.71}\n","{'loss': 0.0081, 'learning_rate': 8.181818181818183e-06, 'epoch': 1.72}\n","{'loss': 0.0044, 'learning_rate': 8.03030303030303e-06, 'epoch': 1.72}\n","{'loss': 0.0005, 'learning_rate': 7.878787878787878e-06, 'epoch': 1.73}\n","{'loss': 0.0436, 'learning_rate': 7.727272727272727e-06, 'epoch': 1.73}\n","{'loss': 0.0002, 'learning_rate': 7.5757575757575764e-06, 'epoch': 1.74}\n","{'loss': 0.0001, 'learning_rate': 7.424242424242425e-06, 'epoch': 1.74}\n","{'loss': 0.0006, 'learning_rate': 7.272727272727272e-06, 'epoch': 1.75}\n","{'loss': 0.0045, 'learning_rate': 7.1212121212121215e-06, 'epoch': 1.75}\n","{'loss': 0.0066, 'learning_rate': 6.969696969696971e-06, 'epoch': 1.76}\n","{'loss': 0.005, 'learning_rate': 6.818181818181818e-06, 'epoch': 1.76}\n","{'loss': 0.0733, 'learning_rate': 6.666666666666667e-06, 'epoch': 1.77}\n","{'loss': 0.0011, 'learning_rate': 6.515151515151516e-06, 'epoch': 1.77}\n","{'loss': 0.0033, 'learning_rate': 6.363636363636363e-06, 'epoch': 1.78}\n","{'loss': 0.0022, 'learning_rate': 6.212121212121212e-06, 'epoch': 1.78}\n","{'loss': 0.0089, 'learning_rate': 6.060606060606061e-06, 'epoch': 1.79}\n","{'loss': 0.0009, 'learning_rate': 5.909090909090909e-06, 'epoch': 1.79}\n","{'loss': 0.0009, 'learning_rate': 5.7575757575757586e-06, 'epoch': 1.8}\n","{'loss': 0.006, 'learning_rate': 5.606060606060606e-06, 'epoch': 1.81}\n","{'loss': 0.0009, 'learning_rate': 5.4545454545454545e-06, 'epoch': 1.81}\n","{'loss': 0.0054, 'learning_rate': 5.303030303030304e-06, 'epoch': 1.82}\n","{'loss': 0.0055, 'learning_rate': 5.151515151515152e-06, 'epoch': 1.82}\n","{'loss': 0.0161, 'learning_rate': 5e-06, 'epoch': 1.83}\n","{'loss': 0.0238, 'learning_rate': 4.848484848484849e-06, 'epoch': 1.83}\n","{'loss': 0.0007, 'learning_rate': 4.696969696969697e-06, 'epoch': 1.84}\n","{'loss': 0.016, 'learning_rate': 4.5454545454545455e-06, 'epoch': 1.84}\n","{'loss': 0.0023, 'learning_rate': 4.393939393939394e-06, 'epoch': 1.85}\n","{'loss': 0.0016, 'learning_rate': 4.242424242424243e-06, 'epoch': 1.85}\n","{'loss': 0.0013, 'learning_rate': 4.0909090909090915e-06, 'epoch': 1.86}\n","{'loss': 0.0019, 'learning_rate': 3.939393939393939e-06, 'epoch': 1.86}\n","{'loss': 0.0227, 'learning_rate': 3.7878787878787882e-06, 'epoch': 1.87}\n","{'loss': 0.0004, 'learning_rate': 3.636363636363636e-06, 'epoch': 1.87}\n","{'loss': 0.0021, 'learning_rate': 3.4848484848484854e-06, 'epoch': 1.88}\n","{'loss': 0.0003, 'learning_rate': 3.3333333333333333e-06, 'epoch': 1.88}\n","{'loss': 0.0024, 'learning_rate': 3.1818181818181817e-06, 'epoch': 1.89}\n","{'loss': 0.0102, 'learning_rate': 3.0303030303030305e-06, 'epoch': 1.89}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4770b98e610f42caa713f6975c52da24","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1900 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.009772734716534615, 'eval_recall': 0.9950438429279451, 'eval_precision': 0.9278350515463918, 'eval_f1': 0.9922793472539042, 'eval_runtime': 56.3969, 'eval_samples_per_second': 33.69, 'eval_steps_per_second': 33.69, 'epoch': 1.89}\n","{'loss': 0.0002, 'learning_rate': 2.8787878787878793e-06, 'epoch': 1.9}\n","{'loss': 0.0008, 'learning_rate': 2.7272727272727272e-06, 'epoch': 1.91}\n","{'loss': 0.0006, 'learning_rate': 2.575757575757576e-06, 'epoch': 1.91}\n","{'loss': 0.0004, 'learning_rate': 2.4242424242424244e-06, 'epoch': 1.92}\n","{'loss': 0.0074, 'learning_rate': 2.2727272727272728e-06, 'epoch': 1.92}\n","{'loss': 0.0011, 'learning_rate': 2.1212121212121216e-06, 'epoch': 1.93}\n","{'loss': 0.0057, 'learning_rate': 1.9696969696969695e-06, 'epoch': 1.93}\n","{'loss': 0.0055, 'learning_rate': 1.818181818181818e-06, 'epoch': 1.94}\n","{'loss': 0.008, 'learning_rate': 1.6666666666666667e-06, 'epoch': 1.94}\n","{'loss': 0.0003, 'learning_rate': 1.5151515151515152e-06, 'epoch': 1.95}\n","{'loss': 0.0668, 'learning_rate': 1.3636363636363636e-06, 'epoch': 1.95}\n","{'loss': 0.002, 'learning_rate': 1.2121212121212122e-06, 'epoch': 1.96}\n","{'loss': 0.0987, 'learning_rate': 1.0606060606060608e-06, 'epoch': 1.96}\n","{'loss': 0.0015, 'learning_rate': 9.09090909090909e-07, 'epoch': 1.97}\n","{'loss': 0.0016, 'learning_rate': 7.575757575757576e-07, 'epoch': 1.97}\n","{'loss': 0.0003, 'learning_rate': 6.060606060606061e-07, 'epoch': 1.98}\n","{'loss': 0.0013, 'learning_rate': 4.545454545454545e-07, 'epoch': 1.98}\n","{'loss': 0.0032, 'learning_rate': 3.0303030303030305e-07, 'epoch': 1.99}\n","{'loss': 0.0099, 'learning_rate': 1.5151515151515152e-07, 'epoch': 1.99}\n","{'loss': 0.0038, 'learning_rate': 0.0, 'epoch': 2.0}\n","{'train_runtime': 1753.8193, 'train_samples_per_second': 8.666, 'train_steps_per_second': 2.167, 'train_loss': 0.12110708509250176, 'epoch': 2.0}\n","Shutting down background jobs, please wait a moment...\n","Done!\n","Waiting for the remaining 9 operations to synchronize with Neptune. Do not kill this process.\n","All 9 operations synced, thanks for waiting!\n","Explore the metadata in the Neptune app:\n","https://app.neptune.ai/bernd.heidemann/PII/e/PII-222/metadata\n"]},{"data":{"text/plain":["TrainOutput(global_step=3800, training_loss=0.12110708509250176, metrics={'train_runtime': 1753.8193, 'train_samples_per_second': 8.666, 'train_steps_per_second': 2.167, 'train_loss': 0.12110708509250176, 'epoch': 2.0})"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["import os\n","os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n","\n","\n","\n","model = AutoModelForTokenClassification.from_pretrained(\n","    parameter[\"model\"],\n","    num_labels=len(all_labels),\n","    id2label=id2label,\n","    label2id=label2id,\n","    ignore_mismatched_sizes=True\n",")\n","\n","if parameter['freeze_embeddings']:\n","    for param in model.deberta.embeddings.parameters():\n","        param.requires_grad = False\n","        \n","if parameter['freeze_layers'] > 0:\n","    for layer in model.deberta.encoder.layer[:parameter['freeze_layers']]:\n","        for param in layer.parameters():\n","            param.requires_grad = False\n","\n","print(model.config)\n","#my_model=MyModel(parameter['model'], len(label2id))\n","\n","trainer=get_trainer(model, train_ds, valid_ds)\n","#trainer.set_lr(0.1)\n","trainer.train()"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","c:\\Users\\Bernd\\anaconda3\\envs\\mytorch\\lib\\site-packages\\transformers\\convert_slow_tokenizer.py:470: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n","  warnings.warn(\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"name":"stdout","output_type":"stream","text":["    row_id  document  token           label\n","0        0         7      9  B-NAME_STUDENT\n","1        1         7     10  I-NAME_STUDENT\n","2        2         7    482  B-NAME_STUDENT\n","3        3         7    483  I-NAME_STUDENT\n","4        4         7    741  B-NAME_STUDENT\n","5        5         7    742  I-NAME_STUDENT\n","6        6        10      0  B-NAME_STUDENT\n","7        7        10      1  I-NAME_STUDENT\n","8        8        10    464  B-NAME_STUDENT\n","9        9        10    465  I-NAME_STUDENT\n","10      10        16      4  B-NAME_STUDENT\n","11      11        16      5  I-NAME_STUDENT\n","12      12        20      5  B-NAME_STUDENT\n","13      13        20      6  I-NAME_STUDENT\n","14      14        20      8  I-NAME_STUDENT\n","15      15        20    328  B-NAME_STUDENT\n","16      16        20    330  B-NAME_STUDENT\n","17      17        56     12  B-NAME_STUDENT\n","18      18        56     13  I-NAME_STUDENT\n","19      19        86      6  B-NAME_STUDENT\n","20      20        86      7  I-NAME_STUDENT\n","21      21        93      0  B-NAME_STUDENT\n","22      22        93      1  I-NAME_STUDENT\n","23      23       104      7  B-NAME_STUDENT\n","24      24       104      8  B-NAME_STUDENT\n","25      25       104      9  I-NAME_STUDENT\n","26      26       112      5  B-NAME_STUDENT\n","27      27       112      6  I-NAME_STUDENT\n","28      28       123     32  B-NAME_STUDENT\n","29      29       123     33  I-NAME_STUDENT\n","30      30       123     35        B-ID_NUM\n","31      31       123   1500  B-NAME_STUDENT\n"]}],"source":["create_submission(model, f\"submission.csv\")"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["https://app.neptune.ai/bernd.heidemann/PII/e/PII-223\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\Bernd\\anaconda3\\envs\\mytorch\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"69cf5fd08a1848a49047a1734a978e51","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/3800 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'loss': 0.0004, 'learning_rate': 1.0000000000000001e-07, 'epoch': 0.01}\n","{'loss': 0.0009, 'learning_rate': 2.0000000000000002e-07, 'epoch': 0.01}\n","{'loss': 0.0003, 'learning_rate': 3.0000000000000004e-07, 'epoch': 0.02}\n","{'loss': 0.0018, 'learning_rate': 4.0000000000000003e-07, 'epoch': 0.02}\n","{'loss': 0.0232, 'learning_rate': 5.000000000000001e-07, 'epoch': 0.03}\n","{'loss': 0.0014, 'learning_rate': 6.000000000000001e-07, 'epoch': 0.03}\n","{'loss': 0.0007, 'learning_rate': 7.000000000000001e-07, 'epoch': 0.04}\n","{'loss': 0.0006, 'learning_rate': 8.000000000000001e-07, 'epoch': 0.04}\n","{'loss': 0.0002, 'learning_rate': 9.000000000000001e-07, 'epoch': 0.05}\n","{'loss': 0.0002, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.05}\n","{'loss': 0.0041, 'learning_rate': 1.1e-06, 'epoch': 0.06}\n","{'loss': 0.0014, 'learning_rate': 1.2000000000000002e-06, 'epoch': 0.06}\n","{'loss': 0.0708, 'learning_rate': 1.3e-06, 'epoch': 0.07}\n","{'loss': 0.0064, 'learning_rate': 1.4000000000000001e-06, 'epoch': 0.07}\n","{'loss': 0.0056, 'learning_rate': 1.5e-06, 'epoch': 0.08}\n","{'loss': 0.006, 'learning_rate': 1.6000000000000001e-06, 'epoch': 0.08}\n","{'loss': 0.0003, 'learning_rate': 1.7000000000000002e-06, 'epoch': 0.09}\n","{'loss': 0.0006, 'learning_rate': 1.8000000000000001e-06, 'epoch': 0.09}\n","{'loss': 0.0012, 'learning_rate': 1.9000000000000002e-06, 'epoch': 0.1}\n","{'loss': 0.001, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.11}\n","{'loss': 0.0012, 'learning_rate': 2.1000000000000002e-06, 'epoch': 0.11}\n","{'loss': 0.0025, 'learning_rate': 2.2e-06, 'epoch': 0.12}\n","{'loss': 0.0007, 'learning_rate': 2.3000000000000004e-06, 'epoch': 0.12}\n","{'loss': 0.0019, 'learning_rate': 2.4000000000000003e-06, 'epoch': 0.13}\n","{'loss': 0.0006, 'learning_rate': 2.5e-06, 'epoch': 0.13}\n","{'loss': 0.0003, 'learning_rate': 2.6e-06, 'epoch': 0.14}\n","{'loss': 0.0005, 'learning_rate': 2.7000000000000004e-06, 'epoch': 0.14}\n","{'loss': 0.0017, 'learning_rate': 2.8000000000000003e-06, 'epoch': 0.15}\n","{'loss': 0.0167, 'learning_rate': 2.9e-06, 'epoch': 0.15}\n","{'loss': 0.0004, 'learning_rate': 3e-06, 'epoch': 0.16}\n","{'loss': 0.0008, 'learning_rate': 3.1000000000000004e-06, 'epoch': 0.16}\n","{'loss': 0.0008, 'learning_rate': 3.2000000000000003e-06, 'epoch': 0.17}\n","{'loss': 0.0016, 'learning_rate': 3.3000000000000006e-06, 'epoch': 0.17}\n","{'loss': 0.0004, 'learning_rate': 3.4000000000000005e-06, 'epoch': 0.18}\n","{'loss': 0.0022, 'learning_rate': 3.5e-06, 'epoch': 0.18}\n","{'loss': 0.0001, 'learning_rate': 3.6000000000000003e-06, 'epoch': 0.19}\n","{'loss': 0.0006, 'learning_rate': 3.7e-06, 'epoch': 0.19}\n","{'loss': 0.0002, 'learning_rate': 3.8000000000000005e-06, 'epoch': 0.2}\n","{'loss': 0.0005, 'learning_rate': 3.900000000000001e-06, 'epoch': 0.21}\n","{'loss': 0.0015, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.21}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6e612113122d4cfc9055262667149b89","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1900 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.032189611345529556, 'eval_recall': 0.9785233193544288, 'eval_precision': 0.9595015576323987, 'eval_f1': 0.9777777777777777, 'eval_runtime': 55.827, 'eval_samples_per_second': 34.034, 'eval_steps_per_second': 34.034, 'epoch': 0.21}\n","{'loss': 0.0021, 'learning_rate': 4.1e-06, 'epoch': 0.22}\n","{'loss': 0.0002, 'learning_rate': 4.2000000000000004e-06, 'epoch': 0.22}\n","{'loss': 0.0015, 'learning_rate': 4.3e-06, 'epoch': 0.23}\n","{'loss': 0.0006, 'learning_rate': 4.4e-06, 'epoch': 0.23}\n","{'loss': 0.0042, 'learning_rate': 4.5e-06, 'epoch': 0.24}\n","{'loss': 0.0011, 'learning_rate': 4.600000000000001e-06, 'epoch': 0.24}\n","{'loss': 0.0018, 'learning_rate': 4.7e-06, 'epoch': 0.25}\n","{'loss': 0.0007, 'learning_rate': 4.800000000000001e-06, 'epoch': 0.25}\n","{'loss': 0.0004, 'learning_rate': 4.9000000000000005e-06, 'epoch': 0.26}\n","{'loss': 0.0001, 'learning_rate': 5e-06, 'epoch': 0.26}\n","{'loss': 0.0127, 'learning_rate': 4.984848484848485e-06, 'epoch': 0.27}\n","{'loss': 0.0001, 'learning_rate': 4.9696969696969696e-06, 'epoch': 0.27}\n","{'loss': 0.001, 'learning_rate': 4.954545454545455e-06, 'epoch': 0.28}\n","{'loss': 0.0102, 'learning_rate': 4.93939393939394e-06, 'epoch': 0.28}\n","{'loss': 0.0003, 'learning_rate': 4.924242424242425e-06, 'epoch': 0.29}\n","{'loss': 0.0007, 'learning_rate': 4.90909090909091e-06, 'epoch': 0.29}\n","{'loss': 0.0007, 'learning_rate': 4.893939393939394e-06, 'epoch': 0.3}\n","{'loss': 0.0011, 'learning_rate': 4.878787878787879e-06, 'epoch': 0.31}\n","{'loss': 0.002, 'learning_rate': 4.863636363636364e-06, 'epoch': 0.31}\n","{'loss': 0.0008, 'learning_rate': 4.848484848484849e-06, 'epoch': 0.32}\n","{'loss': 0.0002, 'learning_rate': 4.833333333333333e-06, 'epoch': 0.32}\n","{'loss': 0.0172, 'learning_rate': 4.818181818181819e-06, 'epoch': 0.33}\n","{'loss': 0.0002, 'learning_rate': 4.803030303030303e-06, 'epoch': 0.33}\n","{'loss': 0.0004, 'learning_rate': 4.787878787878788e-06, 'epoch': 0.34}\n","{'loss': 0.0003, 'learning_rate': 4.772727272727273e-06, 'epoch': 0.34}\n","{'loss': 0.0257, 'learning_rate': 4.757575757575758e-06, 'epoch': 0.35}\n","{'loss': 0.0238, 'learning_rate': 4.7424242424242426e-06, 'epoch': 0.35}\n","{'loss': 0.0007, 'learning_rate': 4.727272727272728e-06, 'epoch': 0.36}\n","{'loss': 0.0559, 'learning_rate': 4.7121212121212126e-06, 'epoch': 0.36}\n","{'loss': 0.0008, 'learning_rate': 4.696969696969698e-06, 'epoch': 0.37}\n","{'loss': 0.0039, 'learning_rate': 4.681818181818183e-06, 'epoch': 0.37}\n","{'loss': 0.0011, 'learning_rate': 4.666666666666667e-06, 'epoch': 0.38}\n","{'loss': 0.0001, 'learning_rate': 4.651515151515152e-06, 'epoch': 0.38}\n","{'loss': 0.0015, 'learning_rate': 4.636363636363636e-06, 'epoch': 0.39}\n","{'loss': 0.0029, 'learning_rate': 4.621212121212122e-06, 'epoch': 0.39}\n","{'loss': 0.0005, 'learning_rate': 4.606060606060606e-06, 'epoch': 0.4}\n","{'loss': 0.0003, 'learning_rate': 4.590909090909092e-06, 'epoch': 0.41}\n","{'loss': 0.0004, 'learning_rate': 4.575757575757576e-06, 'epoch': 0.41}\n","{'loss': 0.0007, 'learning_rate': 4.560606060606061e-06, 'epoch': 0.42}\n","{'loss': 0.0012, 'learning_rate': 4.5454545454545455e-06, 'epoch': 0.42}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"775d612194c24dce83a49a5abebd5ac5","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1900 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.019631382077932358, 'eval_recall': 0.9764900241453806, 'eval_precision': 0.9561971129915381, 'eval_f1': 0.9756936135299202, 'eval_runtime': 55.7665, 'eval_samples_per_second': 34.071, 'eval_steps_per_second': 34.071, 'epoch': 0.42}\n","{'loss': 0.0283, 'learning_rate': 4.53030303030303e-06, 'epoch': 0.43}\n","{'loss': 0.0059, 'learning_rate': 4.5151515151515155e-06, 'epoch': 0.43}\n","{'loss': 0.0011, 'learning_rate': 4.5e-06, 'epoch': 0.44}\n","{'loss': 0.0028, 'learning_rate': 4.4848484848484855e-06, 'epoch': 0.44}\n","{'loss': 0.0004, 'learning_rate': 4.46969696969697e-06, 'epoch': 0.45}\n","{'loss': 0.0002, 'learning_rate': 4.454545454545455e-06, 'epoch': 0.45}\n","{'loss': 0.0003, 'learning_rate': 4.43939393939394e-06, 'epoch': 0.46}\n","{'loss': 0.0001, 'learning_rate': 4.424242424242425e-06, 'epoch': 0.46}\n","{'loss': 0.0025, 'learning_rate': 4.409090909090909e-06, 'epoch': 0.47}\n","{'loss': 0.001, 'learning_rate': 4.393939393939394e-06, 'epoch': 0.47}\n","{'loss': 0.0002, 'learning_rate': 4.378787878787879e-06, 'epoch': 0.48}\n","{'loss': 0.005, 'learning_rate': 4.363636363636364e-06, 'epoch': 0.48}\n","{'loss': 0.002, 'learning_rate': 4.348484848484849e-06, 'epoch': 0.49}\n","{'loss': 0.0014, 'learning_rate': 4.333333333333334e-06, 'epoch': 0.49}\n","{'loss': 0.0003, 'learning_rate': 4.3181818181818185e-06, 'epoch': 0.5}\n","{'loss': 0.0002, 'learning_rate': 4.303030303030303e-06, 'epoch': 0.51}\n","{'loss': 0.0041, 'learning_rate': 4.287878787878788e-06, 'epoch': 0.51}\n","{'loss': 0.0011, 'learning_rate': 4.272727272727273e-06, 'epoch': 0.52}\n","{'loss': 0.0005, 'learning_rate': 4.2575757575757585e-06, 'epoch': 0.52}\n","{'loss': 0.0011, 'learning_rate': 4.242424242424243e-06, 'epoch': 0.53}\n","{'loss': 0.0106, 'learning_rate': 4.227272727272728e-06, 'epoch': 0.53}\n","{'loss': 0.0002, 'learning_rate': 4.212121212121212e-06, 'epoch': 0.54}\n","{'loss': 0.0011, 'learning_rate': 4.196969696969697e-06, 'epoch': 0.54}\n","{'loss': 0.0091, 'learning_rate': 4.181818181818182e-06, 'epoch': 0.55}\n","{'loss': 0.0125, 'learning_rate': 4.166666666666667e-06, 'epoch': 0.55}\n","{'loss': 0.001, 'learning_rate': 4.151515151515152e-06, 'epoch': 0.56}\n","{'loss': 0.004, 'learning_rate': 4.136363636363637e-06, 'epoch': 0.56}\n","{'loss': 0.0002, 'learning_rate': 4.1212121212121215e-06, 'epoch': 0.57}\n","{'loss': 0.0003, 'learning_rate': 4.106060606060606e-06, 'epoch': 0.57}\n","{'loss': 0.0015, 'learning_rate': 4.0909090909090915e-06, 'epoch': 0.58}\n","{'loss': 0.0016, 'learning_rate': 4.075757575757576e-06, 'epoch': 0.58}\n","{'loss': 0.0014, 'learning_rate': 4.060606060606061e-06, 'epoch': 0.59}\n","{'loss': 0.0054, 'learning_rate': 4.045454545454546e-06, 'epoch': 0.59}\n","{'loss': 0.0004, 'learning_rate': 4.030303030303031e-06, 'epoch': 0.6}\n","{'loss': 0.0003, 'learning_rate': 4.015151515151515e-06, 'epoch': 0.61}\n","{'loss': 0.0003, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.61}\n","{'loss': 0.0005, 'learning_rate': 3.984848484848485e-06, 'epoch': 0.62}\n","{'loss': 0.0068, 'learning_rate': 3.96969696969697e-06, 'epoch': 0.62}\n","{'loss': 0.0009, 'learning_rate': 3.954545454545454e-06, 'epoch': 0.63}\n","{'loss': 0.0003, 'learning_rate': 3.93939393939394e-06, 'epoch': 0.63}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7d69ea875da140c6a4833acf524fada2","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1900 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.0054142167791724205, 'eval_recall': 0.9954250857796416, 'eval_precision': 0.9237028301886793, 'eval_f1': 0.9924611973392463, 'eval_runtime': 55.8742, 'eval_samples_per_second': 34.005, 'eval_steps_per_second': 34.005, 'epoch': 0.63}\n","{'loss': 0.0105, 'learning_rate': 3.9242424242424244e-06, 'epoch': 0.64}\n","{'loss': 0.0021, 'learning_rate': 3.90909090909091e-06, 'epoch': 0.64}\n","{'loss': 0.0001, 'learning_rate': 3.8939393939393944e-06, 'epoch': 0.65}\n","{'loss': 0.0042, 'learning_rate': 3.878787878787879e-06, 'epoch': 0.65}\n","{'loss': 0.0056, 'learning_rate': 3.863636363636364e-06, 'epoch': 0.66}\n","{'loss': 0.0005, 'learning_rate': 3.848484848484848e-06, 'epoch': 0.66}\n","{'loss': 0.0003, 'learning_rate': 3.833333333333334e-06, 'epoch': 0.67}\n","{'loss': 0.0009, 'learning_rate': 3.818181818181819e-06, 'epoch': 0.67}\n","{'loss': 0.0008, 'learning_rate': 3.803030303030303e-06, 'epoch': 0.68}\n","{'loss': 0.0011, 'learning_rate': 3.7878787878787882e-06, 'epoch': 0.68}\n","{'loss': 0.0002, 'learning_rate': 3.772727272727273e-06, 'epoch': 0.69}\n","{'loss': 0.0008, 'learning_rate': 3.757575757575758e-06, 'epoch': 0.69}\n","{'loss': 0.0002, 'learning_rate': 3.742424242424243e-06, 'epoch': 0.7}\n","{'loss': 0.0004, 'learning_rate': 3.727272727272728e-06, 'epoch': 0.71}\n","{'loss': 0.0006, 'learning_rate': 3.7121212121212124e-06, 'epoch': 0.71}\n","{'loss': 0.0003, 'learning_rate': 3.6969696969696974e-06, 'epoch': 0.72}\n","{'loss': 0.0006, 'learning_rate': 3.681818181818182e-06, 'epoch': 0.72}\n","{'loss': 0.0434, 'learning_rate': 3.6666666666666666e-06, 'epoch': 0.73}\n","{'loss': 0.0002, 'learning_rate': 3.651515151515152e-06, 'epoch': 0.73}\n","{'loss': 0.0003, 'learning_rate': 3.6363636363636366e-06, 'epoch': 0.74}\n","{'loss': 0.0916, 'learning_rate': 3.6212121212121216e-06, 'epoch': 0.74}\n","{'loss': 0.0005, 'learning_rate': 3.606060606060606e-06, 'epoch': 0.75}\n","{'loss': 0.0009, 'learning_rate': 3.590909090909091e-06, 'epoch': 0.75}\n","{'loss': 0.0001, 'learning_rate': 3.575757575757576e-06, 'epoch': 0.76}\n","{'loss': 0.0002, 'learning_rate': 3.560606060606061e-06, 'epoch': 0.76}\n","{'loss': 0.0001, 'learning_rate': 3.5454545454545458e-06, 'epoch': 0.77}\n","{'loss': 0.0005, 'learning_rate': 3.5303030303030304e-06, 'epoch': 0.77}\n","{'loss': 0.0002, 'learning_rate': 3.5151515151515154e-06, 'epoch': 0.78}\n","{'loss': 0.0029, 'learning_rate': 3.5e-06, 'epoch': 0.78}\n","{'loss': 0.0002, 'learning_rate': 3.4848484848484854e-06, 'epoch': 0.79}\n","{'loss': 0.0008, 'learning_rate': 3.46969696969697e-06, 'epoch': 0.79}\n","{'loss': 0.0007, 'learning_rate': 3.454545454545455e-06, 'epoch': 0.8}\n","{'loss': 0.0006, 'learning_rate': 3.4393939393939395e-06, 'epoch': 0.81}\n","{'loss': 0.0001, 'learning_rate': 3.4242424242424246e-06, 'epoch': 0.81}\n","{'loss': 0.0002, 'learning_rate': 3.409090909090909e-06, 'epoch': 0.82}\n","{'loss': 0.0003, 'learning_rate': 3.3939393939393946e-06, 'epoch': 0.82}\n","{'loss': 0.0002, 'learning_rate': 3.378787878787879e-06, 'epoch': 0.83}\n","{'loss': 0.0012, 'learning_rate': 3.3636363636363637e-06, 'epoch': 0.83}\n","{'loss': 0.0003, 'learning_rate': 3.3484848484848487e-06, 'epoch': 0.84}\n","{'loss': 0.0003, 'learning_rate': 3.3333333333333333e-06, 'epoch': 0.84}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"76e0f0fbb5d44fa3937dabd46afd88c1","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1900 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.015537953935563564, 'eval_recall': 0.9894522811030626, 'eval_precision': 0.9553374233128834, 'eval_f1': 0.9880951799877975, 'eval_runtime': 55.8738, 'eval_samples_per_second': 34.005, 'eval_steps_per_second': 34.005, 'epoch': 0.84}\n","{'loss': 0.0009, 'learning_rate': 3.3181818181818188e-06, 'epoch': 0.85}\n","{'loss': 0.0007, 'learning_rate': 3.3030303030303033e-06, 'epoch': 0.85}\n","{'loss': 0.0001, 'learning_rate': 3.2878787878787883e-06, 'epoch': 0.86}\n","{'loss': 0.0003, 'learning_rate': 3.272727272727273e-06, 'epoch': 0.86}\n","{'loss': 0.0003, 'learning_rate': 3.257575757575758e-06, 'epoch': 0.87}\n","{'loss': 0.0001, 'learning_rate': 3.2424242424242425e-06, 'epoch': 0.87}\n","{'loss': 0.2165, 'learning_rate': 3.227272727272728e-06, 'epoch': 0.88}\n","{'loss': 0.0005, 'learning_rate': 3.2121212121212125e-06, 'epoch': 0.88}\n","{'loss': 0.0003, 'learning_rate': 3.196969696969697e-06, 'epoch': 0.89}\n","{'loss': 0.0547, 'learning_rate': 3.181818181818182e-06, 'epoch': 0.89}\n","{'loss': 0.0008, 'learning_rate': 3.1666666666666667e-06, 'epoch': 0.9}\n","{'loss': 0.0114, 'learning_rate': 3.1515151515151517e-06, 'epoch': 0.91}\n","{'loss': 0.0016, 'learning_rate': 3.1363636363636367e-06, 'epoch': 0.91}\n","{'loss': 0.0003, 'learning_rate': 3.1212121212121217e-06, 'epoch': 0.92}\n","{'loss': 0.0013, 'learning_rate': 3.1060606060606063e-06, 'epoch': 0.92}\n","{'loss': 0.002, 'learning_rate': 3.090909090909091e-06, 'epoch': 0.93}\n","{'loss': 0.0006, 'learning_rate': 3.075757575757576e-06, 'epoch': 0.93}\n","{'loss': 0.0007, 'learning_rate': 3.0606060606060605e-06, 'epoch': 0.94}\n","{'loss': 0.0003, 'learning_rate': 3.045454545454546e-06, 'epoch': 0.94}\n","{'loss': 0.0004, 'learning_rate': 3.0303030303030305e-06, 'epoch': 0.95}\n","{'loss': 0.0004, 'learning_rate': 3.0151515151515155e-06, 'epoch': 0.95}\n","{'loss': 0.0008, 'learning_rate': 3e-06, 'epoch': 0.96}\n","{'loss': 0.0006, 'learning_rate': 2.984848484848485e-06, 'epoch': 0.96}\n","{'loss': 0.0029, 'learning_rate': 2.96969696969697e-06, 'epoch': 0.97}\n","{'loss': 0.0004, 'learning_rate': 2.954545454545455e-06, 'epoch': 0.97}\n","{'loss': 0.0003, 'learning_rate': 2.9393939393939397e-06, 'epoch': 0.98}\n","{'loss': 0.0009, 'learning_rate': 2.9242424242424243e-06, 'epoch': 0.98}\n","{'loss': 0.001, 'learning_rate': 2.9090909090909093e-06, 'epoch': 0.99}\n","{'loss': 0.0003, 'learning_rate': 2.893939393939394e-06, 'epoch': 0.99}\n","{'loss': 0.0001, 'learning_rate': 2.8787878787878793e-06, 'epoch': 1.0}\n","{'loss': 0.0001, 'learning_rate': 2.863636363636364e-06, 'epoch': 1.01}\n","{'loss': 0.0001, 'learning_rate': 2.848484848484849e-06, 'epoch': 1.01}\n","{'loss': 0.0004, 'learning_rate': 2.8333333333333335e-06, 'epoch': 1.02}\n","{'loss': 0.0001, 'learning_rate': 2.818181818181818e-06, 'epoch': 1.02}\n","{'loss': 0.0003, 'learning_rate': 2.803030303030303e-06, 'epoch': 1.03}\n","{'loss': 0.0003, 'learning_rate': 2.7878787878787885e-06, 'epoch': 1.03}\n","{'loss': 0.0002, 'learning_rate': 2.772727272727273e-06, 'epoch': 1.04}\n","{'loss': 0.0007, 'learning_rate': 2.7575757575757576e-06, 'epoch': 1.04}\n","{'loss': 0.0004, 'learning_rate': 2.7424242424242426e-06, 'epoch': 1.05}\n","{'loss': 0.0003, 'learning_rate': 2.7272727272727272e-06, 'epoch': 1.05}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bf5d8a12803c44a9a99a78818d4a02a6","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1900 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.011750098317861557, 'eval_recall': 0.9895793620536282, 'eval_precision': 0.9525382262996942, 'eval_f1': 0.9881015129331381, 'eval_runtime': 55.8907, 'eval_samples_per_second': 33.995, 'eval_steps_per_second': 33.995, 'epoch': 1.05}\n","{'loss': 0.0003, 'learning_rate': 2.7121212121212127e-06, 'epoch': 1.06}\n","{'loss': 0.0001, 'learning_rate': 2.6969696969696972e-06, 'epoch': 1.06}\n","{'loss': 0.0001, 'learning_rate': 2.6818181818181822e-06, 'epoch': 1.07}\n","{'loss': 0.0001, 'learning_rate': 2.666666666666667e-06, 'epoch': 1.07}\n","{'loss': 0.0004, 'learning_rate': 2.6515151515151514e-06, 'epoch': 1.08}\n","{'loss': 0.0002, 'learning_rate': 2.6363636363636364e-06, 'epoch': 1.08}\n","{'loss': 0.0004, 'learning_rate': 2.621212121212122e-06, 'epoch': 1.09}\n","{'loss': 0.0032, 'learning_rate': 2.6060606060606064e-06, 'epoch': 1.09}\n","{'loss': 0.0004, 'learning_rate': 2.590909090909091e-06, 'epoch': 1.1}\n","{'loss': 0.0007, 'learning_rate': 2.575757575757576e-06, 'epoch': 1.11}\n","{'loss': 0.0002, 'learning_rate': 2.5606060606060606e-06, 'epoch': 1.11}\n","{'loss': 0.0001, 'learning_rate': 2.5454545454545456e-06, 'epoch': 1.12}\n","{'loss': 0.0017, 'learning_rate': 2.5303030303030306e-06, 'epoch': 1.12}\n","{'loss': 0.0003, 'learning_rate': 2.5151515151515156e-06, 'epoch': 1.13}\n","{'loss': 0.0001, 'learning_rate': 2.5e-06, 'epoch': 1.13}\n","{'loss': 0.0002, 'learning_rate': 2.4848484848484848e-06, 'epoch': 1.14}\n","{'loss': 0.0004, 'learning_rate': 2.46969696969697e-06, 'epoch': 1.14}\n","{'loss': 0.0009, 'learning_rate': 2.454545454545455e-06, 'epoch': 1.15}\n","{'loss': 0.0004, 'learning_rate': 2.4393939393939394e-06, 'epoch': 1.15}\n","{'loss': 0.0008, 'learning_rate': 2.4242424242424244e-06, 'epoch': 1.16}\n","{'loss': 0.0002, 'learning_rate': 2.4090909090909094e-06, 'epoch': 1.16}\n","{'loss': 0.0001, 'learning_rate': 2.393939393939394e-06, 'epoch': 1.17}\n","{'loss': 0.0, 'learning_rate': 2.378787878787879e-06, 'epoch': 1.17}\n","{'loss': 0.0001, 'learning_rate': 2.363636363636364e-06, 'epoch': 1.18}\n","{'loss': 0.0006, 'learning_rate': 2.348484848484849e-06, 'epoch': 1.18}\n","{'loss': 0.0002, 'learning_rate': 2.3333333333333336e-06, 'epoch': 1.19}\n","{'loss': 0.0002, 'learning_rate': 2.318181818181818e-06, 'epoch': 1.19}\n","{'loss': 0.0006, 'learning_rate': 2.303030303030303e-06, 'epoch': 1.2}\n","{'loss': 0.0005, 'learning_rate': 2.287878787878788e-06, 'epoch': 1.21}\n","{'loss': 0.0001, 'learning_rate': 2.2727272727272728e-06, 'epoch': 1.21}\n","{'loss': 0.006, 'learning_rate': 2.2575757575757578e-06, 'epoch': 1.22}\n","{'loss': 0.0004, 'learning_rate': 2.2424242424242428e-06, 'epoch': 1.22}\n","{'loss': 0.0001, 'learning_rate': 2.2272727272727274e-06, 'epoch': 1.23}\n","{'loss': 0.0011, 'learning_rate': 2.2121212121212124e-06, 'epoch': 1.23}\n","{'loss': 0.002, 'learning_rate': 2.196969696969697e-06, 'epoch': 1.24}\n","{'loss': 0.001, 'learning_rate': 2.181818181818182e-06, 'epoch': 1.24}\n","{'loss': 0.0005, 'learning_rate': 2.166666666666667e-06, 'epoch': 1.25}\n","{'loss': 0.0002, 'learning_rate': 2.1515151515151515e-06, 'epoch': 1.25}\n","{'loss': 0.0002, 'learning_rate': 2.1363636363636365e-06, 'epoch': 1.26}\n","{'loss': 0.0001, 'learning_rate': 2.1212121212121216e-06, 'epoch': 1.26}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b757e2aae52b496f9d62a7b6e5e78cfb","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1900 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.021222904324531555, 'eval_recall': 0.9791587241072564, 'eval_precision': 0.9682080924855492, 'eval_f1': 0.9787329675644776, 'eval_runtime': 55.8967, 'eval_samples_per_second': 33.991, 'eval_steps_per_second': 33.991, 'epoch': 1.26}\n","{'loss': 0.0008, 'learning_rate': 2.106060606060606e-06, 'epoch': 1.27}\n","{'loss': 0.0006, 'learning_rate': 2.090909090909091e-06, 'epoch': 1.27}\n","{'loss': 0.0001, 'learning_rate': 2.075757575757576e-06, 'epoch': 1.28}\n","{'loss': 0.0002, 'learning_rate': 2.0606060606060607e-06, 'epoch': 1.28}\n","{'loss': 0.0002, 'learning_rate': 2.0454545454545457e-06, 'epoch': 1.29}\n","{'loss': 0.0003, 'learning_rate': 2.0303030303030303e-06, 'epoch': 1.29}\n","{'loss': 0.0008, 'learning_rate': 2.0151515151515153e-06, 'epoch': 1.3}\n","{'loss': 0.0001, 'learning_rate': 2.0000000000000003e-06, 'epoch': 1.31}\n","{'loss': 0.0043, 'learning_rate': 1.984848484848485e-06, 'epoch': 1.31}\n","{'loss': 0.0001, 'learning_rate': 1.96969696969697e-06, 'epoch': 1.32}\n","{'loss': 0.0002, 'learning_rate': 1.954545454545455e-06, 'epoch': 1.32}\n","{'loss': 0.0019, 'learning_rate': 1.9393939393939395e-06, 'epoch': 1.33}\n","{'loss': 0.0003, 'learning_rate': 1.924242424242424e-06, 'epoch': 1.33}\n","{'loss': 0.1262, 'learning_rate': 1.9090909090909095e-06, 'epoch': 1.34}\n","{'loss': 0.0001, 'learning_rate': 1.8939393939393941e-06, 'epoch': 1.34}\n","{'loss': 0.0002, 'learning_rate': 1.878787878787879e-06, 'epoch': 1.35}\n","{'loss': 0.0005, 'learning_rate': 1.863636363636364e-06, 'epoch': 1.35}\n","{'loss': 0.0002, 'learning_rate': 1.8484848484848487e-06, 'epoch': 1.36}\n","{'loss': 0.0001, 'learning_rate': 1.8333333333333333e-06, 'epoch': 1.36}\n","{'loss': 0.0006, 'learning_rate': 1.8181818181818183e-06, 'epoch': 1.37}\n","{'loss': 0.0001, 'learning_rate': 1.803030303030303e-06, 'epoch': 1.37}\n","{'loss': 0.0002, 'learning_rate': 1.787878787878788e-06, 'epoch': 1.38}\n","{'loss': 0.0021, 'learning_rate': 1.7727272727272729e-06, 'epoch': 1.38}\n","{'loss': 0.0001, 'learning_rate': 1.7575757575757577e-06, 'epoch': 1.39}\n","{'loss': 0.0003, 'learning_rate': 1.7424242424242427e-06, 'epoch': 1.39}\n","{'loss': 0.0005, 'learning_rate': 1.7272727272727275e-06, 'epoch': 1.4}\n","{'loss': 0.0002, 'learning_rate': 1.7121212121212123e-06, 'epoch': 1.41}\n","{'loss': 0.0002, 'learning_rate': 1.6969696969696973e-06, 'epoch': 1.41}\n","{'loss': 0.0005, 'learning_rate': 1.6818181818181819e-06, 'epoch': 1.42}\n","{'loss': 0.0001, 'learning_rate': 1.6666666666666667e-06, 'epoch': 1.42}\n","{'loss': 0.0003, 'learning_rate': 1.6515151515151517e-06, 'epoch': 1.43}\n","{'loss': 0.0002, 'learning_rate': 1.6363636363636365e-06, 'epoch': 1.43}\n","{'loss': 0.0168, 'learning_rate': 1.6212121212121213e-06, 'epoch': 1.44}\n","{'loss': 0.0141, 'learning_rate': 1.6060606060606063e-06, 'epoch': 1.44}\n","{'loss': 0.0002, 'learning_rate': 1.590909090909091e-06, 'epoch': 1.45}\n","{'loss': 0.0005, 'learning_rate': 1.5757575757575759e-06, 'epoch': 1.45}\n","{'loss': 0.0001, 'learning_rate': 1.5606060606060609e-06, 'epoch': 1.46}\n","{'loss': 0.0003, 'learning_rate': 1.5454545454545454e-06, 'epoch': 1.46}\n","{'loss': 0.0005, 'learning_rate': 1.5303030303030302e-06, 'epoch': 1.47}\n","{'loss': 0.0006, 'learning_rate': 1.5151515151515152e-06, 'epoch': 1.47}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6133aadbbff0450abc8fedc7c6038e04","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1900 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.007906520739197731, 'eval_recall': 0.9949167619773795, 'eval_precision': 0.9388415877203502, 'eval_f1': 0.9926364452073498, 'eval_runtime': 55.8833, 'eval_samples_per_second': 33.999, 'eval_steps_per_second': 33.999, 'epoch': 1.47}\n","{'loss': 0.0002, 'learning_rate': 1.5e-06, 'epoch': 1.48}\n","{'loss': 0.0001, 'learning_rate': 1.484848484848485e-06, 'epoch': 1.48}\n","{'loss': 0.0012, 'learning_rate': 1.4696969696969698e-06, 'epoch': 1.49}\n","{'loss': 0.0003, 'learning_rate': 1.4545454545454546e-06, 'epoch': 1.49}\n","{'loss': 0.0006, 'learning_rate': 1.4393939393939396e-06, 'epoch': 1.5}\n","{'loss': 0.0001, 'learning_rate': 1.4242424242424244e-06, 'epoch': 1.51}\n","{'loss': 0.0004, 'learning_rate': 1.409090909090909e-06, 'epoch': 1.51}\n","{'loss': 0.0011, 'learning_rate': 1.3939393939393942e-06, 'epoch': 1.52}\n","{'loss': 0.0002, 'learning_rate': 1.3787878787878788e-06, 'epoch': 1.52}\n","{'loss': 0.0002, 'learning_rate': 1.3636363636363636e-06, 'epoch': 1.53}\n","{'loss': 0.0002, 'learning_rate': 1.3484848484848486e-06, 'epoch': 1.53}\n","{'loss': 0.0001, 'learning_rate': 1.3333333333333334e-06, 'epoch': 1.54}\n","{'loss': 0.0001, 'learning_rate': 1.3181818181818182e-06, 'epoch': 1.54}\n","{'loss': 0.0003, 'learning_rate': 1.3030303030303032e-06, 'epoch': 1.55}\n","{'loss': 0.0005, 'learning_rate': 1.287878787878788e-06, 'epoch': 1.55}\n","{'loss': 0.0003, 'learning_rate': 1.2727272727272728e-06, 'epoch': 1.56}\n","{'loss': 0.0017, 'learning_rate': 1.2575757575757578e-06, 'epoch': 1.56}\n","{'loss': 0.0002, 'learning_rate': 1.2424242424242424e-06, 'epoch': 1.57}\n","{'loss': 0.0008, 'learning_rate': 1.2272727272727274e-06, 'epoch': 1.57}\n","{'loss': 0.0003, 'learning_rate': 1.2121212121212122e-06, 'epoch': 1.58}\n","{'loss': 0.0001, 'learning_rate': 1.196969696969697e-06, 'epoch': 1.58}\n","{'loss': 0.0024, 'learning_rate': 1.181818181818182e-06, 'epoch': 1.59}\n","{'loss': 0.0004, 'learning_rate': 1.1666666666666668e-06, 'epoch': 1.59}\n","{'loss': 0.0001, 'learning_rate': 1.1515151515151516e-06, 'epoch': 1.6}\n","{'loss': 0.0008, 'learning_rate': 1.1363636363636364e-06, 'epoch': 1.61}\n","{'loss': 0.0018, 'learning_rate': 1.1212121212121214e-06, 'epoch': 1.61}\n","{'loss': 0.0002, 'learning_rate': 1.1060606060606062e-06, 'epoch': 1.62}\n","{'loss': 0.0003, 'learning_rate': 1.090909090909091e-06, 'epoch': 1.62}\n","{'loss': 0.0005, 'learning_rate': 1.0757575757575758e-06, 'epoch': 1.63}\n","{'loss': 0.0003, 'learning_rate': 1.0606060606060608e-06, 'epoch': 1.63}\n","{'loss': 0.0001, 'learning_rate': 1.0454545454545456e-06, 'epoch': 1.64}\n","{'loss': 0.0322, 'learning_rate': 1.0303030303030304e-06, 'epoch': 1.64}\n","{'loss': 0.0002, 'learning_rate': 1.0151515151515152e-06, 'epoch': 1.65}\n","{'loss': 0.0004, 'learning_rate': 1.0000000000000002e-06, 'epoch': 1.65}\n","{'loss': 0.0001, 'learning_rate': 9.84848484848485e-07, 'epoch': 1.66}\n","{'loss': 0.0011, 'learning_rate': 9.696969696969698e-07, 'epoch': 1.66}\n","{'loss': 0.0006, 'learning_rate': 9.545454545454548e-07, 'epoch': 1.67}\n","{'loss': 0.0003, 'learning_rate': 9.393939393939395e-07, 'epoch': 1.67}\n","{'loss': 0.0003, 'learning_rate': 9.242424242424244e-07, 'epoch': 1.68}\n","{'loss': 0.0003, 'learning_rate': 9.090909090909091e-07, 'epoch': 1.68}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"42b9560186cf4efba8d34912831bbcb0","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1900 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.010066197253763676, 'eval_recall': 0.9952980048290762, 'eval_precision': 0.9394266522729999, 'eval_f1': 0.9930264993026499, 'eval_runtime': 55.8208, 'eval_samples_per_second': 34.037, 'eval_steps_per_second': 34.037, 'epoch': 1.68}\n","{'loss': 0.0012, 'learning_rate': 8.93939393939394e-07, 'epoch': 1.69}\n","{'loss': 0.0003, 'learning_rate': 8.787878787878788e-07, 'epoch': 1.69}\n","{'loss': 0.0002, 'learning_rate': 8.636363636363637e-07, 'epoch': 1.7}\n","{'loss': 0.0001, 'learning_rate': 8.484848484848486e-07, 'epoch': 1.71}\n","{'loss': 0.0003, 'learning_rate': 8.333333333333333e-07, 'epoch': 1.71}\n","{'loss': 0.0001, 'learning_rate': 8.181818181818182e-07, 'epoch': 1.72}\n","{'loss': 0.0003, 'learning_rate': 8.030303030303031e-07, 'epoch': 1.72}\n","{'loss': 0.0001, 'learning_rate': 7.878787878787879e-07, 'epoch': 1.73}\n","{'loss': 0.0008, 'learning_rate': 7.727272727272727e-07, 'epoch': 1.73}\n","{'loss': 0.0001, 'learning_rate': 7.575757575757576e-07, 'epoch': 1.74}\n","{'loss': 0.0001, 'learning_rate': 7.424242424242425e-07, 'epoch': 1.74}\n","{'loss': 0.0002, 'learning_rate': 7.272727272727273e-07, 'epoch': 1.75}\n","{'loss': 0.0006, 'learning_rate': 7.121212121212122e-07, 'epoch': 1.75}\n","{'loss': 0.0002, 'learning_rate': 6.969696969696971e-07, 'epoch': 1.76}\n","{'loss': 0.0005, 'learning_rate': 6.818181818181818e-07, 'epoch': 1.76}\n","{'loss': 0.0056, 'learning_rate': 6.666666666666667e-07, 'epoch': 1.77}\n","{'loss': 0.0002, 'learning_rate': 6.515151515151516e-07, 'epoch': 1.77}\n","{'loss': 0.0004, 'learning_rate': 6.363636363636364e-07, 'epoch': 1.78}\n","{'loss': 0.0019, 'learning_rate': 6.212121212121212e-07, 'epoch': 1.78}\n","{'loss': 0.0007, 'learning_rate': 6.060606060606061e-07, 'epoch': 1.79}\n","{'loss': 0.0003, 'learning_rate': 5.90909090909091e-07, 'epoch': 1.79}\n","{'loss': 0.0001, 'learning_rate': 5.757575757575758e-07, 'epoch': 1.8}\n","{'loss': 0.0007, 'learning_rate': 5.606060606060607e-07, 'epoch': 1.81}\n","{'loss': 0.0006, 'learning_rate': 5.454545454545455e-07, 'epoch': 1.81}\n","{'loss': 0.0002, 'learning_rate': 5.303030303030304e-07, 'epoch': 1.82}\n","{'loss': 0.0001, 'learning_rate': 5.151515151515152e-07, 'epoch': 1.82}\n","{'loss': 0.0038, 'learning_rate': 5.000000000000001e-07, 'epoch': 1.83}\n","{'loss': 0.0188, 'learning_rate': 4.848484848484849e-07, 'epoch': 1.83}\n","{'loss': 0.0004, 'learning_rate': 4.696969696969697e-07, 'epoch': 1.84}\n","{'loss': 0.0153, 'learning_rate': 4.5454545454545457e-07, 'epoch': 1.84}\n","{'loss': 0.0003, 'learning_rate': 4.393939393939394e-07, 'epoch': 1.85}\n","{'loss': 0.0004, 'learning_rate': 4.242424242424243e-07, 'epoch': 1.85}\n","{'loss': 0.0002, 'learning_rate': 4.090909090909091e-07, 'epoch': 1.86}\n","{'loss': 0.0005, 'learning_rate': 3.9393939393939396e-07, 'epoch': 1.86}\n","{'loss': 0.002, 'learning_rate': 3.787878787878788e-07, 'epoch': 1.87}\n","{'loss': 0.0265, 'learning_rate': 3.6363636363636366e-07, 'epoch': 1.87}\n","{'loss': 0.0002, 'learning_rate': 3.4848484848484856e-07, 'epoch': 1.88}\n","{'loss': 0.0001, 'learning_rate': 3.3333333333333335e-07, 'epoch': 1.88}\n","{'loss': 0.0015, 'learning_rate': 3.181818181818182e-07, 'epoch': 1.89}\n","{'loss': 0.0006, 'learning_rate': 3.0303030303030305e-07, 'epoch': 1.89}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"aa5410ea899541c29cd7186f5bab95d9","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1900 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.009950129315257072, 'eval_recall': 0.9952980048290762, 'eval_precision': 0.9444109489931267, 'eval_f1': 0.9932396179847622, 'eval_runtime': 55.8415, 'eval_samples_per_second': 34.025, 'eval_steps_per_second': 34.025, 'epoch': 1.89}\n","{'loss': 0.0001, 'learning_rate': 2.878787878787879e-07, 'epoch': 1.9}\n","{'loss': 0.0003, 'learning_rate': 2.7272727272727274e-07, 'epoch': 1.91}\n","{'loss': 0.0002, 'learning_rate': 2.575757575757576e-07, 'epoch': 1.91}\n","{'loss': 0.0003, 'learning_rate': 2.4242424242424244e-07, 'epoch': 1.92}\n","{'loss': 0.0002, 'learning_rate': 2.2727272727272729e-07, 'epoch': 1.92}\n","{'loss': 0.0002, 'learning_rate': 2.1212121212121216e-07, 'epoch': 1.93}\n","{'loss': 0.0004, 'learning_rate': 1.9696969696969698e-07, 'epoch': 1.93}\n","{'loss': 0.0003, 'learning_rate': 1.8181818181818183e-07, 'epoch': 1.94}\n","{'loss': 0.0019, 'learning_rate': 1.6666666666666668e-07, 'epoch': 1.94}\n","{'loss': 0.0001, 'learning_rate': 1.5151515151515152e-07, 'epoch': 1.95}\n","{'loss': 0.0029, 'learning_rate': 1.3636363636363637e-07, 'epoch': 1.95}\n","{'loss': 0.0018, 'learning_rate': 1.2121212121212122e-07, 'epoch': 1.96}\n","{'loss': 0.0018, 'learning_rate': 1.0606060606060608e-07, 'epoch': 1.96}\n","{'loss': 0.0005, 'learning_rate': 9.090909090909091e-08, 'epoch': 1.97}\n","{'loss': 0.0006, 'learning_rate': 7.575757575757576e-08, 'epoch': 1.97}\n","{'loss': 0.001, 'learning_rate': 6.060606060606061e-08, 'epoch': 1.98}\n","{'loss': 0.0003, 'learning_rate': 4.545454545454546e-08, 'epoch': 1.98}\n","{'loss': 0.0014, 'learning_rate': 3.0303030303030305e-08, 'epoch': 1.99}\n","{'loss': 0.0009, 'learning_rate': 1.5151515151515152e-08, 'epoch': 1.99}\n","{'loss': 0.0028, 'learning_rate': 0.0, 'epoch': 2.0}\n","{'train_runtime': 1660.5459, 'train_samples_per_second': 9.152, 'train_steps_per_second': 2.288, 'train_loss': 0.0034090387485278036, 'epoch': 2.0}\n","Shutting down background jobs, please wait a moment...\n","Done!\n","Waiting for the remaining 12 operations to synchronize with Neptune. Do not kill this process.\n","All 12 operations synced, thanks for waiting!\n","Explore the metadata in the Neptune app:\n","https://app.neptune.ai/bernd.heidemann/PII/e/PII-223/metadata\n"]},{"data":{"text/plain":["TrainOutput(global_step=3800, training_loss=0.0034090387485278036, metrics={'train_runtime': 1660.5459, 'train_samples_per_second': 9.152, 'train_steps_per_second': 2.288, 'train_loss': 0.0034090387485278036, 'epoch': 2.0})"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["unfreeze(model)\n","trainer=get_trainer(model, train_ds, valid_ds, learnrate_multiplier=parameter[\"lr_scale_unfreeze\"])\n","trainer.train()"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","c:\\Users\\Bernd\\anaconda3\\envs\\mytorch\\lib\\site-packages\\transformers\\convert_slow_tokenizer.py:470: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n","  warnings.warn(\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"name":"stdout","output_type":"stream","text":["    row_id  document  token           label\n","0        0         7      9  B-NAME_STUDENT\n","1        1         7     10  I-NAME_STUDENT\n","2        2         7    482  B-NAME_STUDENT\n","3        3         7    483  I-NAME_STUDENT\n","4        4         7    741  B-NAME_STUDENT\n","5        5         7    742  I-NAME_STUDENT\n","6        6        10      0  B-NAME_STUDENT\n","7        7        10      1  I-NAME_STUDENT\n","8        8        10    464  B-NAME_STUDENT\n","9        9        10    465  I-NAME_STUDENT\n","10      10        16      4  B-NAME_STUDENT\n","11      11        16      5  I-NAME_STUDENT\n","12      12        20      5  B-NAME_STUDENT\n","13      13        20      6  I-NAME_STUDENT\n","14      14        20      8  I-NAME_STUDENT\n","15      15        56     12  B-NAME_STUDENT\n","16      16        56     13  I-NAME_STUDENT\n","17      17        86      6  B-NAME_STUDENT\n","18      18        86      7  I-NAME_STUDENT\n","19      19        93      0  B-NAME_STUDENT\n","20      20        93      1  I-NAME_STUDENT\n","21      21       104      7  B-NAME_STUDENT\n","22      22       104      8  B-NAME_STUDENT\n","23      23       104      9  I-NAME_STUDENT\n","24      24       112      5  B-NAME_STUDENT\n","25      25       112      6  I-NAME_STUDENT\n","26      26       123     32  B-NAME_STUDENT\n","27      27       123     33  I-NAME_STUDENT\n"]}],"source":["create_submission(model, f\"submission.csv\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"databundleVersionId":7500999,"sourceId":66653,"sourceType":"competition"},{"datasetId":4319117,"sourceId":7429898,"sourceType":"datasetVersion"}],"dockerImageVersionId":30636,"isGpuEnabled":true,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
