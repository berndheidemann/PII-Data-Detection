{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Transformer NER baseline [lb 0.854]\n","\n","The following is a basic script to train and run inference using `transformers` using 2x T4 GPUs. You might get better performance if you use a bigger model, or one that has already been trained on NER.\n","\n","It includes processing to correctly map the given tokens with labels during training and vice versa when running inference.\n","\n","\n","Update: Thanks to @takanashihumbert, I switched `tokens` for `token_map` which helped improve the score from 0.569 to 0.854!\n","\n","\n","deberta-v3-small: lb 0.576  \n","deberta-v3-base: lb 0.569 (before update) --> 0.854 (after update) "]},{"cell_type":"code","execution_count":68,"metadata":{"execution":{"iopub.execute_input":"2024-01-25T21:37:35.578114Z","iopub.status.busy":"2024-01-25T21:37:35.577723Z","iopub.status.idle":"2024-01-25T21:37:35.587366Z","shell.execute_reply":"2024-01-25T21:37:35.5858Z","shell.execute_reply.started":"2024-01-25T21:37:35.578083Z"},"trusted":true},"outputs":[],"source":["TRAINING = False # be sure to turn internet off if doing inference\n","\n","TRAINING_MODEL_PATH = \"microsoft/deberta-v3-large\"\n","TRAINING_MAX_LENGTH = 512\n","\n","\n","\n"," #   !pip install seqeval evaluate -q\n"," #   !pip install -U datasets accelerate transformers -q"]},{"cell_type":"code","execution_count":69,"metadata":{"execution":{"iopub.execute_input":"2024-01-25T21:37:35.590432Z","iopub.status.busy":"2024-01-25T21:37:35.589758Z","iopub.status.idle":"2024-01-25T21:37:35.604681Z","shell.execute_reply":"2024-01-25T21:37:35.603633Z","shell.execute_reply.started":"2024-01-25T21:37:35.590393Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["6807\n","dict_keys(['document', 'full_text', 'tokens', 'trailing_whitespace', 'labels'])\n","['Design', 'Thinking', 'for', 'innovation', 'reflexion', '-', 'Avril', '2021', '-', 'Nathalie']\n","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-NAME_STUDENT']\n","[True, True, True, True, False, False, True, False, False, True]\n"]}],"source":["\n","import json\n","\n","data = json.load(open(\"data/train.json\"))\n","\n","print(len(data))\n","print(data[0].keys())\n","\n","x = data[0]\n","\n","print(x[\"tokens\"][:10])\n","print(x[\"labels\"][:10])\n","print(x[\"trailing_whitespace\"][:10])"]},{"cell_type":"code","execution_count":70,"metadata":{"execution":{"iopub.execute_input":"2024-01-25T21:37:35.606208Z","iopub.status.busy":"2024-01-25T21:37:35.605889Z","iopub.status.idle":"2024-01-25T21:37:35.62164Z","shell.execute_reply":"2024-01-25T21:37:35.620746Z","shell.execute_reply.started":"2024-01-25T21:37:35.606175Z"},"trusted":true},"outputs":[{"data":{"text/plain":["{0: 'B-EMAIL',\n"," 1: 'B-ID_NUM',\n"," 2: 'B-NAME_STUDENT',\n"," 3: 'B-PHONE_NUM',\n"," 4: 'B-STREET_ADDRESS',\n"," 5: 'B-URL_PERSONAL',\n"," 6: 'B-USERNAME',\n"," 7: 'I-ID_NUM',\n"," 8: 'I-NAME_STUDENT',\n"," 9: 'I-PHONE_NUM',\n"," 10: 'I-STREET_ADDRESS',\n"," 11: 'I-URL_PERSONAL',\n"," 12: 'O'}"]},"execution_count":70,"metadata":{},"output_type":"execute_result"}],"source":["\n","from itertools import chain\n","\n","all_labels = sorted(list(set(chain(*[x[\"labels\"] for x in data]))))\n","label2id = {l: i for i,l in enumerate(all_labels)}\n","id2label = {v:k for k,v in label2id.items()}\n","\n","id2label"]},{"cell_type":"code","execution_count":71,"metadata":{},"outputs":[],"source":["from datasets import Dataset\n","\n","ds = Dataset.from_dict({\n","    \"full_text\": [x[\"full_text\"] for x in data],\n","    \"document\": [x[\"document\"] for x in data],\n","    \"tokens\": [x[\"tokens\"] for x in data],\n","    \"trailing_whitespace\": [x[\"trailing_whitespace\"] for x in data],\n","    \"provided_labels\": [x[\"labels\"] for x in data],\n","})"]},{"cell_type":"code","execution_count":89,"metadata":{"execution":{"iopub.execute_input":"2024-01-25T21:37:35.623598Z","iopub.status.busy":"2024-01-25T21:37:35.623238Z","iopub.status.idle":"2024-01-25T21:37:35.635911Z","shell.execute_reply":"2024-01-25T21:37:35.635016Z","shell.execute_reply.started":"2024-01-25T21:37:35.623565Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"name":"stdout","output_type":"stream","text":["original: [CLS] Design Thinking for Innovation  Reflection  1. Challenge: To expand the distribution of Indian Sindhi papad, globally, to the areas  where the Indian diaspora lives.  A papad basically is a crisp, round flatbread from India. It is typically based on a  seasoned dough usually made from peeled black gram flour, either fried or cooked  with dry heat. And Sindhis are an ethno-linguistic group who speak the Sindhi  language. After the partition of India, most of them migrated to other parts of the  world. And Sindhi papad has a unique taste of its own. But it is usually restricted to  some of the Indian cities itself. Not everyone has the access to have the food items  in their households, especially those who stay thousands of kilometres away from  India.  2. Selection: The tool I’ve selected is Learning Launch. I selected it for the challenge  because I’ve never approached this idea much in the exercises. Also, I mostly liked the  approach of having an initial ‘hypothesis’. Learning Launch process is basically an idea  generating tool which includes a rough idea, a specific group of persons, who have a  specific need, the idea that meets the need, and which might turn out to be better than  the current alternatives. This overall creates a hypothesis. An appropriate video lecture  reference for this could be the one which was there in the course itself, “Learning Launch  Tool”, in week 4.  3. Application: First, I pondered upon an idea for which there might be a need for a certain  section of people. For instance, here, it is the Sindhi diaspora’s need for having their  traditional Sindhi food item for themselves. Although, there might be several ways to  order Sindhi papad online, they are usually expensive due to the shipping charges. Here,  I am mostly highlighting on the alternative of having a collaboration or a joint venture with  further international organizations and to build a franchise. Although there could be a  probability of the tool being partially effective.  4. Insight: To be frank, I’m only at a nascent stage of the challenge. From this conception,  to the actual establishment of the products inside the global supermarkets and grocery  stores, it’ll require several other aspects like market research, demographic research and  furthermore aspects. Also, as the professor in the video said, that the idea can also be  inserted in the ‘trash bin’, that is, it might be used not now but later, when it’s need  becomes quite pertinent.  5. Approach: Next time, or rather, whenever I’ll brainstorm more with this idea, I shall apply  the storytelling tool. The reason being that there actually have been several fact-based  stories in which Sindhi papad has been appreciated across several groups of people,  especially in India. For more, you can look-up this link:  https://alvarado.com/categoriesindex.html  \n","tokenize: [CLS] Design Thinking for Innovation Reflection 1. Challenge: To expand the distribution of Indian Sindhi papad, globally, to the areas where the Indian diaspora lives. A papad basically is a crisp, round flatbread from India. It is typically based on a seasoned dough usually made from peeled black gram flour, either fried or cooked with dry heat. And Sindhis are an ethno-linguistic group who speak the Sindhi language. After the partition of India, most of them migrated to other parts of the world. And Sindhi papad has a unique taste of its own. But it is usually restricted to some of the Indian cities itself. Not everyone has the access to have the food items in their households, especially those who stay thousands of kilometres away from India. 2. Selection: The tool I’ve selected is Learning Launch. I selected it for the challenge because I’ve never approached this idea much in the exercises. Also, I mostly liked the approach of having an initial ‘hypothesis’. Learning Launch process is basically an idea generating tool which includes a rough idea, a specific group of persons, who have a specific need, the idea that meets the need, and which might turn out to be better than the current alternatives. This overall creates a hypothesis. An appropriate video lecture reference for this could be the one which was there in the course itself, “Learning Launch Tool”, in week 4. 3. Application: First, I pondered upon an idea for which there might be a need for a certain section of people. For instance, here, it is the Sindhi diaspora’s need for having their traditional Sindhi food item for themselves. Although, there might be several ways to order Sindhi papad online, they are usually expensive due to the shipping charges. Here, I am mostly highlighting on the alternative of having a collaboration or a joint venture with further international organizations and to build a franchise. Although there could be a probability of the tool being partially effective. 4. Insight: To be frank, I’m only at a nascent stage of the challenge. From this conception, to the actual establishment of the products inside the global supermarkets and grocery stores, it’ll require several other aspects like market research, demographic research and furthermore aspects. Also, as the professor in the video said, that the idea can also be inserted in the ‘trash bin’, that is, it might be used not now but later, when it’s need becomes quite pertinent. 5. Approach: Next time, or rather, whenever I’ll brainstorm more with this idea, I shall apply the storytelling tool. The reason being that there actually have been several fact-based stories in which Sindhi papad has been appreciated across several groups of people, especially in India. For more, you can look-up this link: https://alvarado.com/categoriesindex.html[SEP]\n","labels: O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O B-URL_PERSONAL B-URL_PERSONAL B-URL_PERSONAL B-URL_PERSONAL B-URL_PERSONAL B-URL_PERSONAL B-URL_PERSONAL B-URL_PERSONAL B-URL_PERSONAL B-URL_PERSONAL B-URL_PERSONAL B-URL_PERSONAL B-URL_PERSONAL O\n"]},{"data":{"text/plain":["['[CLS]',\n"," '▁Design',\n"," '▁Thinking',\n"," '▁for',\n"," '▁Innovation',\n"," '▁Reflection',\n"," '▁1',\n"," '.',\n"," '▁Challenge',\n"," ':',\n"," '▁To',\n"," '▁expand',\n"," '▁the',\n"," '▁distribution',\n"," '▁of',\n"," '▁Indian',\n"," '▁Sindhi',\n"," '▁papa',\n"," 'd',\n"," ',',\n"," '▁globally',\n"," ',',\n"," '▁to',\n"," '▁the',\n"," '▁areas',\n"," '▁where',\n"," '▁the',\n"," '▁Indian',\n"," '▁diaspora',\n"," '▁lives',\n"," '.',\n"," '▁A',\n"," '▁papa',\n"," 'd',\n"," '▁basically',\n"," '▁is',\n"," '▁a',\n"," '▁crisp',\n"," ',',\n"," '▁round',\n"," '▁flatbread',\n"," '▁from',\n"," '▁India',\n"," '.',\n"," '▁It',\n"," '▁is',\n"," '▁typically',\n"," '▁based',\n"," '▁on',\n"," '▁a',\n"," '▁seasoned',\n"," '▁dough',\n"," '▁usually',\n"," '▁made',\n"," '▁from',\n"," '▁peeled',\n"," '▁black',\n"," '▁gram',\n"," '▁flour',\n"," ',',\n"," '▁either',\n"," '▁fried',\n"," '▁or',\n"," '▁cooked',\n"," '▁with',\n"," '▁dry',\n"," '▁heat',\n"," '.',\n"," '▁And',\n"," '▁Sindhi',\n"," 's',\n"," '▁are',\n"," '▁an',\n"," '▁ethno',\n"," '-',\n"," 'linguistic',\n"," '▁group',\n"," '▁who',\n"," '▁speak',\n"," '▁the',\n"," '▁Sindhi',\n"," '▁language',\n"," '.',\n"," '▁After',\n"," '▁the',\n"," '▁partition',\n"," '▁of',\n"," '▁India',\n"," ',',\n"," '▁most',\n"," '▁of',\n"," '▁them',\n"," '▁migrated',\n"," '▁to',\n"," '▁other',\n"," '▁parts',\n"," '▁of',\n"," '▁the',\n"," '▁world',\n"," '.',\n"," '▁And',\n"," '▁Sindhi',\n"," '▁papa',\n"," 'd',\n"," '▁has',\n"," '▁a',\n"," '▁unique',\n"," '▁taste',\n"," '▁of',\n"," '▁its',\n"," '▁own',\n"," '.',\n"," '▁But',\n"," '▁it',\n"," '▁is',\n"," '▁usually',\n"," '▁restricted',\n"," '▁to',\n"," '▁some',\n"," '▁of',\n"," '▁the',\n"," '▁Indian',\n"," '▁cities',\n"," '▁itself',\n"," '.',\n"," '▁Not',\n"," '▁everyone',\n"," '▁has',\n"," '▁the',\n"," '▁access',\n"," '▁to',\n"," '▁have',\n"," '▁the',\n"," '▁food',\n"," '▁items',\n"," '▁in',\n"," '▁their',\n"," '▁households',\n"," ',',\n"," '▁especially',\n"," '▁those',\n"," '▁who',\n"," '▁stay',\n"," '▁thousands',\n"," '▁of',\n"," '▁kilometres',\n"," '▁away',\n"," '▁from',\n"," '▁India',\n"," '.',\n"," '▁2',\n"," '.',\n"," '▁Selection',\n"," ':',\n"," '▁The',\n"," '▁tool',\n"," '▁I',\n"," '’',\n"," 've',\n"," '▁selected',\n"," '▁is',\n"," '▁Learning',\n"," '▁Launch',\n"," '.',\n"," '▁I',\n"," '▁selected',\n"," '▁it',\n"," '▁for',\n"," '▁the',\n"," '▁challenge',\n"," '▁because',\n"," '▁I',\n"," '’',\n"," 've',\n"," '▁never',\n"," '▁approached',\n"," '▁this',\n"," '▁idea',\n"," '▁much',\n"," '▁in',\n"," '▁the',\n"," '▁exercises',\n"," '.',\n"," '▁Also',\n"," ',',\n"," '▁I',\n"," '▁mostly',\n"," '▁liked',\n"," '▁the',\n"," '▁approach',\n"," '▁of',\n"," '▁having',\n"," '▁an',\n"," '▁initial',\n"," '▁‘',\n"," 'hypo',\n"," 'thesis',\n"," '’',\n"," '.',\n"," '▁Learning',\n"," '▁Launch',\n"," '▁process',\n"," '▁is',\n"," '▁basically',\n"," '▁an',\n"," '▁idea',\n"," '▁generating',\n"," '▁tool',\n"," '▁which',\n"," '▁includes',\n"," '▁a',\n"," '▁rough',\n"," '▁idea',\n"," ',',\n"," '▁a',\n"," '▁specific',\n"," '▁group',\n"," '▁of',\n"," '▁persons',\n"," ',',\n"," '▁who',\n"," '▁have',\n"," '▁a',\n"," '▁specific',\n"," '▁need',\n"," ',',\n"," '▁the',\n"," '▁idea',\n"," '▁that',\n"," '▁meets',\n"," '▁the',\n"," '▁need',\n"," ',',\n"," '▁and',\n"," '▁which',\n"," '▁might',\n"," '▁turn',\n"," '▁out',\n"," '▁to',\n"," '▁be',\n"," '▁better',\n"," '▁than',\n"," '▁the',\n"," '▁current',\n"," '▁alternatives',\n"," '.',\n"," '▁This',\n"," '▁overall',\n"," '▁creates',\n"," '▁a',\n"," '▁hypothesis',\n"," '.',\n"," '▁An',\n"," '▁appropriate',\n"," '▁video',\n"," '▁lecture',\n"," '▁reference',\n"," '▁for',\n"," '▁this',\n"," '▁could',\n"," '▁be',\n"," '▁the',\n"," '▁one',\n"," '▁which',\n"," '▁was',\n"," '▁there',\n"," '▁in',\n"," '▁the',\n"," '▁course',\n"," '▁itself',\n"," ',',\n"," '▁“',\n"," 'Learning',\n"," '▁Launch',\n"," '▁Tool',\n"," '”',\n"," ',',\n"," '▁in',\n"," '▁week',\n"," '▁4',\n"," '.',\n"," '▁3',\n"," '.',\n"," '▁Application',\n"," ':',\n"," '▁First',\n"," ',',\n"," '▁I',\n"," '▁pondered',\n"," '▁upon',\n"," '▁an',\n"," '▁idea',\n"," '▁for',\n"," '▁which',\n"," '▁there',\n"," '▁might',\n"," '▁be',\n"," '▁a',\n"," '▁need',\n"," '▁for',\n"," '▁a',\n"," '▁certain',\n"," '▁section',\n"," '▁of',\n"," '▁people',\n"," '.',\n"," '▁For',\n"," '▁instance',\n"," ',',\n"," '▁here',\n"," ',',\n"," '▁it',\n"," '▁is',\n"," '▁the',\n"," '▁Sindhi',\n"," '▁diaspora',\n"," '’',\n"," 's',\n"," '▁need',\n"," '▁for',\n"," '▁having',\n"," '▁their',\n"," '▁traditional',\n"," '▁Sindhi',\n"," '▁food',\n"," '▁item',\n"," '▁for',\n"," '▁themselves',\n"," '.',\n"," '▁Although',\n"," ',',\n"," '▁there',\n"," '▁might',\n"," '▁be',\n"," '▁several',\n"," '▁ways',\n"," '▁to',\n"," '▁order',\n"," '▁Sindhi',\n"," '▁papa',\n"," 'd',\n"," '▁online',\n"," ',',\n"," '▁they',\n"," '▁are',\n"," '▁usually',\n"," '▁expensive',\n"," '▁due',\n"," '▁to',\n"," '▁the',\n"," '▁shipping',\n"," '▁charges',\n"," '.',\n"," '▁Here',\n"," ',',\n"," '▁I',\n"," '▁am',\n"," '▁mostly',\n"," '▁highlighting',\n"," '▁on',\n"," '▁the',\n"," '▁alternative',\n"," '▁of',\n"," '▁having',\n"," '▁a',\n"," '▁collaboration',\n"," '▁or',\n"," '▁a',\n"," '▁joint',\n"," '▁venture',\n"," '▁with',\n"," '▁further',\n"," '▁international',\n"," '▁organizations',\n"," '▁and',\n"," '▁to',\n"," '▁build',\n"," '▁a',\n"," '▁franchise',\n"," '.',\n"," '▁Although',\n"," '▁there',\n"," '▁could',\n"," '▁be',\n"," '▁a',\n"," '▁probability',\n"," '▁of',\n"," '▁the',\n"," '▁tool',\n"," '▁being',\n"," '▁partially',\n"," '▁effective',\n"," '.',\n"," '▁4',\n"," '.',\n"," '▁Insight',\n"," ':',\n"," '▁To',\n"," '▁be',\n"," '▁frank',\n"," ',',\n"," '▁I',\n"," '’',\n"," 'm',\n"," '▁only',\n"," '▁at',\n"," '▁a',\n"," '▁nascent',\n"," '▁stage',\n"," '▁of',\n"," '▁the',\n"," '▁challenge',\n"," '.',\n"," '▁From',\n"," '▁this',\n"," '▁conception',\n"," ',',\n"," '▁to',\n"," '▁the',\n"," '▁actual',\n"," '▁establishment',\n"," '▁of',\n"," '▁the',\n"," '▁products',\n"," '▁inside',\n"," '▁the',\n"," '▁global',\n"," '▁supermarkets',\n"," '▁and',\n"," '▁grocery',\n"," '▁stores',\n"," ',',\n"," '▁it',\n"," '’',\n"," 'll',\n"," '▁require',\n"," '▁several',\n"," '▁other',\n"," '▁aspects',\n"," '▁like',\n"," '▁market',\n"," '▁research',\n"," ',',\n"," '▁demographic',\n"," '▁research',\n"," '▁and',\n"," '▁furthermore',\n"," '▁aspects',\n"," '.',\n"," '▁Also',\n"," ',',\n"," '▁as',\n"," '▁the',\n"," '▁professor',\n"," '▁in',\n"," '▁the',\n"," '▁video',\n"," '▁said',\n"," ',',\n"," '▁that',\n"," '▁the',\n"," '▁idea',\n"," '▁can',\n"," '▁also',\n"," '▁be',\n"," '▁inserted',\n"," '▁in',\n"," '▁the',\n"," '▁‘',\n"," 'trash',\n"," '▁bin',\n"," '’',\n"," ',',\n"," '▁that',\n"," '▁is',\n"," ',',\n"," '▁it',\n"," '▁might',\n"," '▁be',\n"," '▁used',\n"," '▁not',\n"," '▁now',\n"," '▁but',\n"," '▁later',\n"," ',',\n"," '▁when',\n"," '▁it',\n"," '’',\n"," 's',\n"," '▁need',\n"," '▁becomes',\n"," '▁quite',\n"," '▁pertinent',\n"," '.',\n"," '▁5',\n"," '.',\n"," '▁Approach',\n"," ':',\n"," '▁Next',\n"," '▁time',\n"," ',',\n"," '▁or',\n"," '▁rather',\n"," ',',\n"," '▁whenever',\n"," '▁I',\n"," '’',\n"," 'll',\n"," '▁brainstorm',\n"," '▁more',\n"," '▁with',\n"," '▁this',\n"," '▁idea',\n"," ',',\n"," '▁I',\n"," '▁shall',\n"," '▁apply',\n"," '▁the',\n"," '▁storytelling',\n"," '▁tool',\n"," '.',\n"," '▁The',\n"," '▁reason',\n"," '▁being',\n"," '▁that',\n"," '▁there',\n"," '▁actually',\n"," '▁have',\n"," '▁been',\n"," '▁several',\n"," '▁fact',\n"," '-',\n"," 'based',\n"," '▁stories',\n"," '▁in',\n"," '▁which',\n"," '▁Sindhi',\n"," '▁papa',\n"," 'd',\n"," '▁has',\n"," '▁been',\n"," '▁appreciated',\n"," '▁across',\n"," '▁several',\n"," '▁groups',\n"," '▁of',\n"," '▁people',\n"," ',',\n"," '▁especially',\n"," '▁in',\n"," '▁India',\n"," '.',\n"," '▁For',\n"," '▁more',\n"," ',',\n"," '▁you',\n"," '▁can',\n"," '▁look',\n"," '-',\n"," 'up',\n"," '▁this',\n"," '▁link',\n"," ':',\n"," '▁https',\n"," ':',\n"," '/',\n"," '/',\n"," 'alva',\n"," 'rado',\n"," '.',\n"," 'com',\n"," '/',\n"," 'categories',\n"," 'index',\n"," '.',\n"," 'html',\n"," '[SEP]']"]},"execution_count":89,"metadata":{},"output_type":"execute_result"}],"source":["\n","from transformers import AutoTokenizer\n","import numpy as np\n","\n","tokenizer = AutoTokenizer.from_pretrained(TRAINING_MODEL_PATH)\n","\n","def tokenize(example, tokenizer, label2id):\n","    text = []\n","    labels = []\n","    for single_token, single_label, single_whitespace in zip(example[\"tokens\"], example[\"provided_labels\"], example[\"trailing_whitespace\"]):\n","        text.append(single_token)\n","        labels.extend([single_label]*len(single_token))\n","        if single_whitespace:\n","            text.append(\" \")\n","            labels.append(\"O\")\n","\n","    tokenized = tokenizer(\"\".join(text), return_offsets_mapping=True, truncation=False)\n","\n","    labels = np.array(labels)\n","\n","    text = \"\".join(text)\n","    token_labels = []\n","\n","    for start_idx, end_idx in tokenized.offset_mapping:\n","\n","        # CLS token\n","        if start_idx + end_idx == 0: \n","            token_labels.append(label2id[\"O\"])\n","            continue\n","\n","        # case when token starts with whitespace\n","        if text[start_idx].isspace():\n","            start_idx += 1\n","        \n","        while start_idx >= len(labels):\n","            start_idx -= 1\n","\n","        token_labels.append(label2id[labels[start_idx]])\n","\n","    length = len(tokenized.input_ids)\n","\n","    return {\n","        **tokenized,\n","        \"labels\": token_labels,\n","        \"length\": length\n","    }\n","\n","#id=0\n","#for entry in ds:\n","#    if entry['document'] == 13315:\n","#        print(id)\n","#        break\n","#    id+=1\n","\n","sample = ds[2790]\n","sample_tokenized=tokenize(sample, tokenizer, label2id)\n","\n","# create text of sample_tokenized\n","\n","text = tokenizer.decode(sample_tokenized[\"input_ids\"])\n","\n","print(\"original: [CLS] \" + sample[\"full_text\"].replace(\"\\n\", \" \"))\n","print(\"tokenize: \" + text)\n","print(\"labels: \" + \" \".join([id2label[x] for x in sample_tokenized[\"labels\"]]))\n","\n","# tokenizer.convert_ids_to_tokens(sample_tokenized[\"input_ids\"])\n"]},{"cell_type":"code","execution_count":73,"metadata":{"execution":{"iopub.execute_input":"2024-01-25T21:37:35.641436Z","iopub.status.busy":"2024-01-25T21:37:35.641152Z","iopub.status.idle":"2024-01-25T21:37:35.655238Z","shell.execute_reply":"2024-01-25T21:37:35.654323Z","shell.execute_reply.started":"2024-01-25T21:37:35.641411Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2a722613b1f04457a7bd35de30e41475","version_major":2,"version_minor":0},"text/plain":["Map (num_proc=12):   0%|          | 0/6807 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["\n","\n","\n","ds = ds.map(lambda x: tokenize(x, tokenizer, label2id), num_proc=12)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":74,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["full_text  --->  Design Thinking for innovation reflexion-Avril 2021-Nathalie Sylla\n","\n","Challenge & selection\n","\n","The tool I use to help all stakeholders finding their way through the complexity of a project is the  mind map.\n","\n","What exactly is a mind map? According to the definition of Buzan T. and Buzan B. (1999, Dessine-moi  l'intelligence. Paris: Les Éditions d'Organisation.), the mind map (or heuristic diagram) is a graphic  representation technique that follows the natural functioning of the mind and allows the brain's  potential to be released. Cf Annex1\n","\n","This tool has many advantages:\n","\n","•  It is accessible to all and does not require significant material investment and can be done  quickly\n","\n","•  It is scalable\n","\n","•  It allows categorization and linking of information\n","\n","•  It can be applied to any type of situation: notetaking, problem solving, analysis, creation of  new ideas\n","\n","•  It is suitable for all people and is easy to learn\n","\n","•  It is fun and encourages exchanges\n","\n","•  It makes visible the dimension of projects, opportunities, interconnections\n","\n","•  It synthesizes\n","\n","•  It makes the project understandable\n","\n","•  It allows you to explore ideas\n","\n","The creation of a mind map starts with an idea/problem located at its center. This starting point  generates ideas/work areas, incremented around this center in a radial structure, which in turn is  completed with as many branches as new ideas.\n","\n","This tool enables creativity and logic to be mobilized, it is a map of the thoughts.\n","\n","Creativity is enhanced because participants feel comfortable with the method.\n","\n","Application & Insight\n","\n","I start the process of the mind map creation with the stakeholders standing around a large board  (white or paper board). In the center of the board, I write and highlight the topic to design.\n","\n","Through a series of questions, I guide the stakeholders in modelling the mind map. I adapt the series  of questions according to the topic to be addressed. In the type of questions, we can use: who, what,  when, where, why, how, how much.\n","\n","The use of the “why” is very interesting to understand the origin. By this way, the interviewed person  frees itself from paradigms and thus dares to propose new ideas / ways of functioning. I plan two  hours for a workshop.\n","\n","Design Thinking for innovation reflexion-Avril 2021-Nathalie Sylla\n","\n","After modelling the mind map on paper, I propose to the participants a digital visualization of their  work with the addition of color codes, images and interconnections. This second workshop also lasts  two hours and allows the mind map to evolve. Once familiarized with it, the stakeholders discover  the power of the tool. Then, the second workshop brings out even more ideas and constructive  exchanges between the stakeholders. Around this new mind map, they have learned to work  together and want to make visible the untold ideas.\n","\n","I now present all the projects I manage in this type of format in order to ease rapid understanding for  decision-makers. These presentations are the core of my business models. The decision-makers are  thus able to identify the opportunities of the projects and can take quick decisions to validate them.  They find answers to their questions thank to a schematic representation.\n","\n","Approach\n","\n","What I find amazing with the facilitation of this type of workshop is the participants commitment for  the project. This tool helps to give meaning. The participants appropriate the story and want to keep  writing it. Then, they easily become actors or sponsors of the project. A trust relationship is built,  thus facilitating the implementation of related actions.\n","\n","Design Thinking for innovation reflexion-Avril 2021-Nathalie Sylla\n","\n","Annex 1: Mind Map Shared facilities project\n","\n","\n","document  --->  7\n","tokens  --->  ['Design', 'Thinking', 'for', 'innovation', 'reflexion', '-', 'Avril', '2021', '-', 'Nathalie', 'Sylla', '\\n\\n', 'Challenge', '&', 'selection', '\\n\\n', 'The', 'tool', 'I', 'use', 'to', 'help', 'all', 'stakeholders', 'finding', 'their', 'way', 'through', 'the', 'complexity', 'of', 'a', 'project', 'is', 'the', ' ', 'mind', 'map', '.', '\\n\\n', 'What', 'exactly', 'is', 'a', 'mind', 'map', '?', 'According', 'to', 'the', 'definition', 'of', 'Buzan', 'T.', 'and', 'Buzan', 'B.', '(', '1999', ',', 'Dessine', '-', 'moi', ' ', \"l'intelligence\", '.', 'Paris', ':', 'Les', 'Éditions', \"d'Organisation\", '.', ')', ',', 'the', 'mind', 'map', '(', 'or', 'heuristic', 'diagram', ')', 'is', 'a', 'graphic', ' ', 'representation', 'technique', 'that', 'follows', 'the', 'natural', 'functioning', 'of', 'the', 'mind', 'and', 'allows', 'the', 'brain', \"'s\", ' ', 'potential', 'to', 'be', 'released', '.', 'Cf', 'Annex1', '\\n\\n', 'This', 'tool', 'has', 'many', 'advantages', ':', '\\n\\n', '•', ' ', 'It', 'is', 'accessible', 'to', 'all', 'and', 'does', 'not', 'require', 'significant', 'material', 'investment', 'and', 'can', 'be', 'done', ' ', 'quickly', '\\n\\n', '•', ' ', 'It', 'is', 'scalable', '\\n\\n', '•', ' ', 'It', 'allows', 'categorization', 'and', 'linking', 'of', 'information', '\\n\\n', '•', ' ', 'It', 'can', 'be', 'applied', 'to', 'any', 'type', 'of', 'situation', ':', 'notetaking', ',', 'problem', 'solving', ',', 'analysis', ',', 'creation', 'of', ' ', 'new', 'ideas', '\\n\\n', '•', ' ', 'It', 'is', 'suitable', 'for', 'all', 'people', 'and', 'is', 'easy', 'to', 'learn', '\\n\\n', '•', ' ', 'It', 'is', 'fun', 'and', 'encourages', 'exchanges', '\\n\\n', '•', ' ', 'It', 'makes', 'visible', 'the', 'dimension', 'of', 'projects', ',', 'opportunities', ',', 'interconnections', '\\n\\n', '•', ' ', 'It', 'synthesizes', '\\n\\n', '•', ' ', 'It', 'makes', 'the', 'project', 'understandable', '\\n\\n', '•', ' ', 'It', 'allows', 'you', 'to', 'explore', 'ideas', '\\n\\n', 'The', 'creation', 'of', 'a', 'mind', 'map', 'starts', 'with', 'an', 'idea', '/', 'problem', 'located', 'at', 'its', 'center', '.', 'This', 'starting', 'point', ' ', 'generates', 'ideas', '/', 'work', 'areas', ',', 'incremented', 'around', 'this', 'center', 'in', 'a', 'radial', 'structure', ',', 'which', 'in', 'turn', 'is', ' ', 'completed', 'with', 'as', 'many', 'branches', 'as', 'new', 'ideas', '.', '\\n\\n', 'This', 'tool', 'enables', 'creativity', 'and', 'logic', 'to', 'be', 'mobilized', ',', 'it', 'is', 'a', 'map', 'of', 'the', 'thoughts', '.', '\\n\\n', 'Creativity', 'is', 'enhanced', 'because', 'participants', 'feel', 'comfortable', 'with', 'the', 'method', '.', '\\n\\n', 'Application', '&', 'Insight', '\\n\\n', 'I', 'start', 'the', 'process', 'of', 'the', 'mind', 'map', 'creation', 'with', 'the', 'stakeholders', 'standing', 'around', 'a', 'large', 'board', ' ', '(', 'white', 'or', 'paper', 'board', ')', '.', 'In', 'the', 'center', 'of', 'the', 'board', ',', 'I', 'write', 'and', 'highlight', 'the', 'topic', 'to', 'design', '.', '\\n\\n', 'Through', 'a', 'series', 'of', 'questions', ',', 'I', 'guide', 'the', 'stakeholders', 'in', 'modelling', 'the', 'mind', 'map', '.', 'I', 'adapt', 'the', 'series', ' ', 'of', 'questions', 'according', 'to', 'the', 'topic', 'to', 'be', 'addressed', '.', 'In', 'the', 'type', 'of', 'questions', ',', 'we', 'can', 'use', ':', 'who', ',', 'what', ',', ' ', 'when', ',', 'where', ',', 'why', ',', 'how', ',', 'how', 'much', '.', '\\n\\n', 'The', 'use', 'of', 'the', '“', 'why', '”', 'is', 'very', 'interesting', 'to', 'understand', 'the', 'origin', '.', 'By', 'this', 'way', ',', 'the', 'interviewed', 'person', ' ', 'frees', 'itself', 'from', 'paradigms', 'and', 'thus', 'dares', 'to', 'propose', 'new', 'ideas', '/', 'ways', 'of', 'functioning', '.', 'I', 'plan', 'two', ' ', 'hours', 'for', 'a', 'workshop', '.', '\\n\\n', 'Design', 'Thinking', 'for', 'innovation', 'reflexion', '-', 'Avril', '2021', '-', 'Nathalie', 'Sylla', '\\n\\n', 'After', 'modelling', 'the', 'mind', 'map', 'on', 'paper', ',', 'I', 'propose', 'to', 'the', 'participants', 'a', 'digital', 'visualization', 'of', 'their', ' ', 'work', 'with', 'the', 'addition', 'of', 'color', 'codes', ',', 'images', 'and', 'interconnections', '.', 'This', 'second', 'workshop', 'also', 'lasts', ' ', 'two', 'hours', 'and', 'allows', 'the', 'mind', 'map', 'to', 'evolve', '.', 'Once', 'familiarized', 'with', 'it', ',', 'the', 'stakeholders', 'discover', ' ', 'the', 'power', 'of', 'the', 'tool', '.', 'Then', ',', 'the', 'second', 'workshop', 'brings', 'out', 'even', 'more', 'ideas', 'and', 'constructive', ' ', 'exchanges', 'between', 'the', 'stakeholders', '.', 'Around', 'this', 'new', 'mind', 'map', ',', 'they', 'have', 'learned', 'to', 'work', ' ', 'together', 'and', 'want', 'to', 'make', 'visible', 'the', 'untold', 'ideas', '.', '\\n\\n', 'I', 'now', 'present', 'all', 'the', 'projects', 'I', 'manage', 'in', 'this', 'type', 'of', 'format', 'in', 'order', 'to', 'ease', 'rapid', 'understanding', 'for', ' ', 'decision', '-', 'makers', '.', 'These', 'presentations', 'are', 'the', 'core', 'of', 'my', 'business', 'models', '.', 'The', 'decision', '-', 'makers', 'are', ' ', 'thus', 'able', 'to', 'identify', 'the', 'opportunities', 'of', 'the', 'projects', 'and', 'can', 'take', 'quick', 'decisions', 'to', 'validate', 'them', '.', ' ', 'They', 'find', 'answers', 'to', 'their', 'questions', 'thank', 'to', 'a', 'schematic', 'representation', '.', '\\n\\n', 'Approach', '\\n\\n', 'What', 'I', 'find', 'amazing', 'with', 'the', 'facilitation', 'of', 'this', 'type', 'of', 'workshop', 'is', 'the', 'participants', 'commitment', 'for', ' ', 'the', 'project', '.', 'This', 'tool', 'helps', 'to', 'give', 'meaning', '.', 'The', 'participants', 'appropriate', 'the', 'story', 'and', 'want', 'to', 'keep', ' ', 'writing', 'it', '.', 'Then', ',', 'they', 'easily', 'become', 'actors', 'or', 'sponsors', 'of', 'the', 'project', '.', 'A', 'trust', 'relationship', 'is', 'built', ',', ' ', 'thus', 'facilitating', 'the', 'implementation', 'of', 'related', 'actions', '.', '\\n\\n', 'Design', 'Thinking', 'for', 'innovation', 'reflexion', '-', 'Avril', '2021', '-', 'Nathalie', 'Sylla', '\\n\\n', 'Annex', '1', ':', 'Mind', 'Map', 'Shared', 'facilities', 'project', '\\n\\n']\n","trailing_whitespace  --->  [True, True, True, True, False, False, True, False, False, True, False, False, True, True, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, True, False, False, False, True, True, True, True, True, False, True, True, True, True, True, True, True, True, True, True, True, False, False, True, False, False, True, False, False, True, False, True, True, True, False, False, False, True, True, True, True, False, True, True, False, True, True, True, True, False, True, True, True, True, True, True, True, True, True, True, True, True, True, False, True, False, True, True, True, False, True, True, False, False, True, True, True, True, False, False, False, True, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, True, False, True, True, False, False, True, False, True, True, True, True, True, True, False, False, True, False, True, True, True, True, True, True, True, True, False, True, False, True, True, False, True, False, True, True, True, False, True, False, False, True, False, True, True, True, True, True, True, True, True, True, True, False, False, True, False, True, True, True, True, True, False, False, True, False, True, True, True, True, True, True, False, True, False, True, False, False, True, False, True, False, False, True, False, True, True, True, True, False, False, True, False, True, True, True, True, True, False, False, True, True, True, True, True, True, True, True, True, False, False, True, True, True, True, False, True, True, True, True, False, True, False, False, True, False, True, True, True, True, True, True, True, True, False, True, True, True, True, True, False, True, True, True, True, True, True, True, False, False, False, True, True, True, True, True, True, True, True, False, True, True, True, True, True, True, True, False, False, False, True, True, True, True, True, True, True, True, True, False, False, False, True, True, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, True, True, True, False, False, True, True, True, True, True, True, False, True, True, True, True, True, True, True, True, False, False, False, True, True, True, True, False, True, True, True, True, True, True, True, True, True, False, True, True, True, True, True, False, True, True, True, True, True, True, True, True, False, True, True, True, True, True, False, True, True, True, False, True, False, True, False, True, False, False, True, False, True, False, True, False, True, True, False, False, False, True, True, True, True, False, False, True, True, True, True, True, True, True, False, True, True, True, False, True, True, True, True, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, True, True, True, True, False, True, True, True, False, False, False, True, True, True, True, False, False, True, False, False, True, False, False, True, True, True, True, True, True, False, True, True, True, True, True, True, True, True, True, True, True, False, True, True, True, True, True, True, False, True, True, True, False, True, True, True, True, True, True, False, True, True, True, True, True, True, True, True, False, True, True, True, True, False, True, True, True, True, False, True, True, True, True, False, True, False, True, True, True, True, True, True, True, True, True, True, True, False, True, True, True, False, True, True, True, True, True, False, True, True, True, True, True, True, False, True, True, True, True, True, True, True, True, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, True, True, True, True, True, True, True, True, True, False, True, True, False, False, True, True, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, True, False, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, True, False, True, True, True, True, True, True, False, True, True, True, True, True, True, True, True, True, True, False, True, False, True, False, True, True, True, True, True, True, True, True, True, False, True, True, True, True, True, False, True, False, True, True, True, True, True, True, False, False, False, True, True, True, True, False, False, True, False, False, True, False, False, True, False, True, True, True, True, True, False, False]\n","provided_labels  --->  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-NAME_STUDENT', 'I-NAME_STUDENT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-NAME_STUDENT', 'I-NAME_STUDENT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-NAME_STUDENT', 'I-NAME_STUDENT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n","input_ids  --->  [1, 2169, 12103, 270, 3513, 28310, 4593, 271, 57498, 24360, 16789, 271, 1609, 30065, 12287, 662, 86260, 6738, 429, 1857, 279, 1637, 273, 380, 264, 408, 305, 6998, 1879, 308, 384, 390, 262, 6870, 265, 266, 663, 269, 262, 791, 2269, 260, 458, 1444, 269, 266, 791, 2269, 302, 1663, 264, 262, 3742, 265, 72791, 1398, 897, 260, 263, 72791, 1398, 736, 260, 287, 15724, 261, 10040, 268, 5152, 271, 92671, 2531, 280, 51388, 260, 3045, 294, 9110, 25247, 42255, 268, 1931, 280, 65426, 7933, 260, 285, 261, 262, 791, 2269, 287, 698, 59729, 6000, 285, 269, 266, 4981, 5190, 3395, 272, 3832, 262, 1008, 7392, 265, 262, 791, 263, 1279, 262, 1959, 280, 268, 1068, 264, 282, 1315, 260, 45110, 30097, 435, 329, 1637, 303, 386, 5228, 294, 1795, 325, 269, 3469, 264, 305, 263, 490, 298, 1449, 1318, 1146, 1578, 263, 295, 282, 619, 1126, 1795, 325, 269, 18440, 1795, 325, 1279, 51669, 263, 9563, 265, 439, 1795, 325, 295, 282, 2312, 264, 356, 810, 265, 1364, 294, 1521, 14850, 261, 735, 7273, 261, 1423, 261, 2820, 265, 353, 1000, 1795, 325, 269, 2714, 270, 305, 355, 263, 269, 639, 264, 799, 1795, 325, 269, 785, 263, 8331, 9963, 1795, 325, 682, 3979, 262, 7337, 265, 1205, 261, 1604, 261, 88147, 1795, 325, 40478, 268, 1795, 325, 682, 262, 663, 14022, 1795, 325, 1279, 274, 264, 2314, 1000, 279, 2820, 265, 266, 791, 2269, 2351, 275, 299, 781, 320, 40843, 1137, 288, 359, 1386, 260, 329, 1392, 582, 11243, 1000, 320, 6045, 893, 261, 109134, 441, 291, 1386, 267, 266, 25531, 1730, 261, 319, 267, 930, 269, 1797, 275, 283, 386, 6357, 283, 353, 1000, 260, 329, 1637, 4292, 5023, 263, 5506, 264, 282, 45769, 261, 278, 269, 266, 2269, 265, 262, 2230, 260, 28303, 269, 5469, 401, 2754, 551, 1800, 275, 262, 1459, 260, 5736, 429, 22459, 273, 564, 262, 568, 265, 262, 791, 2269, 2820, 275, 262, 6998, 2566, 441, 266, 614, 1247, 287, 7551, 289, 1089, 1247, 285, 260, 344, 262, 1386, 265, 262, 1247, 261, 273, 1183, 263, 4738, 262, 2270, 264, 587, 260, 3492, 266, 813, 265, 841, 261, 273, 1653, 262, 6998, 267, 14956, 262, 791, 2269, 260, 273, 7052, 262, 813, 265, 841, 970, 264, 262, 2270, 264, 282, 5007, 260, 344, 262, 810, 265, 841, 261, 301, 295, 380, 294, 328, 261, 339, 261, 335, 261, 399, 261, 579, 261, 361, 261, 361, 400, 260, 279, 380, 265, 262, 317, 14916, 318, 269, 379, 1257, 264, 796, 262, 5392, 260, 927, 291, 384, 261, 262, 8921, 604, 484, 268, 1161, 292, 41582, 263, 2090, 52521, 264, 9803, 353, 1000, 840, 1029, 265, 7392, 260, 273, 741, 375, 743, 270, 266, 3956, 260, 2169, 12103, 270, 3513, 28310, 4593, 271, 57498, 24360, 16789, 271, 1609, 30065, 12287, 662, 86260, 643, 14956, 262, 791, 2269, 277, 1089, 261, 273, 9803, 264, 262, 2754, 266, 1412, 15895, 265, 308, 374, 275, 262, 908, 265, 1163, 4321, 261, 1426, 263, 88147, 260, 329, 567, 3956, 327, 437, 268, 375, 743, 263, 1279, 262, 791, 2269, 264, 10358, 260, 1414, 103648, 275, 278, 261, 262, 6998, 2607, 262, 617, 265, 262, 1637, 260, 1060, 261, 262, 567, 3956, 2449, 321, 402, 310, 1000, 263, 14350, 9963, 457, 262, 6998, 260, 8132, 291, 353, 791, 2269, 261, 306, 286, 1859, 264, 374, 603, 263, 409, 264, 365, 3979, 262, 37316, 1000, 260, 273, 394, 910, 305, 262, 1205, 273, 2059, 267, 291, 810, 265, 2475, 267, 556, 264, 3468, 4817, 1507, 270, 1129, 271, 12197, 260, 606, 6991, 281, 262, 2233, 265, 312, 460, 1836, 260, 279, 1129, 271, 12197, 281, 2090, 526, 264, 2313, 262, 1604, 265, 262, 1205, 263, 295, 413, 1538, 2359, 264, 15757, 349, 260, 450, 433, 2995, 264, 308, 841, 2022, 264, 266, 24664, 5190, 260, 17798, 458, 273, 433, 1201, 275, 262, 34554, 265, 291, 810, 265, 3956, 269, 262, 2754, 2897, 270, 262, 663, 260, 329, 1637, 1530, 264, 527, 2094, 260, 279, 2754, 1825, 262, 697, 263, 409, 264, 548, 898, 278, 260, 1060, 261, 306, 1166, 638, 5421, 289, 9340, 265, 262, 663, 260, 336, 1903, 1328, 269, 1119, 261, 2090, 15742, 262, 3450, 265, 1144, 2255, 260, 2169, 12103, 270, 3513, 28310, 4593, 271, 57498, 24360, 16789, 271, 1609, 30065, 12287, 662, 86260, 30097, 376, 294, 7826, 7035, 22229, 2196, 663, 2]\n","token_type_ids  --->  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","attention_mask  --->  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n","offset_mapping  --->  [[0, 0], [0, 6], [6, 15], [15, 19], [19, 30], [30, 37], [37, 40], [40, 41], [41, 43], [43, 46], [46, 51], [51, 52], [52, 53], [53, 57], [57, 60], [60, 62], [62, 66], [67, 77], [77, 79], [79, 89], [90, 94], [94, 99], [99, 101], [101, 105], [105, 108], [108, 113], [113, 117], [117, 130], [130, 138], [138, 144], [144, 148], [148, 156], [156, 160], [160, 171], [171, 174], [174, 176], [176, 184], [184, 187], [187, 191], [192, 197], [197, 201], [201, 202], [203, 208], [208, 216], [216, 219], [219, 221], [221, 226], [226, 230], [230, 231], [231, 241], [241, 244], [244, 248], [248, 259], [259, 262], [262, 266], [266, 268], [268, 270], [270, 271], [271, 275], [275, 279], [279, 281], [281, 283], [283, 284], [284, 286], [286, 290], [290, 291], [291, 295], [295, 296], [296, 299], [299, 300], [300, 303], [304, 306], [306, 307], [307, 319], [319, 320], [320, 326], [326, 327], [327, 331], [331, 333], [333, 339], [339, 340], [340, 342], [342, 343], [343, 348], [348, 355], [355, 356], [356, 357], [357, 358], [358, 362], [362, 367], [367, 371], [371, 373], [373, 375], [375, 385], [385, 393], [393, 394], [394, 397], [397, 399], [399, 407], [408, 423], [423, 433], [433, 438], [438, 446], [446, 450], [450, 458], [458, 470], [470, 473], [473, 477], [477, 482], [482, 486], [486, 493], [493, 497], [497, 503], [503, 504], [504, 505], [506, 516], [516, 519], [519, 522], [522, 531], [531, 532], [532, 535], [535, 541], [541, 542], [543, 548], [548, 553], [553, 557], [557, 562], [562, 573], [573, 574], [575, 577], [578, 581], [581, 584], [584, 595], [595, 598], [598, 602], [602, 606], [606, 611], [611, 615], [615, 623], [623, 635], [635, 644], [644, 655], [655, 659], [659, 663], [663, 666], [666, 671], [672, 680], [681, 683], [684, 687], [687, 690], [690, 699], [700, 702], [703, 706], [706, 713], [713, 728], [728, 732], [732, 740], [740, 743], [743, 755], [756, 758], [759, 762], [762, 766], [766, 769], [769, 777], [777, 780], [780, 784], [784, 789], [789, 792], [792, 802], [802, 803], [803, 808], [808, 814], [814, 815], [815, 823], [823, 831], [831, 832], [832, 841], [841, 842], [842, 851], [851, 854], [855, 859], [859, 865], [866, 868], [869, 872], [872, 875], [875, 884], [884, 888], [888, 892], [892, 899], [899, 903], [903, 906], [906, 911], [911, 914], [914, 920], [921, 923], [924, 927], [927, 930], [930, 934], [934, 938], [938, 949], [949, 959], [960, 962], [963, 966], [966, 972], [972, 980], [980, 984], [984, 994], [994, 997], [997, 1006], [1006, 1007], [1007, 1021], [1021, 1022], [1022, 1039], [1040, 1042], [1043, 1046], [1046, 1057], [1057, 1058], [1059, 1061], [1062, 1065], [1065, 1071], [1071, 1075], [1075, 1083], [1083, 1098], [1099, 1101], [1102, 1105], [1105, 1112], [1112, 1116], [1116, 1119], [1119, 1127], [1127, 1133], [1134, 1138], [1138, 1147], [1147, 1150], [1150, 1152], [1152, 1157], [1157, 1161], [1161, 1168], [1168, 1173], [1173, 1176], [1176, 1181], [1181, 1182], [1182, 1189], [1189, 1197], [1197, 1200], [1200, 1204], [1204, 1211], [1211, 1212], [1212, 1217], [1217, 1226], [1226, 1232], [1233, 1243], [1243, 1249], [1249, 1250], [1250, 1254], [1254, 1260], [1260, 1261], [1261, 1273], [1273, 1280], [1280, 1285], [1285, 1292], [1292, 1295], [1295, 1297], [1297, 1304], [1304, 1314], [1314, 1315], [1315, 1321], [1321, 1324], [1324, 1329], [1329, 1332], [1333, 1343], [1343, 1348], [1348, 1351], [1351, 1356], [1356, 1365], [1365, 1368], [1368, 1372], [1372, 1378], [1378, 1379], [1380, 1385], [1385, 1390], [1390, 1398], [1398, 1409], [1409, 1413], [1413, 1419], [1419, 1422], [1422, 1425], [1425, 1435], [1435, 1436], [1436, 1439], [1439, 1442], [1442, 1444], [1444, 1448], [1448, 1451], [1451, 1455], [1455, 1464], [1464, 1465], [1466, 1477], [1477, 1480], [1480, 1489], [1489, 1497], [1497, 1510], [1510, 1515], [1515, 1527], [1527, 1532], [1532, 1536], [1536, 1543], [1543, 1544], [1545, 1557], [1557, 1559], [1559, 1567], [1568, 1570], [1570, 1576], [1576, 1580], [1580, 1588], [1588, 1591], [1591, 1595], [1595, 1600], [1600, 1604], [1604, 1613], [1613, 1618], [1618, 1622], [1622, 1635], [1635, 1644], [1644, 1651], [1651, 1653], [1653, 1659], [1659, 1665], [1666, 1668], [1668, 1673], [1673, 1676], [1676, 1682], [1682, 1688], [1688, 1689], [1689, 1690], [1690, 1693], [1693, 1697], [1697, 1704], [1704, 1707], [1707, 1711], [1711, 1717], [1717, 1718], [1718, 1720], [1720, 1726], [1726, 1730], [1730, 1740], [1740, 1744], [1744, 1750], [1750, 1753], [1753, 1760], [1760, 1761], [1762, 1770], [1770, 1772], [1772, 1779], [1779, 1782], [1782, 1792], [1792, 1793], [1793, 1795], [1795, 1801], [1801, 1805], [1805, 1818], [1818, 1821], [1821, 1831], [1831, 1835], [1835, 1840], [1840, 1844], [1844, 1845], [1845, 1847], [1847, 1853], [1853, 1857], [1857, 1864], [1865, 1868], [1868, 1878], [1878, 1888], [1888, 1891], [1891, 1895], [1895, 1901], [1901, 1904], [1904, 1907], [1907, 1917], [1917, 1918], [1918, 1921], [1921, 1925], [1925, 1930], [1930, 1933], [1933, 1943], [1943, 1944], [1944, 1947], [1947, 1951], [1951, 1955], [1955, 1956], [1956, 1960], [1960, 1961], [1961, 1966], [1966, 1967], [1968, 1973], [1973, 1974], [1974, 1980], [1980, 1981], [1981, 1985], [1985, 1986], [1986, 1990], [1990, 1991], [1991, 1995], [1995, 2000], [2000, 2001], [2002, 2006], [2006, 2010], [2010, 2013], [2013, 2017], [2017, 2019], [2019, 2022], [2022, 2023], [2023, 2026], [2026, 2031], [2031, 2043], [2043, 2046], [2046, 2057], [2057, 2061], [2061, 2068], [2068, 2069], [2069, 2072], [2072, 2077], [2077, 2081], [2081, 2082], [2082, 2086], [2086, 2098], [2098, 2105], [2106, 2111], [2111, 2112], [2112, 2119], [2119, 2124], [2124, 2134], [2134, 2138], [2138, 2143], [2143, 2149], [2149, 2152], [2152, 2160], [2160, 2164], [2164, 2170], [2170, 2172], [2172, 2177], [2177, 2180], [2180, 2192], [2192, 2193], [2193, 2195], [2195, 2200], [2200, 2204], [2205, 2211], [2211, 2215], [2215, 2217], [2217, 2226], [2226, 2227], [2228, 2235], [2235, 2244], [2244, 2248], [2248, 2259], [2259, 2266], [2266, 2269], [2269, 2270], [2270, 2272], [2272, 2275], [2275, 2280], [2280, 2281], [2281, 2282], [2282, 2286], [2286, 2289], [2289, 2291], [2291, 2295], [2296, 2302], [2302, 2312], [2312, 2316], [2316, 2321], [2321, 2325], [2325, 2328], [2328, 2334], [2334, 2335], [2335, 2337], [2337, 2345], [2345, 2348], [2348, 2352], [2352, 2365], [2365, 2367], [2367, 2375], [2375, 2389], [2389, 2392], [2392, 2398], [2399, 2404], [2404, 2409], [2409, 2413], [2413, 2422], [2422, 2425], [2425, 2431], [2431, 2437], [2437, 2438], [2438, 2445], [2445, 2449], [2449, 2466], [2466, 2467], [2467, 2472], [2472, 2479], [2479, 2488], [2488, 2493], [2493, 2498], [2498, 2499], [2500, 2504], [2504, 2510], [2510, 2514], [2514, 2521], [2521, 2525], [2525, 2530], [2530, 2534], [2534, 2537], [2537, 2544], [2544, 2545], [2545, 2550], [2550, 2563], [2563, 2568], [2568, 2571], [2571, 2572], [2572, 2576], [2576, 2589], [2589, 2598], [2599, 2603], [2603, 2609], [2609, 2612], [2612, 2616], [2616, 2621], [2621, 2622], [2622, 2627], [2627, 2628], [2628, 2632], [2632, 2639], [2639, 2648], [2648, 2655], [2655, 2659], [2659, 2664], [2664, 2669], [2669, 2675], [2675, 2679], [2679, 2692], [2693, 2703], [2703, 2711], [2711, 2715], [2715, 2728], [2728, 2729], [2729, 2736], [2736, 2741], [2741, 2745], [2745, 2750], [2750, 2754], [2754, 2755], [2755, 2760], [2760, 2765], [2765, 2773], [2773, 2776], [2776, 2781], [2782, 2791], [2791, 2795], [2795, 2800], [2800, 2803], [2803, 2808], [2808, 2816], [2816, 2820], [2820, 2827], [2827, 2833], [2833, 2834], [2835, 2837], [2837, 2841], [2841, 2849], [2849, 2853], [2853, 2857], [2857, 2866], [2866, 2868], [2868, 2875], [2875, 2878], [2878, 2883], [2883, 2888], [2888, 2891], [2891, 2898], [2898, 2901], [2901, 2907], [2907, 2910], [2910, 2915], [2915, 2921], [2921, 2935], [2935, 2939], [2940, 2949], [2949, 2950], [2950, 2956], [2956, 2957], [2957, 2963], [2963, 2977], [2977, 2981], [2981, 2985], [2985, 2990], [2990, 2993], [2993, 2996], [2996, 3005], [3005, 3012], [3012, 3013], [3013, 3017], [3017, 3026], [3026, 3027], [3027, 3033], [3033, 3037], [3038, 3043], [3043, 3048], [3048, 3051], [3051, 3060], [3060, 3064], [3064, 3078], [3078, 3081], [3081, 3085], [3085, 3094], [3094, 3098], [3098, 3102], [3102, 3107], [3107, 3113], [3113, 3123], [3123, 3126], [3126, 3135], [3135, 3140], [3140, 3141], [3142, 3147], [3147, 3152], [3152, 3160], [3160, 3163], [3163, 3169], [3169, 3179], [3179, 3185], [3185, 3188], [3188, 3190], [3190, 3200], [3200, 3215], [3215, 3216], [3217, 3226], [3227, 3232], [3232, 3234], [3234, 3239], [3239, 3247], [3247, 3252], [3252, 3256], [3256, 3269], [3269, 3272], [3272, 3277], [3277, 3282], [3282, 3285], [3285, 3294], [3294, 3297], [3297, 3301], [3301, 3314], [3314, 3325], [3325, 3329], [3330, 3334], [3334, 3342], [3342, 3343], [3343, 3348], [3348, 3353], [3353, 3359], [3359, 3362], [3362, 3367], [3367, 3375], [3375, 3376], [3376, 3380], [3380, 3393], [3393, 3405], [3405, 3409], [3409, 3415], [3415, 3419], [3419, 3424], [3424, 3427], [3427, 3432], [3433, 3441], [3441, 3444], [3444, 3445], [3445, 3450], [3450, 3451], [3451, 3456], [3456, 3463], [3463, 3470], [3470, 3477], [3477, 3480], [3480, 3489], [3489, 3492], [3492, 3496], [3496, 3504], [3504, 3505], [3505, 3507], [3507, 3513], [3513, 3526], [3526, 3529], [3529, 3535], [3535, 3536], [3537, 3542], [3542, 3555], [3555, 3559], [3559, 3574], [3574, 3577], [3577, 3585], [3585, 3593], [3593, 3594], [3595, 3602], [3602, 3611], [3611, 3615], [3615, 3626], [3626, 3633], [3633, 3636], [3636, 3637], [3637, 3639], [3639, 3642], [3642, 3647], [3647, 3648], [3648, 3649], [3649, 3653], [3653, 3656], [3656, 3658], [3658, 3662], [3663, 3669], [3669, 3671], [3671, 3672], [3672, 3677], [3677, 3681], [3681, 3688], [3688, 3699], [3699, 3707], [0, 0]]\n","labels  --->  [12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 2, 2, 2, 8, 8, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 2, 2, 2, 8, 8, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 2, 2, 2, 8, 8, 12, 12, 12, 12, 12, 12, 12, 12, 12]\n","length  --->  726\n"]}],"source":["for key in ds[0].keys():\n","    print(key, \" ---> \", ds[0][key])"]},{"cell_type":"code","execution_count":75,"metadata":{"execution":{"iopub.execute_input":"2024-01-25T21:37:35.668178Z","iopub.status.busy":"2024-01-25T21:37:35.667908Z","iopub.status.idle":"2024-01-25T21:37:35.67861Z","shell.execute_reply":"2024-01-25T21:37:35.677603Z","shell.execute_reply.started":"2024-01-25T21:37:35.668154Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["8251\n","('Kenichi', 'B-NAME_STUDENT')\n","('Watanabe', 'I-NAME_STUDENT')\n","****************************************************************************************************\n","('▁Ken', 'B-NAME_STUDENT')\n","('ichi', 'B-NAME_STUDENT')\n","('▁Watanabe', 'I-NAME_STUDENT')\n","4951\n","('Norma', 'B-NAME_STUDENT')\n","('Valenzuela', 'I-NAME_STUDENT')\n","('Norma', 'B-NAME_STUDENT')\n","('Valenzuela', 'I-NAME_STUDENT')\n","****************************************************************************************************\n","('▁Norma', 'B-NAME_STUDENT')\n","('▁Valenzuela', 'I-NAME_STUDENT')\n","('▁Norma', 'B-NAME_STUDENT')\n","('▁Valenzuela', 'I-NAME_STUDENT')\n","20629\n","****************************************************************************************************\n","8865\n","****************************************************************************************************\n","13315\n","('https://alvarado.com/categoriesindex.html', 'B-URL_PERSONAL')\n","****************************************************************************************************\n","('▁https', 'B-URL_PERSONAL')\n","(':', 'B-URL_PERSONAL')\n","('/', 'B-URL_PERSONAL')\n","('/', 'B-URL_PERSONAL')\n","('alva', 'B-URL_PERSONAL')\n","('rado', 'B-URL_PERSONAL')\n","('.', 'B-URL_PERSONAL')\n","('com', 'B-URL_PERSONAL')\n","('/', 'B-URL_PERSONAL')\n","('categories', 'B-URL_PERSONAL')\n","('index', 'B-URL_PERSONAL')\n","('.', 'B-URL_PERSONAL')\n","('html', 'B-URL_PERSONAL')\n","7293\n","('Judith', 'B-NAME_STUDENT')\n","('Van', 'I-NAME_STUDENT')\n","('Den', 'I-NAME_STUDENT')\n","('Heuvel', 'I-NAME_STUDENT')\n","****************************************************************************************************\n","('▁Judith', 'B-NAME_STUDENT')\n","('▁Van', 'I-NAME_STUDENT')\n","('▁Den', 'I-NAME_STUDENT')\n","('▁He', 'I-NAME_STUDENT')\n","('uvel', 'I-NAME_STUDENT')\n","14286\n","****************************************************************************************************\n","19275\n","****************************************************************************************************\n","21544\n","****************************************************************************************************\n","10488\n","****************************************************************************************************\n"]}],"source":["# Confirm that alignment is good\n","\n","# run multiple times to see different rows\n","\n","for i in range(10):\n","    x = ds.shuffle()[0]\n","    print(x[\"document\"])\n","\n","    for single_token,single_label in zip(x[\"tokens\"], x[\"provided_labels\"]):\n","        if single_label != \"O\":\n","            print((single_token,single_label))\n","\n","    print(\"*\"*100)\n","            \n","    for single_token, single_label in zip(tokenizer.convert_ids_to_tokens(x[\"input_ids\"]), x[\"labels\"]):\n","        if id2label[single_label] != \"O\":\n","            print((single_token,id2label[single_label]))"]},{"cell_type":"markdown","metadata":{},"source":["## There are some long ones that will get truncated when training if you use a typical max_length\n","\n","There might be some key labels that are at the end that are being missed."]},{"cell_type":"code","execution_count":90,"metadata":{"execution":{"iopub.execute_input":"2024-01-25T21:37:35.680254Z","iopub.status.busy":"2024-01-25T21:37:35.679887Z","iopub.status.idle":"2024-01-25T21:37:35.693285Z","shell.execute_reply":"2024-01-25T21:37:35.692336Z","shell.execute_reply.started":"2024-01-25T21:37:35.680222Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(array([  9.,  19.,  29.,  50.,  56.,  61.,  83., 104., 147., 165., 190.,\n","        209., 262., 271., 311., 302., 317., 299., 307., 342., 320., 294.,\n","        275., 241., 214., 223., 210., 167., 175., 180., 109., 116.,  84.,\n","         81.,  58.,  57.,  67.,  51.,  50.,  41.,  27.,  32.,  36.,  14.,\n","         27.,  13.,  11.,   9.,   5.,  13.,  10.,   9.,   8.,   1.,   5.,\n","          2.,   6.,   3.,   5.,   1.,   2.,   2.,   2.,   0.,   2.,   2.,\n","          2.,   0.,   0.,   2.,   2.,   0.,   0.,   0.,   0.,   1.,   1.,\n","          0.,   0.,   0.,   0.,   0.,   2.,   0.,   0.,   0.,   0.,   0.,\n","          0.,   1.,   0.,   1.,   0.,   0.,   1.,   0.,   0.,   0.,   0.,\n","          1.]),\n"," array([  67.  ,   97.09,  127.18,  157.27,  187.36,  217.45,  247.54,\n","         277.63,  307.72,  337.81,  367.9 ,  397.99,  428.08,  458.17,\n","         488.26,  518.35,  548.44,  578.53,  608.62,  638.71,  668.8 ,\n","         698.89,  728.98,  759.07,  789.16,  819.25,  849.34,  879.43,\n","         909.52,  939.61,  969.7 ,  999.79, 1029.88, 1059.97, 1090.06,\n","        1120.15, 1150.24, 1180.33, 1210.42, 1240.51, 1270.6 , 1300.69,\n","        1330.78, 1360.87, 1390.96, 1421.05, 1451.14, 1481.23, 1511.32,\n","        1541.41, 1571.5 , 1601.59, 1631.68, 1661.77, 1691.86, 1721.95,\n","        1752.04, 1782.13, 1812.22, 1842.31, 1872.4 , 1902.49, 1932.58,\n","        1962.67, 1992.76, 2022.85, 2052.94, 2083.03, 2113.12, 2143.21,\n","        2173.3 , 2203.39, 2233.48, 2263.57, 2293.66, 2323.75, 2353.84,\n","        2383.93, 2414.02, 2444.11, 2474.2 , 2504.29, 2534.38, 2564.47,\n","        2594.56, 2624.65, 2654.74, 2684.83, 2714.92, 2745.01, 2775.1 ,\n","        2805.19, 2835.28, 2865.37, 2895.46, 2925.55, 2955.64, 2985.73,\n","        3015.82, 3045.91, 3076.  ]),\n"," <BarContainer object of 100 artists>)"]},"execution_count":90,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["\n","import matplotlib.pyplot as plt\n","\n","\n","plt.hist(ds[\"length\"], bins=100)"]},{"cell_type":"code","execution_count":91,"metadata":{"execution":{"iopub.execute_input":"2024-01-25T21:37:35.696799Z","iopub.status.busy":"2024-01-25T21:37:35.696483Z","iopub.status.idle":"2024-01-25T21:37:35.707229Z","shell.execute_reply":"2024-01-25T21:37:35.706271Z","shell.execute_reply.started":"2024-01-25T21:37:35.696758Z"},"trusted":true},"outputs":[{"data":{"application/vnd.plotly.v1+json":{"config":{"plotlyServerURL":"https://plot.ly"},"data":[{"hovertemplate":"label=B-NAME_STUDENT<br>range=%{x}<br>count=%{y}<extra></extra>","legendgroup":"B-NAME_STUDENT","marker":{"color":"#636efa","symbol":"circle"},"mode":"markers","name":"B-NAME_STUDENT","orientation":"v","showlegend":true,"type":"scatter","x":["0-50","200-500","500-1000","1000-2000","50-100","100-200","2000-10000"],"xaxis":"x","y":[793,163,283,57,31,33,5],"yaxis":"y"},{"hovertemplate":"label=I-NAME_STUDENT<br>range=%{x}<br>count=%{y}<extra></extra>","legendgroup":"I-NAME_STUDENT","marker":{"color":"#EF553B","symbol":"circle"},"mode":"markers","name":"I-NAME_STUDENT","orientation":"v","showlegend":true,"type":"scatter","x":["0-50","200-500","500-1000","1000-2000","50-100","100-200","2000-10000"],"xaxis":"x","y":[752,86,190,41,16,6,5],"yaxis":"y"},{"hovertemplate":"label=B-URL_PERSONAL<br>range=%{x}<br>count=%{y}<extra></extra>","legendgroup":"B-URL_PERSONAL","marker":{"color":"#00cc96","symbol":"circle"},"mode":"markers","name":"B-URL_PERSONAL","orientation":"v","showlegend":true,"type":"scatter","x":["500-1000","0-50","200-500","1000-2000","50-100","2000-10000","100-200"],"xaxis":"x","y":[32,15,31,15,10,1,6],"yaxis":"y"},{"hovertemplate":"label=B-EMAIL<br>range=%{x}<br>count=%{y}<extra></extra>","legendgroup":"B-EMAIL","marker":{"color":"#ab63fa","symbol":"circle"},"mode":"markers","name":"B-EMAIL","orientation":"v","showlegend":true,"type":"scatter","x":["0-50","50-100","500-1000","200-500"],"xaxis":"x","y":[21,3,6,9],"yaxis":"y"},{"hovertemplate":"label=B-ID_NUM<br>range=%{x}<br>count=%{y}<extra></extra>","legendgroup":"B-ID_NUM","marker":{"color":"#FFA15A","symbol":"circle"},"mode":"markers","name":"B-ID_NUM","orientation":"v","showlegend":true,"type":"scatter","x":["0-50","50-100","500-1000","200-500","100-200"],"xaxis":"x","y":[37,10,12,17,2],"yaxis":"y"},{"hovertemplate":"label=I-URL_PERSONAL<br>range=%{x}<br>count=%{y}<extra></extra>","legendgroup":"I-URL_PERSONAL","marker":{"color":"#19d3f3","symbol":"circle"},"mode":"markers","name":"I-URL_PERSONAL","orientation":"v","showlegend":true,"type":"scatter","x":["0-50"],"xaxis":"x","y":[1],"yaxis":"y"},{"hovertemplate":"label=B-USERNAME<br>range=%{x}<br>count=%{y}<extra></extra>","legendgroup":"B-USERNAME","marker":{"color":"#FF6692","symbol":"circle"},"mode":"markers","name":"B-USERNAME","orientation":"v","showlegend":true,"type":"scatter","x":["50-100","0-50","500-1000"],"xaxis":"x","y":[1,3,2],"yaxis":"y"},{"hovertemplate":"label=B-PHONE_NUM<br>range=%{x}<br>count=%{y}<extra></extra>","legendgroup":"B-PHONE_NUM","marker":{"color":"#B6E880","symbol":"circle"},"mode":"markers","name":"B-PHONE_NUM","orientation":"v","showlegend":true,"type":"scatter","x":["0-50","200-500"],"xaxis":"x","y":[3,3],"yaxis":"y"},{"hovertemplate":"label=I-PHONE_NUM<br>range=%{x}<br>count=%{y}<extra></extra>","legendgroup":"I-PHONE_NUM","marker":{"color":"#FF97FF","symbol":"circle"},"mode":"markers","name":"I-PHONE_NUM","orientation":"v","showlegend":true,"type":"scatter","x":["0-50","200-500"],"xaxis":"x","y":[6,9],"yaxis":"y"},{"hovertemplate":"label=B-STREET_ADDRESS<br>range=%{x}<br>count=%{y}<extra></extra>","legendgroup":"B-STREET_ADDRESS","marker":{"color":"#FECB52","symbol":"circle"},"mode":"markers","name":"B-STREET_ADDRESS","orientation":"v","showlegend":true,"type":"scatter","x":["0-50","100-200"],"xaxis":"x","y":[1,1],"yaxis":"y"},{"hovertemplate":"label=I-STREET_ADDRESS<br>range=%{x}<br>count=%{y}<extra></extra>","legendgroup":"I-STREET_ADDRESS","marker":{"color":"#636efa","symbol":"circle"},"mode":"markers","name":"I-STREET_ADDRESS","orientation":"v","showlegend":true,"type":"scatter","x":["0-50","100-200"],"xaxis":"x","y":[10,10],"yaxis":"y"},{"hovertemplate":"label=I-ID_NUM<br>range=%{x}<br>count=%{y}<extra></extra>","legendgroup":"I-ID_NUM","marker":{"color":"#EF553B","symbol":"circle"},"mode":"markers","name":"I-ID_NUM","orientation":"v","showlegend":true,"type":"scatter","x":["50-100"],"xaxis":"x","y":[1],"yaxis":"y"}],"layout":{"height":1000,"legend":{"title":{"text":"label"},"tracegroupgap":0},"margin":{"t":60},"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"#E5ECF6","showlakes":true,"showland":true,"subunitcolor":"white"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"#E5ECF6","polar":{"angularaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"bgcolor":"#E5ECF6","radialaxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","gridwidth":2,"linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white"},"yaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","gridwidth":2,"linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white"},"zaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","gridwidth":2,"linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"baxis":{"gridcolor":"white","linecolor":"white","ticks":""},"bgcolor":"#E5ECF6","caxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","zerolinewidth":2}}},"xaxis":{"anchor":"y","domain":[0,1],"title":{"text":"range"}},"yaxis":{"anchor":"x","domain":[0,1],"title":{"text":"count"},"type":"log"}}}},"metadata":{},"output_type":"display_data"}],"source":["\n","import pandas as pd\n","import plotly.express as px\n","from collections import Counter\n","\n","\n","group = []\n","labels = []\n","\n","group_thresholds = [0, 50, 100, 200, 500, 1000, 2000, 10000]\n","\n","for sample_labels in ds[\"provided_labels\"]:\n","    for i, label in enumerate(sample_labels):\n","        if label != \"O\":\n","            for j in range(1, len(group_thresholds)):\n","                lower = group_thresholds[j-1]\n","                upper = group_thresholds[j]\n","                \n","                if lower <= i < upper:\n","                    group.append(f\"{lower}-{upper}\")\n","                    labels.append(label)\n","                    break\n","\n","pairs = list(zip(labels, group))\n","\n","counts = Counter(pairs)\n","\n","\n","data = {\n","    \"label\": [],\n","    \"count\": [],\n","    \"range\": [],\n","}\n","\n","for (label, range_), count in counts.items():\n","    data[\"label\"].append(label)\n","    data[\"range\"].append(range_)\n","    data[\"count\"].append(count)\n","\n","            \n","df = pd.DataFrame(data)\n","\n","\n","px.scatter(df, x=\"range\", y=\"count\", color=\"label\", log_y=True, height=1000)"]},{"cell_type":"code","execution_count":78,"metadata":{"execution":{"iopub.execute_input":"2024-01-25T21:37:35.708858Z","iopub.status.busy":"2024-01-25T21:37:35.708576Z","iopub.status.idle":"2024-01-25T21:37:35.721935Z","shell.execute_reply":"2024-01-25T21:37:35.720959Z","shell.execute_reply.started":"2024-01-25T21:37:35.708834Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Writing run.py\n"]}],"source":["%%writefile run.py\n","\n","import os\n","import json\n","import argparse\n","import random\n","from itertools import chain\n","from functools import partial\n","\n","from transformers import AutoTokenizer, AutoModelForTokenClassification, Trainer, TrainingArguments, DataCollatorForTokenClassification\n","from tokenizers import AddedToken\n","import evaluate\n","from datasets import Dataset\n","import numpy as np\n","\n","os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n","\n","# https://www.kaggle.com/competitions/pii-detection-removal-from-educational-data/discussion/468844\n","def filter_no_pii(example, percent_allow=0.2):\n","    # Return True if there is PII\n","    # Or 20% of the time if there isn't\n","    \n","    has_pii = set(\"O\") != set(example[\"provided_labels\"])\n","    \n","    return has_pii or (random.random() < percent_allow)\n","\n","def tokenize(example, tokenizer, label2id, max_length):\n","    text = []\n","    labels = []\n","    \n","    for t, l, ws in zip(example[\"tokens\"], example[\"provided_labels\"], example[\"trailing_whitespace\"]):\n","        \n","        text.append(t)\n","        labels.extend([l]*len(t))\n","        if ws:\n","            text.append(\" \")\n","            labels.append(\"O\")\n","    \n","    \n","    tokenized = tokenizer(\"\".join(text), return_offsets_mapping=True, max_length=max_length)\n","    \n","    labels = np.array(labels)\n","    \n","    text = \"\".join(text)\n","    token_labels = []\n","    \n","    for start_idx, end_idx in tokenized.offset_mapping:\n","        \n","        # CLS token\n","        if start_idx == 0 and end_idx == 0: \n","            token_labels.append(label2id[\"O\"])\n","            continue\n","        \n","        # case when token starts with whitespace\n","        if text[start_idx].isspace():\n","            start_idx += 1\n","        \n","        while start_idx >= len(labels):\n","            start_idx -= 1\n","            \n","        token_labels.append(label2id[labels[start_idx]])\n","        \n","    length = len(tokenized.input_ids)\n","        \n","    return {\n","        **tokenized,\n","        \"labels\": token_labels,\n","        \"length\": length\n","    }\n","    \n","def compute_metrics(p, metric, all_labels):\n","    predictions, labels = p\n","    predictions = np.argmax(predictions, axis=2)\n","\n","    # Remove ignored index (special tokens)\n","    true_predictions = [\n","        [all_labels[p] for (p, l) in zip(prediction, label) if l != -100]\n","        for prediction, label in zip(predictions, labels)\n","    ]\n","    true_labels = [\n","        [all_labels[l] for (p, l) in zip(prediction, label) if l != -100]\n","        for prediction, label in zip(predictions, labels)\n","    ]\n","\n","    results = metric.compute(predictions=true_predictions, references=true_labels)\n","\n","    # Unpack nested dictionaries\n","    final_results = {}\n","    for key, value in results.items():\n","        if isinstance(value, dict):\n","            for n, v in value.items():\n","                final_results[f\"{key}_{n}\"] = v\n","        else:\n","            final_results[key] = value\n","    return final_results   \n","\n","def main():\t20\n","    \n","    parser = argparse.ArgumentParser()\n","    \n","    parser.add_argument(\"--model_path\", type=str)\n","    parser.add_argument(\"--max_length\", type=int)\n","    \n","    args = parser.parse_args()\n","    \n","    \n","    data = json.load(open(\"/kaggle/input/pii-detection-removal-from-educational-data/train.json\"))\n","\n","\n","    all_labels = sorted(list(set(chain(*[x[\"labels\"] for x in data]))))\n","    label2id = {l: i for i,l in enumerate(all_labels)}\n","    id2label = {v:k for k,v in label2id.items()}\n","\n","\n","    ds = Dataset.from_dict({\n","        \"full_text\": [x[\"full_text\"] for x in data],\n","        \"document\": [x[\"document\"] for x in data],\n","        \"tokens\": [x[\"tokens\"] for x in data],\n","        \"trailing_whitespace\": [x[\"trailing_whitespace\"] for x in data],\n","        \"provided_labels\": [x[\"labels\"] for x in data],b 0.576  \n","    })\n","\n","    \n","    tokenizer = AutoTokenizer.from_pretrained(args.model_path)\n","    \n","    # lots of newlines in the text\n","    # adding this should be helpful\n","    tokenizer.add_tokens(AddedToken(\"\\n\", normalized=False))\n","    \n","    ds = ds.filter(\n","        filter_no_pii,\n","        num_proc=2,\n","    )\n","    \n","    ds = ds.map(\n","        tokenize, \n","        fn_kwargs={\"tokenizer\": tokenizer, \"label2id\": label2id, \"max_length\": args.max_length}, \n","        num_proc=2,\n","    )\n","\n","\n","    metric = evaluate.load(\"seqeval\")\n","\n","\n","    model = AutoModelForTokenClassification.from_pretrained(args.model_path, num_labels=len(all_labels), id2label=id2label, label2id=label2id)\n","    model.resize_token_embeddings(len(tokenizer), pad_to_multiple_of=16)\n","\n","    collator = DataCollatorForTokenClassification(tokenizer, pad_to_multiple_of=16)\n","\n","    args = TrainingArguments(\n","        \"output\", \n","        fp16=True, \n","        learning_rate=5e-5,\n","        weight_decay=0.01,\n","        warmup_ratio=0.1,\n","        per_device_train_batch_size=8,\n","        per_device_eval_batch_size=4, \n","        report_to=\"none\",\n","        evaluation_strategy=\"epoch\",\n","        save_strategy=\"epoch\",\n","        save_total_limit=1,\n","        logging_steps=5,\n","        metric_for_best_model=\"overall_recall\",\n","        greater_is_better=True,\n","        gradient_checkpointing=True,\n","        num_train_epochs=1\n","        dataloader_num_workers=1,\n","    )\n","\n","    # may want to try to balance classes in splits\n","    final_ds = ds.train_test_split(test_size=0.2)\n","\n","\n","    trainer = Trainer(\n","        model=model, \n","        args=args, \n","        train_dataset=final_ds[\"train\"], \n","        eval_dataset=final_ds[\"test\"], \n","        data_collator=collator, \n","        tokenizer=tokenizer,\n","        compute_metrics=partial(compute_metrics, metric=metric, all_labels=all_labels),\n","    )\n","\n","\n","    trainer.train()\n","    \n","    \n","if __name__ == \"__main__\":\n","    main()"]},{"cell_type":"code","execution_count":79,"metadata":{"execution":{"iopub.execute_input":"2024-01-25T21:37:35.723745Z","iopub.status.busy":"2024-01-25T21:37:35.723047Z","iopub.status.idle":"2024-01-25T21:37:35.73577Z","shell.execute_reply":"2024-01-25T21:37:35.734814Z","shell.execute_reply.started":"2024-01-25T21:37:35.723707Z"},"trusted":true},"outputs":[],"source":["if TRAINING:\n","    # utilize both t4 gpus\n","    !accelerate launch --multi_gpu --num_processes 2 run.py \\\n","      --model_path $TRAINING_MODEL_PATH \\\n","      --max_length $TRAINING_MAX_LENGTH"]},{"cell_type":"code","execution_count":80,"metadata":{"execution":{"iopub.execute_input":"2024-01-25T21:37:35.737914Z","iopub.status.busy":"2024-01-25T21:37:35.737658Z","iopub.status.idle":"2024-01-25T21:37:35.749405Z","shell.execute_reply":"2024-01-25T21:37:35.748491Z","shell.execute_reply.started":"2024-01-25T21:37:35.737891Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Writing infer.py\n"]}],"source":["%%writefile infer.py\n","\n","import json\n","import argparse\n","from itertools import chain\n","\n","from transformers import AutoTokenizer, AutoModelForTokenClassification, Trainer, TrainingArguments, DataCollatorForTokenClassification\n","from datasets import Dataset\n","import numpy as np\n","\n","def tokenize(example, tokenizer, max_length):\n","    text = []\n","    token_map = []\n","    \n","    idx = 0\n","    \n","    for t, ws in zip(example[\"tokens\"], example[\"trailing_whitespace\"]):\n","        \n","        text.append(t)\n","        token_map.extend([idx]*len(t))\n","        if ws:\n","            text.append(\" \")\n","            token_map.append(-1)\n","            \n","        idx += 1\n","            \n","        \n","    tokenized = tokenizer(\"\".join(text), return_offsets_mapping=True, max_length=max_length)\n","    \n","        \n","    return {\n","        **tokenized,\n","        \"token_map\": token_map,\n","    }\n","\n","def main():\n","    \n","    parser = argparse.ArgumentParser()\n","    \n","    parser.add_argument(\"--model_path\", type=str)\n","    parser.add_argument(\"--max_length\", type=int)\n","    \n","    args = parser.parse_args()\n","    \n","    data = json.load(open(\"/kaggle/input/pii-detection-removal-from-educational-data/test.json\"))\n","    \n","    ds = Dataset.from_dict({\n","        \"full_text\": [x[\"full_text\"] for x in data],\n","        \"document\": [x[\"document\"] for x in data],\n","        \"tokens\": [x[\"tokens\"] for x in data],\n","        \"trailing_whitespace\": [x[\"trailing_whitespace\"] for x in data],\n","    })\n","\n","    \n","    tokenizer = AutoTokenizer.from_pretrained(args.model_path)\n","    ds = ds.map(\n","        tokenize, \n","        fn_kwargs={\"tokenizer\": tokenizer, \"max_length\": args.max_length}, \n","        num_proc=2,\n","    )\n","    \n","    model = AutoModelForTokenClassification.from_pretrained(args.model_path)\n","\n","    collator = DataCollatorForTokenClassification(tokenizer, pad_to_multiple_of=16)\n","\n","    args = TrainingArguments(\n","        \".\", \n","        per_device_eval_batch_size=4, \n","        report_to=\"none\",\n","    )\n","    \n","    trainer = Trainer(\n","        model=model, \n","        args=args, \n","        data_collator=collator, \n","        tokenizer=tokenizer,\n","    )\n","    \n","    \n","    predictions = trainer.predict(ds).predictions\n","\n","    ds.to_parquet(\"test_ds.pq\")\n","    \n","    np.save(\"preds.npy\", predictions)\n","    \n","    \n","if __name__ == \"__main__\":\n","    main()"]},{"cell_type":"code","execution_count":81,"metadata":{"execution":{"iopub.execute_input":"2024-01-25T21:37:35.75094Z","iopub.status.busy":"2024-01-25T21:37:35.750623Z","iopub.status.idle":"2024-01-25T21:38:23.004134Z","shell.execute_reply":"2024-01-25T21:38:23.003086Z","shell.execute_reply.started":"2024-01-25T21:37:35.750909Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["The following values were not passed to `accelerate launch` and had defaults used instead:\n","\t`--num_machines` was set to a value of `1`\n","\t`--mixed_precision` was set to a value of `'no'`\n","\t`--dynamo_backend` was set to a value of `'no'`\n","To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n","usage: infer.py [-h] [--model_path MODEL_PATH] [--max_length MAX_LENGTH]\n","infer.py: error: argument --model_path: expected one argument\n","Traceback (most recent call last):\n","  File \"/opt/homebrew/Caskroom/miniconda/base/envs/torch_ds/bin/accelerate\", line 10, in <module>\n","    sys.exit(main())\n","  File \"/opt/homebrew/Caskroom/miniconda/base/envs/torch_ds/lib/python3.10/site-packages/accelerate/commands/accelerate_cli.py\", line 45, in main\n","    args.func(args)\n","  File \"/opt/homebrew/Caskroom/miniconda/base/envs/torch_ds/lib/python3.10/site-packages/accelerate/commands/launch.py\", line 941, in launch_command\n","    simple_launcher(args)\n","  File \"/opt/homebrew/Caskroom/miniconda/base/envs/torch_ds/lib/python3.10/site-packages/accelerate/commands/launch.py\", line 603, in simple_launcher\n","    raise subprocess.CalledProcessError(returncode=process.returncode, cmd=cmd)\n","subprocess.CalledProcessError: Command '['/opt/homebrew/Caskroom/miniconda/base/envs/torch_ds/bin/python3.10', 'infer.py', '--model_path', '--max_length']' returned non-zero exit status 2.\n"]}],"source":["if not TRAINING:\n","    \n","    !accelerate launch --num_processes 2 infer.py \\\n","      --model_path $INFERENCE_MODEL_PATH \\\n","      --max_length $INFERENCE_MAX_LENGTH"]},{"cell_type":"markdown","metadata":{},"source":["### Recall is much more important than precision, so it might make sense to make predictions even if they aren't the highest score"]},{"cell_type":"code","execution_count":82,"metadata":{"execution":{"iopub.execute_input":"2024-01-25T21:38:23.008142Z","iopub.status.busy":"2024-01-25T21:38:23.00778Z","iopub.status.idle":"2024-01-25T21:38:23.361032Z","shell.execute_reply":"2024-01-25T21:38:23.36012Z","shell.execute_reply.started":"2024-01-25T21:38:23.008112Z"},"trusted":true},"outputs":[{"ename":"NameError","evalue":"name 'INFERENCE_MODEL_PATH' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[82], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[0;32m----> 9\u001b[0m config \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28mopen\u001b[39m(Path(\u001b[43mINFERENCE_MODEL_PATH\u001b[49m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig.json\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     11\u001b[0m id2label \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid2label\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     13\u001b[0m preds \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpreds.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","\u001b[0;31mNameError\u001b[0m: name 'INFERENCE_MODEL_PATH' is not defined"]}],"source":["if not TRAINING:\n","    \n","    import numpy as np\n","    import json\n","    from datasets import Dataset\n","    import pandas as pd\n","    from pathlib import Path\n","\n","    config = json.load(open(Path(INFERENCE_MODEL_PATH) / \"config.json\"))\n","\n","    id2label = config[\"id2label\"]\n","\n","    preds = np.load(\"preds.npy\")\n","\n","    ds = Dataset.from_parquet(\"test_ds.pq\")\n","\n","    preds = preds.argmax(-1)\n","\n","    triplets = []\n","    document, token, label, token_str = [], [], [], []\n","    for p, token_map, offsets, tokens, doc in zip(preds, ds[\"token_map\"], ds[\"offset_mapping\"], ds[\"tokens\"], ds[\"document\"]):\n","\n","        for token_pred, (start_idx, end_idx) in zip(p, offsets):\n","            label_pred = id2label[str(token_pred)]\n","\n","            if start_idx + end_idx == 0: continue\n","\n","            if token_map[start_idx] == -1: \n","                start_idx += 1\n","\n","            # ignore \"\\n\\n\"\n","            while start_idx < len(token_map) and tokens[token_map[start_idx]].isspace():\n","                start_idx += 1\n","\n","            if start_idx >= len(token_map): break\n","\n","            token_id = token_map[start_idx]\n","\n","            # ignore \"O\" predictions and whitespace preds\n","            if label_pred != \"O\" and token_id != -1:\n","                triplet = (label_pred, token_id, tokens[token_id])\n","\n","                if triplet not in triplets:\n","                    document.append(doc)\n","                    token.append(token_id)\n","                    label.append(label_pred)\n","                    token_str.append(tokens[token_id])\n","                    triplets.append(triplet)\n","\n","\n","    df = pd.DataFrame({\n","        \"document\": document,\n","        \"token\": token,\n","        \"label\": label,\n","        \"token_str\": token_str\n","    })\n","\n","    df[\"row_id\"] = list(range(len(df)))\n","\n","    display(df.head(50))\n","\n","\n","    df[[\"row_id\", \"document\", \"token\", \"label\"]].to_csv(\"submission.csv\", index=False)"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"databundleVersionId":7500999,"sourceId":66653,"sourceType":"competition"},{"datasetId":4319117,"sourceId":7429898,"sourceType":"datasetVersion"}],"dockerImageVersionId":30636,"isGpuEnabled":true,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"}},"nbformat":4,"nbformat_minor":4}
